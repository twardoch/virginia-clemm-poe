{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Virginia Clemm Poe Documentation","text":""},{"location":"index.html#tldr","title":"TLDR","text":"<p>Virginia Clemm Poe is a Python package that provides programmatic access to comprehensive Poe.com model data with pricing information. It acts as a companion tool to the official Poe API by fetching, maintaining, and enriching model data through web scraping, with a special focus on capturing detailed pricing information not available through the API alone.</p> <p>Key Features: - \ud83e\udd16 Comprehensive Model Data: Access to all Poe.com models with detailed metadata - \ud83d\udcb0 Pricing Information: Automatically scraped pricing data for all operations - \ud83d\udc0d Python API: Clean, typed API for programmatic access - \ud83d\udda5\ufe0f CLI Interface: Fire-based command-line tools for data management - \ud83c\udf10 Web Scraping: Playwright-powered browser automation for reliable data extraction - \ud83d\udcca Pydantic Models: Fully typed data structures for easy integration</p>"},{"location":"index.html#explore-models","title":"Explore Models","text":"<p>\ud83d\udd0d Browse Interactive Models Database - Explore all available Poe.com models with real-time search, filtering, and detailed pricing information</p> <p>\ud83d\udcca View Models Table - Interactive searchable table of all models with pricing and metadata</p>"},{"location":"index.html#table-of-contents","title":"Table of Contents","text":""},{"location":"index.html#getting-started","title":"Getting Started","text":"<ol> <li>Introduction and Overview - Learn about the package's purpose, architecture, and core concepts</li> <li>Installation and Setup - Step-by-step installation guide and initial configuration</li> <li>Quick Start Guide - Get up and running with basic examples and common use cases</li> </ol>"},{"location":"index.html#usage-guides","title":"Usage Guides","text":"<ol> <li>Python API Reference - Complete Python API documentation with examples</li> <li>CLI Usage and Commands - Command-line interface reference and usage patterns</li> <li>Data Models and Structure - Understanding the data structures and Pydantic models</li> </ol>"},{"location":"index.html#advanced-topics","title":"Advanced Topics","text":"<ol> <li>Browser Management and Web Scraping - Deep dive into web scraping functionality and browser automation</li> <li>Configuration and Advanced Usage - Advanced configuration options and customization</li> <li>Troubleshooting and FAQ - Common issues, solutions, and frequently asked questions</li> </ol>"},{"location":"index.html#quick-example","title":"Quick Example","text":"<pre><code>from virginia_clemm_poe import api\n\n# Search for Claude models\nclaude_models = api.search_models(query=\"claude\")\n\n# Get specific model with pricing\nmodel = api.get_model_by_id(\"claude-3-opus\")\nif model.pricing:\n    print(f\"Input cost: {model.pricing.details['Input (text)']}\")\n\n# List all available models\nall_models = api.list_models()\nprint(f\"Total models available: {len(all_models)}\")\n</code></pre>"},{"location":"index.html#cli-quick-start","title":"CLI Quick Start","text":"<pre><code># Setup browser for web scraping\nvirginia-clemm-poe setup\n\n# Update model data with pricing\nPOE_API_KEY=your_key virginia-clemm-poe update --pricing\n\n# Search for models\nvirginia-clemm-poe search \"gpt-4\"\n</code></pre>"},{"location":"index.html#project-links","title":"Project Links","text":"<ul> <li>GitHub Repository: terragonlabs/virginia-clemm-poe</li> <li>PyPI Package: virginia-clemm-poe</li> <li>Issues &amp; Support: GitHub Issues</li> </ul> <p>Named after Edgar Allan Poe's wife and cousin, Virginia Clemm Poe, this package serves as a faithful companion to the Poe platform, just as she was to the great poet.</p>"},{"location":"chapter1-introduction.html","title":"Chapter 1: Introduction and Overview","text":""},{"location":"chapter1-introduction.html#what-is-virginia-clemm-poe","title":"What is Virginia Clemm Poe?","text":"<p>Virginia Clemm Poe is a specialized Python package designed to bridge the gap between the official Poe.com API and the rich metadata available on the Poe website. While the Poe API provides basic model information, it lacks crucial details like pricing data, detailed descriptions, and creator information that are only available through the web interface.</p> <p>This package solves that problem by combining API data with intelligent web scraping to create a comprehensive, locally-cached dataset of all Poe.com models with their complete metadata.</p>"},{"location":"chapter1-introduction.html#why-this-package-exists","title":"Why This Package Exists","text":""},{"location":"chapter1-introduction.html#the-problem","title":"The Problem","text":"<p>The Poe.com platform hosts hundreds of AI models from various providers, each with different capabilities, pricing structures, and use cases. While Poe provides an API to access these models programmatically, the API response lacks several key pieces of information:</p> <ul> <li>Detailed Pricing Information: Cost per message, input pricing, cache discounts</li> <li>Rich Metadata: Creator information, detailed descriptions, model capabilities</li> <li>Real-time Availability: Which models are currently active and accessible</li> </ul>"},{"location":"chapter1-introduction.html#the-solution","title":"The Solution","text":"<p>Virginia Clemm Poe addresses these limitations by:</p> <ol> <li>Fetching Complete API Data: Starting with the official Poe API to get the base model list</li> <li>Intelligent Web Scraping: Using Playwright to navigate to each model's page and extract missing information</li> <li>Data Enrichment: Combining API and scraped data into comprehensive model records</li> <li>Local Caching: Storing the enriched dataset locally for fast, offline access</li> <li>Easy Access: Providing both Python API and CLI interfaces for different use cases</li> </ol>"},{"location":"chapter1-introduction.html#core-architecture","title":"Core Architecture","text":""},{"location":"chapter1-introduction.html#data-flow","title":"Data Flow","text":"<pre><code>graph TD\n    A[Poe API] --&gt; B[API Data Fetcher]\n    C[Poe Website] --&gt; D[Web Scraper]\n    B --&gt; E[Data Merger]\n    D --&gt; E\n    E --&gt; F[Local JSON Dataset]\n    F --&gt; G[Python API]\n    F --&gt; H[CLI Interface]\n</code></pre>"},{"location":"chapter1-introduction.html#key-components","title":"Key Components","text":"<ol> <li>API Client (<code>api.py</code>): Handles communication with the Poe API</li> <li>Web Scraper (<code>updater.py</code>, <code>browser_manager.py</code>): Manages browser automation and data extraction</li> <li>Data Models (<code>models.py</code>): Pydantic models for type safety and validation</li> <li>Local Storage: JSON-based dataset with version control</li> <li>User Interfaces: Python API and CLI for different access patterns</li> </ol>"},{"location":"chapter1-introduction.html#package-philosophy","title":"Package Philosophy","text":""},{"location":"chapter1-introduction.html#design-principles","title":"Design Principles","text":"<ul> <li>Reliability First: Robust error handling and graceful degradation</li> <li>Type Safety: Full Pydantic models with comprehensive validation</li> <li>Performance: Local caching minimizes network requests</li> <li>Transparency: Clear logging and debugging capabilities</li> <li>Maintainability: Clean architecture with separation of concerns</li> </ul>"},{"location":"chapter1-introduction.html#data-integrity","title":"Data Integrity","text":"<p>The package prioritizes data accuracy and freshness:</p> <ul> <li>Incremental Updates: Only scrape models that need updates</li> <li>Validation: Pydantic models ensure data consistency</li> <li>Backup and Recovery: Automatic backup of existing data before updates</li> <li>Version Tracking: Timestamps for data freshness monitoring</li> </ul>"},{"location":"chapter1-introduction.html#use-cases","title":"Use Cases","text":""},{"location":"chapter1-introduction.html#for-developers","title":"For Developers","text":"<ul> <li>Model Discovery: Find the right AI model for your specific needs</li> <li>Cost Analysis: Compare pricing across different models and providers</li> <li>Integration Planning: Understand model capabilities before implementation</li> <li>Monitoring: Track model availability and pricing changes</li> </ul>"},{"location":"chapter1-introduction.html#for-researchers","title":"For Researchers","text":"<ul> <li>Market Analysis: Study the AI model landscape and pricing trends</li> <li>Capability Mapping: Understand the distribution of AI capabilities</li> <li>Provider Comparison: Analyze different AI providers' offerings</li> </ul>"},{"location":"chapter1-introduction.html#for-business-users","title":"For Business Users","text":"<ul> <li>Cost Optimization: Find the most cost-effective models for your use cases</li> <li>Vendor Evaluation: Compare AI providers and their model portfolios</li> <li>Budget Planning: Understand pricing structures for budget allocation</li> </ul>"},{"location":"chapter1-introduction.html#whats-next","title":"What's Next","text":"<p>In the following chapters, you'll learn how to:</p> <ul> <li>Install and configure the package</li> <li>Use the Python API for programmatic access</li> <li>Leverage the CLI for data management and querying</li> <li>Understand the data structures and models</li> <li>Configure advanced features and troubleshoot issues</li> </ul>"},{"location":"chapter1-introduction.html#package-naming","title":"Package Naming","text":"<p>The package is named after Virginia Clemm Poe (1822-1847), the wife and cousin of Edgar Allan Poe. Just as Virginia was a faithful companion to the great poet, this package serves as a faithful companion to the Poe platform, enriching and enhancing the core functionality with additional valuable information.</p> <p>The choice reflects the package's role as a supportive tool that doesn't replace the original Poe API but rather complements and enhances it, much like how Virginia supported and inspired Edgar Allan Poe's literary work.</p>"},{"location":"chapter2-installation.html","title":"Chapter 2: Installation and Setup","text":""},{"location":"chapter2-installation.html#system-requirements","title":"System Requirements","text":""},{"location":"chapter2-installation.html#python-version","title":"Python Version","text":"<ul> <li>Python 3.12+ is required</li> <li>The package uses modern Python features and type hints</li> </ul>"},{"location":"chapter2-installation.html#operating-system","title":"Operating System","text":"<ul> <li>Linux (recommended for production)</li> <li>macOS (fully supported)</li> <li>Windows (supported with some limitations)</li> </ul>"},{"location":"chapter2-installation.html#browser-requirements","title":"Browser Requirements","text":"<ul> <li>Chrome or Chromium browser must be installed</li> <li>The package uses Playwright for web scraping, which requires a Chromium-based browser</li> <li>Browser installation is handled automatically by the package</li> </ul>"},{"location":"chapter2-installation.html#installation-methods","title":"Installation Methods","text":""},{"location":"chapter2-installation.html#method-1-pypi-installation-recommended","title":"Method 1: PyPI Installation (Recommended)","text":"<pre><code>pip install virginia-clemm-poe\n</code></pre> <p>For users with <code>uv</code> (recommended for faster dependency resolution):</p> <pre><code>uv pip install virginia-clemm-poe\n</code></pre>"},{"location":"chapter2-installation.html#method-2-development-installation","title":"Method 2: Development Installation","text":"<p>If you want to contribute or use the latest development version:</p> <pre><code>git clone https://github.com/terragonlabs/virginia-clemm-poe.git\ncd virginia-clemm-poe\nuv venv --python 3.12\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv pip install -e .\n</code></pre>"},{"location":"chapter2-installation.html#method-3-direct-from-github","title":"Method 3: Direct from GitHub","text":"<pre><code>pip install git+https://github.com/terragonlabs/virginia-clemm-poe.git\n</code></pre>"},{"location":"chapter2-installation.html#initial-setup","title":"Initial Setup","text":""},{"location":"chapter2-installation.html#1-browser-setup","title":"1. Browser Setup","text":"<p>After installation, you need to set up the browser for web scraping:</p> <pre><code>virginia-clemm-poe setup\n</code></pre> <p>This command will: - Download and configure Playwright - Install necessary browser dependencies - Verify browser functionality - Create initial configuration files</p> <p>Browser Setup</p> <p>The setup process downloads a Chromium browser (~100MB) that's isolated from your system browser. This ensures consistent scraping behavior across different environments.</p>"},{"location":"chapter2-installation.html#2-api-key-configuration","title":"2. API Key Configuration","text":"<p>To use the full functionality, you need a Poe API key:</p>"},{"location":"chapter2-installation.html#getting-a-poe-api-key","title":"Getting a Poe API Key","text":"<ol> <li>Visit Poe.com</li> <li>Sign in to your account</li> <li>Navigate to API settings</li> <li>Generate a new API key</li> <li>Copy the key for configuration</li> </ol>"},{"location":"chapter2-installation.html#setting-the-api-key","title":"Setting the API Key","text":"<p>You can provide the API key in several ways:</p> <p>Option 1: Environment Variable (Recommended) <pre><code>export POE_API_KEY=\"your_api_key_here\"\n</code></pre></p> <p>Option 2: Configuration File <pre><code>virginia-clemm-poe config set-api-key your_api_key_here\n</code></pre></p> <p>Option 3: Runtime Parameter <pre><code>virginia-clemm-poe update --api-key your_api_key_here\n</code></pre></p>"},{"location":"chapter2-installation.html#3-verify-installation","title":"3. Verify Installation","text":"<p>Test that everything is working correctly:</p> <pre><code># Check package version\nvirginia-clemm-poe --version\n\n# Test basic functionality\nvirginia-clemm-poe search \"claude\"\n\n# Run a complete health check\nvirginia-clemm-poe diagnose\n</code></pre>"},{"location":"chapter2-installation.html#configuration-options","title":"Configuration Options","text":""},{"location":"chapter2-installation.html#configuration-file-location","title":"Configuration File Location","text":"<p>The package stores configuration in: - Linux/macOS: <code>~/.config/virginia-clemm-poe/config.json</code> - Windows: <code>%APPDATA%\\virginia-clemm-poe\\config.json</code></p>"},{"location":"chapter2-installation.html#configuration-structure","title":"Configuration Structure","text":"<pre><code>{\n  \"api_key\": \"your_poe_api_key\",\n  \"browser\": {\n    \"headless\": true,\n    \"timeout\": 30000,\n    \"user_agent\": \"custom_user_agent\"\n  },\n  \"cache\": {\n    \"enabled\": true,\n    \"max_age\": 3600\n  },\n  \"logging\": {\n    \"level\": \"INFO\",\n    \"file\": \"~/.local/share/virginia-clemm-poe/logs/app.log\"\n  }\n}\n</code></pre>"},{"location":"chapter2-installation.html#environment-variables","title":"Environment Variables","text":"<p>The package respects these environment variables:</p> Variable Description Default <code>POE_API_KEY</code> Your Poe API key None (required) <code>VCP_HEADLESS</code> Run browser in headless mode <code>true</code> <code>VCP_TIMEOUT</code> Browser timeout in milliseconds <code>30000</code> <code>VCP_LOG_LEVEL</code> Logging level <code>INFO</code> <code>VCP_CACHE_DIR</code> Cache directory location Platform default"},{"location":"chapter2-installation.html#data-storage","title":"Data Storage","text":""},{"location":"chapter2-installation.html#default-locations","title":"Default Locations","text":"<p>The package stores data in platform-appropriate locations:</p> <p>Linux/macOS: - Data: <code>~/.local/share/virginia-clemm-poe/</code> - Config: <code>~/.config/virginia-clemm-poe/</code> - Cache: <code>~/.cache/virginia-clemm-poe/</code> - Logs: <code>~/.local/share/virginia-clemm-poe/logs/</code></p> <p>Windows: - Data: <code>%LOCALAPPDATA%\\virginia-clemm-poe\\</code> - Config: <code>%APPDATA%\\virginia-clemm-poe\\</code> - Cache: <code>%LOCALAPPDATA%\\virginia-clemm-poe\\cache\\</code> - Logs: <code>%LOCALAPPDATA%\\virginia-clemm-poe\\logs\\</code></p>"},{"location":"chapter2-installation.html#dataset-location","title":"Dataset Location","text":"<p>The main model dataset is stored as a JSON file: <pre><code>~/.local/share/virginia-clemm-poe/poe_models.json\n</code></pre></p>"},{"location":"chapter2-installation.html#troubleshooting-installation","title":"Troubleshooting Installation","text":""},{"location":"chapter2-installation.html#common-issues","title":"Common Issues","text":""},{"location":"chapter2-installation.html#1-python-version-error","title":"1. Python Version Error","text":"<p><pre><code>ERROR: Package requires Python 3.12+\n</code></pre> Solution: Upgrade your Python installation or use a version manager like <code>pyenv</code>.</p>"},{"location":"chapter2-installation.html#2-browser-setup-fails","title":"2. Browser Setup Fails","text":"<p><pre><code>ERROR: Failed to install browser dependencies\n</code></pre> Solutions: - Ensure you have internet connectivity - Run with elevated permissions if needed - Check disk space (browser download requires ~100MB)</p>"},{"location":"chapter2-installation.html#3-permission-errors","title":"3. Permission Errors","text":"<p><pre><code>ERROR: Permission denied writing to config directory\n</code></pre> Solutions: - Check file permissions on config directories - Run installation with appropriate user permissions - Manually create config directories if needed</p>"},{"location":"chapter2-installation.html#4-network-issues","title":"4. Network Issues","text":"<p><pre><code>ERROR: Unable to connect to Poe API\n</code></pre> Solutions: - Check internet connectivity - Verify API key is correct - Check if your network blocks API requests</p>"},{"location":"chapter2-installation.html#debug-installation","title":"Debug Installation","text":"<p>For detailed debugging during installation:</p> <pre><code># Enable verbose logging\nexport VCP_LOG_LEVEL=DEBUG\n\n# Run installation with debug output\nvirginia-clemm-poe setup --verbose\n\n# Check system compatibility\nvirginia-clemm-poe diagnose --full\n</code></pre>"},{"location":"chapter2-installation.html#upgrading","title":"Upgrading","text":""},{"location":"chapter2-installation.html#upgrade-package","title":"Upgrade Package","text":"<pre><code>pip install --upgrade virginia-clemm-poe\n</code></pre>"},{"location":"chapter2-installation.html#upgrade-browser-dependencies","title":"Upgrade Browser Dependencies","text":"<pre><code>virginia-clemm-poe setup --force\n</code></pre>"},{"location":"chapter2-installation.html#migrate-configuration","title":"Migrate Configuration","text":"<p>When upgrading from older versions, you may need to migrate configuration:</p> <pre><code>virginia-clemm-poe config migrate\n</code></pre>"},{"location":"chapter2-installation.html#uninstallation","title":"Uninstallation","text":""},{"location":"chapter2-installation.html#remove-package","title":"Remove Package","text":"<pre><code>pip uninstall virginia-clemm-poe\n</code></pre>"},{"location":"chapter2-installation.html#clean-up-data-optional","title":"Clean Up Data (Optional)","text":"<p>To remove all data and configuration files:</p> <pre><code># Remove data directories\nrm -rf ~/.local/share/virginia-clemm-poe\nrm -rf ~/.config/virginia-clemm-poe\nrm -rf ~/.cache/virginia-clemm-poe\n\n# On Windows, remove:\n# %LOCALAPPDATA%\\virginia-clemm-poe\n# %APPDATA%\\virginia-clemm-poe\n</code></pre>"},{"location":"chapter2-installation.html#next-steps","title":"Next Steps","text":"<p>With the package installed and configured, you're ready to:</p> <ol> <li>Follow the Quick Start Guide for basic usage</li> <li>Learn about the Python API for programmatic access</li> <li>Explore CLI Commands for command-line usage</li> </ol> <p>Performance Optimization</p> <p>For best performance, consider running the initial data update during off-peak hours as it involves scraping hundreds of model pages: <pre><code>POE_API_KEY=your_key virginia-clemm-poe update --all\n</code></pre></p>"},{"location":"chapter3-quickstart.html","title":"Chapter 3: Quick Start Guide","text":""},{"location":"chapter3-quickstart.html#your-first-5-minutes","title":"Your First 5 Minutes","text":"<p>This guide will get you up and running with Virginia Clemm Poe in just a few minutes. By the end, you'll have:</p> <ul> <li>\u2705 Installed and configured the package</li> <li>\u2705 Updated your local model dataset</li> <li>\u2705 Found and analyzed AI models</li> <li>\u2705 Used both Python API and CLI</li> </ul>"},{"location":"chapter3-quickstart.html#step-1-installation-and-setup","title":"Step 1: Installation and Setup","text":"<pre><code># Install the package\npip install virginia-clemm-poe\n\n# Set up browser for web scraping\nvirginia-clemm-poe setup\n\n# Set your Poe API key\nexport POE_API_KEY=\"your_poe_api_key_here\"\n</code></pre> <p>Get Your API Key</p> <p>Visit Poe.com \u2192 Settings \u2192 API to generate your free API key.</p>"},{"location":"chapter3-quickstart.html#step-2-initial-data-update","title":"Step 2: Initial Data Update","text":"<pre><code># Update model data with pricing information\nvirginia-clemm-poe update --pricing\n</code></pre> <p>This command will: - Fetch all models from the Poe API - Scrape pricing information from the website - Save the enriched dataset locally</p> <p>First Run</p> <p>The first update may take 5-10 minutes as it scrapes data for hundreds of models. Subsequent updates are much faster as they only update changed models.</p>"},{"location":"chapter3-quickstart.html#step-3-basic-cli-usage","title":"Step 3: Basic CLI Usage","text":""},{"location":"chapter3-quickstart.html#search-for-models","title":"Search for Models","text":"<pre><code># Find Claude models\nvirginia-clemm-poe search \"claude\"\n\n# Find GPT models\nvirginia-clemm-poe search \"gpt\"\n\n# Find models by capability\nvirginia-clemm-poe search \"image\"\n</code></pre>"},{"location":"chapter3-quickstart.html#list-all-models","title":"List All Models","text":"<pre><code># Show all available models\nvirginia-clemm-poe list\n\n# Show only models with pricing data\nvirginia-clemm-poe list --with-pricing\n\n# Show models in JSON format\nvirginia-clemm-poe list --format json\n</code></pre>"},{"location":"chapter3-quickstart.html#get-model-details","title":"Get Model Details","text":"<pre><code># Get detailed information about a specific model\nvirginia-clemm-poe info \"claude-3-opus\"\n</code></pre>"},{"location":"chapter3-quickstart.html#step-4-basic-python-api-usage","title":"Step 4: Basic Python API Usage","text":"<p>Create a Python script to explore the model data:</p> <pre><code># quick_start.py\nfrom virginia_clemm_poe import api\n\ndef main():\n    # Search for models\n    print(\"\ud83d\udd0d Searching for Claude models...\")\n    claude_models = api.search_models(query=\"claude\")\n    print(f\"Found {len(claude_models)} Claude models\")\n\n    # Get a specific model\n    print(\"\\n\ud83d\udcca Getting Claude 3 Opus details...\")\n    opus = api.get_model_by_id(\"claude-3-opus\")\n    if opus:\n        print(f\"Model: {opus.model_name}\")\n        print(f\"Description: {opus.description}\")\n        if opus.pricing:\n            input_cost = opus.pricing.details.get(\"Input (text)\", \"N/A\")\n            print(f\"Input cost: {input_cost}\")\n\n    # List all models with pricing\n    print(\"\\n\ud83d\udcb0 Models with pricing data...\")\n    models_with_pricing = api.list_models(with_pricing=True)\n    print(f\"Found {len(models_with_pricing)} models with pricing\")\n\n    # Find cheapest text model\n    print(\"\\n\ud83c\udfaf Finding cheapest text models...\")\n    text_models = [m for m in models_with_pricing \n                   if m.pricing and \"Input (text)\" in m.pricing.details]\n\n    if text_models:\n        # Sort by input cost (assuming cost is in format like \"$0.015 / 1k tokens\")\n        def extract_cost(model):\n            cost_str = model.pricing.details.get(\"Input (text)\", \"$999\")\n            # Simple extraction - in real use, you'd want more robust parsing\n            try:\n                return float(cost_str.replace(\"$\", \"\").split()[0])\n            except:\n                return 999.0\n\n        cheapest = min(text_models, key=extract_cost)\n        print(f\"Cheapest: {cheapest.model_name}\")\n        print(f\"Cost: {cheapest.pricing.details['Input (text)']}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Run the script: <pre><code>python quick_start.py\n</code></pre></p>"},{"location":"chapter3-quickstart.html#common-use-cases","title":"Common Use Cases","text":""},{"location":"chapter3-quickstart.html#use-case-1-find-models-by-price-range","title":"Use Case 1: Find Models by Price Range","text":"<pre><code>from virginia_clemm_poe import api\n\ndef find_affordable_models(max_cost=0.01):\n    \"\"\"Find models under a certain cost threshold.\"\"\"\n    models = api.list_models(with_pricing=True)\n    affordable = []\n\n    for model in models:\n        if model.pricing and \"Input (text)\" in model.pricing.details:\n            cost_str = model.pricing.details[\"Input (text)\"]\n            # Extract numeric cost (simplified)\n            try:\n                cost = float(cost_str.replace(\"$\", \"\").split()[0])\n                if cost &lt;= max_cost:\n                    affordable.append((model.model_name, cost))\n            except:\n                continue\n\n    return sorted(affordable, key=lambda x: x[1])\n\n# Find models under $0.01 per 1k tokens\ncheap_models = find_affordable_models(0.01)\nfor name, cost in cheap_models[:5]:\n    print(f\"{name}: ${cost}\")\n</code></pre>"},{"location":"chapter3-quickstart.html#use-case-2-compare-model-capabilities","title":"Use Case 2: Compare Model Capabilities","text":"<pre><code>from virginia_clemm_poe import api\n\ndef compare_models(model_ids):\n    \"\"\"Compare multiple models side by side.\"\"\"\n    models = [api.get_model_by_id(mid) for mid in model_ids]\n\n    print(f\"{'Model':&lt;20} {'Input Cost':&lt;15} {'Output Cost':&lt;15}\")\n    print(\"-\" * 50)\n\n    for model in models:\n        if model and model.pricing:\n            input_cost = model.pricing.details.get(\"Input (text)\", \"N/A\")\n            output_cost = model.pricing.details.get(\"Bot message\", \"N/A\")\n            print(f\"{model.model_name:&lt;20} {input_cost:&lt;15} {output_cost:&lt;15}\")\n\n# Compare popular models\ncompare_models([\n    \"claude-3-opus\", \n    \"gpt-4\", \n    \"claude-3-sonnet\"\n])\n</code></pre>"},{"location":"chapter3-quickstart.html#use-case-3-monitor-model-availability","title":"Use Case 3: Monitor Model Availability","text":"<pre><code>#!/bin/bash\n# monitor_models.sh - Check if specific models are available\n\nmodels=(\"claude-3-opus\" \"gpt-4\" \"gemini-pro\")\n\nfor model in \"${models[@]}\"; do\n    echo \"Checking $model...\"\n    virginia-clemm-poe info \"$model\" &gt; /dev/null 2&gt;&amp;1\n    if [ $? -eq 0 ]; then\n        echo \"\u2705 $model is available\"\n    else\n        echo \"\u274c $model is not available\"\n    fi\ndone\n</code></pre>"},{"location":"chapter3-quickstart.html#cli-workflow-examples","title":"CLI Workflow Examples","text":""},{"location":"chapter3-quickstart.html#daily-update-routine","title":"Daily Update Routine","text":"<pre><code>#!/bin/bash\n# daily_update.sh - Daily model data maintenance\n\necho \"\ud83d\udd04 Starting daily update...\"\n\n# Update models that might have changed\nvirginia-clemm-poe update --pricing --changed-only\n\n# Check for new models\nvirginia-clemm-poe update --new-only\n\n# Generate a summary report\nvirginia-clemm-poe stats\n\necho \"\u2705 Daily update complete\"\n</code></pre>"},{"location":"chapter3-quickstart.html#research-workflow","title":"Research Workflow","text":"<pre><code># 1. Update dataset\nvirginia-clemm-poe update --all\n\n# 2. Search for specific capabilities\nvirginia-clemm-poe search \"vision\" &gt; vision_models.txt\nvirginia-clemm-poe search \"code\" &gt; coding_models.txt\n\n# 3. Get detailed pricing for interesting models\nvirginia-clemm-poe info \"claude-3-opus\" --format json &gt; opus_details.json\nvirginia-clemm-poe info \"gpt-4-vision\" --format json &gt; gpt4v_details.json\n\n# 4. Generate comparison report\nvirginia-clemm-poe compare \"claude-3-opus\" \"gpt-4\" --output report.html\n</code></pre>"},{"location":"chapter3-quickstart.html#integration-examples","title":"Integration Examples","text":""},{"location":"chapter3-quickstart.html#jupyter-notebook-integration","title":"Jupyter Notebook Integration","text":"<pre><code># In Jupyter notebook\nimport pandas as pd\nfrom virginia_clemm_poe import api\n\n# Load all models into a DataFrame\nmodels = api.list_models(with_pricing=True)\ndf = pd.DataFrame([\n    {\n        'name': m.model_name,\n        'provider': m.bot_info.creator if m.bot_info else 'Unknown',\n        'input_cost': m.pricing.details.get('Input (text)', 'N/A') if m.pricing else 'N/A',\n        'description': m.description[:100] + '...' if len(m.description) &gt; 100 else m.description\n    }\n    for m in models\n])\n\n# Analyze the data\nprint(f\"Total models: {len(df)}\")\nprint(f\"Unique providers: {df['provider'].nunique()}\")\ndf.head()\n</code></pre>"},{"location":"chapter3-quickstart.html#fastapi-integration","title":"FastAPI Integration","text":"<pre><code>from fastapi import FastAPI\nfrom virginia_clemm_poe import api\n\napp = FastAPI()\n\n@app.get(\"/models/search/{query}\")\ndef search_models(query: str):\n    \"\"\"Search for models matching the query.\"\"\"\n    models = api.search_models(query=query)\n    return {\"query\": query, \"count\": len(models), \"models\": models}\n\n@app.get(\"/models/{model_id}\")\ndef get_model(model_id: str):\n    \"\"\"Get detailed information about a specific model.\"\"\"\n    model = api.get_model_by_id(model_id)\n    if not model:\n        return {\"error\": \"Model not found\"}\n    return model\n\n@app.get(\"/stats\")\ndef get_stats():\n    \"\"\"Get statistics about the model dataset.\"\"\"\n    all_models = api.list_models()\n    with_pricing = api.list_models(with_pricing=True)\n\n    return {\n        \"total_models\": len(all_models),\n        \"models_with_pricing\": len(with_pricing),\n        \"coverage\": len(with_pricing) / len(all_models) * 100\n    }\n</code></pre>"},{"location":"chapter3-quickstart.html#next-steps","title":"Next Steps","text":"<p>Now that you've got the basics down, explore:</p> <ol> <li>Python API Reference - Complete API documentation</li> <li>CLI Commands - All available command-line options</li> <li>Data Models - Understanding the data structures</li> <li>Configuration - Advanced configuration options</li> </ol>"},{"location":"chapter3-quickstart.html#quick-reference","title":"Quick Reference","text":""},{"location":"chapter3-quickstart.html#essential-commands","title":"Essential Commands","text":"<pre><code># Setup\nvirginia-clemm-poe setup\nvirginia-clemm-poe update --pricing\n\n# Search and explore\nvirginia-clemm-poe search \"query\"\nvirginia-clemm-poe list --with-pricing\nvirginia-clemm-poe info \"model-id\"\n\n# Maintenance\nvirginia-clemm-poe update --changed-only\nvirginia-clemm-poe stats\nvirginia-clemm-poe diagnose\n</code></pre>"},{"location":"chapter3-quickstart.html#essential-python-imports","title":"Essential Python Imports","text":"<pre><code>from virginia_clemm_poe import api\nfrom virginia_clemm_poe.models import PoeModel, Pricing, BotInfo\n</code></pre> <p>Performance Tips</p> <ul> <li>Use <code>--changed-only</code> for faster updates</li> <li>Cache search results for repeated queries</li> <li>Use <code>--format json</code> for programmatic processing</li> <li>Monitor logs with <code>--verbose</code> for debugging</li> </ul>"},{"location":"chapter4-api.html","title":"Chapter 4: Python API Reference","text":""},{"location":"chapter4-api.html#overview","title":"Overview","text":"<p>The Virginia Clemm Poe Python API provides programmatic access to comprehensive Poe.com model data. The API is designed for simplicity and performance, with intelligent caching and type safety through Pydantic models.</p>"},{"location":"chapter4-api.html#core-functions","title":"Core Functions","text":""},{"location":"chapter4-api.html#data-loading-and-management","title":"Data Loading and Management","text":""},{"location":"chapter4-api.html#load_modelsforce_reload-bool-false-modelcollection","title":"<code>load_models(force_reload: bool = False) -&gt; ModelCollection</code>","text":"<p>The foundational function that loads the complete Poe model dataset from the local JSON file.</p> <pre><code>from virginia_clemm_poe import api\n\n# Standard usage (cached)\ncollection = api.load_models()\nprint(f\"Loaded {len(collection.data)} models\")\n\n# Force reload after external update\ncollection = api.load_models(force_reload=True)\n</code></pre> <p>Parameters: - <code>force_reload</code> (bool): If True, bypasses cache and reloads from file</p> <p>Returns: - <code>ModelCollection</code>: Container with all model data and search capabilities</p> <p>Performance: - First call: ~50-200ms (file I/O + JSON parsing) - Cached calls: &lt;1ms (in-memory access) - Memory usage: ~2-5MB for typical dataset</p>"},{"location":"chapter4-api.html#reload_models-modelcollection","title":"<code>reload_models() -&gt; ModelCollection</code>","text":"<p>Convenience function to force reload models from disk, bypassing cache.</p> <pre><code># After external update\nfresh_collection = api.reload_models()\n</code></pre>"},{"location":"chapter4-api.html#model-retrieval","title":"Model Retrieval","text":""},{"location":"chapter4-api.html#get_all_models-listpoemodel","title":"<code>get_all_models() -&gt; list[PoeModel]</code>","text":"<p>Retrieves the complete list of models without any filtering.</p> <pre><code># Get all models\nmodels = api.get_all_models()\nprint(f\"Total models: {len(models)}\")\n\n# Analyze by provider\nby_owner = {}\nfor model in models:\n    owner = model.owned_by\n    by_owner.setdefault(owner, []).append(model)\n\nfor owner, owner_models in sorted(by_owner.items()):\n    print(f\"{owner}: {len(owner_models)} models\")\n</code></pre> <p>Returns: - <code>list[PoeModel]</code>: Complete list of models with full metadata</p>"},{"location":"chapter4-api.html#get_model_by_idmodel_id-str-poemodel-none","title":"<code>get_model_by_id(model_id: str) -&gt; PoeModel | None</code>","text":"<p>Fast, exact-match lookup for a specific model by ID.</p> <pre><code># Get specific model\nmodel = api.get_model_by_id(\"Claude-3-Opus\")\nif model:\n    print(f\"Found: {model.model_name}\")\n    if model.pricing:\n        print(f\"Input cost: {model.pricing.details.get('Input (text)', 'N/A')}\")\nelse:\n    print(\"Model not found\")\n</code></pre> <p>Parameters: - <code>model_id</code> (str): Exact model ID (case-sensitive)</p> <p>Returns: - <code>PoeModel | None</code>: The matching model or None if not found</p> <p>Performance: - Lookup time: &lt;1ms (uses internal dictionary mapping)</p>"},{"location":"chapter4-api.html#model-search-and-filtering","title":"Model Search and Filtering","text":""},{"location":"chapter4-api.html#search_modelsquery-str-listpoemodel","title":"<code>search_models(query: str) -&gt; list[PoeModel]</code>","text":"<p>Case-insensitive search across model IDs and names.</p> <pre><code># Find Claude models\nclaude_models = api.search_models(\"claude\")\nprint(f\"Found {len(claude_models)} Claude models\")\n\n# Find models by capability\nvision_models = api.search_models(\"vision\")\ncoding_models = api.search_models(\"code\")\n</code></pre> <p>Parameters: - <code>query</code> (str): Search term (case-insensitive)</p> <p>Returns: - <code>list[PoeModel]</code>: Matching models sorted by ID</p>"},{"location":"chapter4-api.html#get_models_with_pricing-listpoemodel","title":"<code>get_models_with_pricing() -&gt; list[PoeModel]</code>","text":"<p>Get all models that have valid pricing information.</p> <pre><code># Get models with pricing for cost analysis\npriced_models = api.get_models_with_pricing()\nprint(f\"Models with pricing: {len(priced_models)}\")\n\n# Find affordable models\nbudget_models = [\n    m for m in priced_models \n    if m.pricing and \"Input (text)\" in m.pricing.details\n]\n</code></pre> <p>Returns: - <code>list[PoeModel]</code>: Models with valid pricing data</p>"},{"location":"chapter4-api.html#get_models_needing_update-listpoemodel","title":"<code>get_models_needing_update() -&gt; list[PoeModel]</code>","text":"<p>Identify models that need pricing information updated.</p> <pre><code># Check data completeness\nneed_update = api.get_models_needing_update()\nall_models = api.get_all_models()\n\ncompletion_rate = (len(all_models) - len(need_update)) / len(all_models) * 100\nprint(f\"Data completion: {completion_rate:.1f}%\")\n</code></pre> <p>Returns: - <code>list[PoeModel]</code>: Models requiring data updates</p>"},{"location":"chapter4-api.html#data-models","title":"Data Models","text":""},{"location":"chapter4-api.html#poemodel","title":"PoeModel","text":"<p>The core model representing a Poe.com AI model.</p> <pre><code>from virginia_clemm_poe.models import PoeModel\n\n# Access model properties\nmodel = api.get_model_by_id(\"Claude-3-Opus\")\nif model:\n    print(f\"ID: {model.id}\")\n    print(f\"Name: {model.model_name}\")\n    print(f\"Owner: {model.owned_by}\")\n    print(f\"Created: {model.created}\")\n    print(f\"Description: {model.description}\")\n</code></pre> <p>Key Properties: - <code>id: str</code> - Unique model identifier - <code>model_name: str</code> - Display name - <code>owned_by: str</code> - Model provider/owner - <code>created: str</code> - Creation timestamp - <code>description: str</code> - Model description - <code>architecture: Architecture</code> - Input/output capabilities - <code>pricing: Pricing | None</code> - Cost information - <code>bot_info: BotInfo | None</code> - Creator and metadata - <code>pricing_error: str | None</code> - Error message if scraping failed</p> <p>Utility Methods: <pre><code># Check if model has pricing data\nif model.has_pricing():\n    print(\"Pricing available\")\n\n# Check if model needs update\nif model.needs_pricing_update():\n    print(\"Needs pricing update\")\n</code></pre></p>"},{"location":"chapter4-api.html#pricing","title":"Pricing","text":"<p>Contains cost information for a model.</p> <pre><code>if model.pricing:\n    # Access pricing details\n    details = model.pricing.details\n    input_cost = details.get(\"Input (text)\", \"N/A\")\n    output_cost = details.get(\"Bot message\", \"N/A\")\n\n    print(f\"Input: {input_cost}\")\n    print(f\"Output: {output_cost}\")\n    print(f\"Last checked: {model.pricing.checked_at}\")\n</code></pre> <p>Properties: - <code>details: dict[str, str]</code> - Cost breakdown - <code>checked_at: datetime</code> - Last update timestamp</p> <p>Common Pricing Fields: - <code>\"Input (text)\"</code> - Cost per text input - <code>\"Input (image)\"</code> - Cost per image input - <code>\"Bot message\"</code> - Cost per output message - <code>\"Chat history loaded\"</code> - History loading cost - <code>\"Cache discount\"</code> - Caching discount rate</p>"},{"location":"chapter4-api.html#botinfo","title":"BotInfo","text":"<p>Creator and description metadata.</p> <pre><code>if model.bot_info:\n    print(f\"Creator: {model.bot_info.creator}\")\n    print(f\"Description: {model.bot_info.description}\")\n    if model.bot_info.description_extra:\n        print(f\"Extra info: {model.bot_info.description_extra}\")\n</code></pre> <p>Properties: - <code>creator: str</code> - Bot creator handle - <code>description: str</code> - Main description - <code>description_extra: str | None</code> - Additional details</p>"},{"location":"chapter4-api.html#architecture","title":"Architecture","text":"<p>Model capability information.</p> <pre><code>arch = model.architecture\nprint(f\"Input types: {arch.input_modalities}\")\nprint(f\"Output types: {arch.output_modalities}\")\nprint(f\"Modality: {arch.modality}\")\n</code></pre> <p>Properties: - <code>input_modalities: list[str]</code> - Supported inputs - <code>output_modalities: list[str]</code> - Supported outputs - <code>modality: str</code> - Primary mode description</p>"},{"location":"chapter4-api.html#advanced-usage-examples","title":"Advanced Usage Examples","text":""},{"location":"chapter4-api.html#cost-analysis","title":"Cost Analysis","text":"<pre><code>def analyze_costs():\n    \"\"\"Analyze model costs across providers.\"\"\"\n    models = api.get_models_with_pricing()\n\n    # Group by provider\n    by_provider = {}\n    for model in models:\n        provider = model.owned_by\n        by_provider.setdefault(provider, []).append(model)\n\n    # Calculate average costs\n    for provider, provider_models in by_provider.items():\n        costs = []\n        for model in provider_models:\n            if model.pricing and \"Input (text)\" in model.pricing.details:\n                cost_str = model.pricing.details[\"Input (text)\"]\n                # Extract numeric cost (simplified parsing)\n                try:\n                    cost = float(cost_str.replace(\"$\", \"\").split()[0])\n                    costs.append(cost)\n                except:\n                    continue\n\n        if costs:\n            avg_cost = sum(costs) / len(costs)\n            print(f\"{provider}: ${avg_cost:.4f} average\")\n\nanalyze_costs()\n</code></pre>"},{"location":"chapter4-api.html#model-comparison","title":"Model Comparison","text":"<pre><code>def compare_models(model_ids: list[str]):\n    \"\"\"Compare multiple models side by side.\"\"\"\n    models = [api.get_model_by_id(mid) for mid in model_ids]\n    models = [m for m in models if m is not None]\n\n    print(f\"{'Model':&lt;25} {'Provider':&lt;15} {'Input Cost':&lt;15}\")\n    print(\"-\" * 55)\n\n    for model in models:\n        provider = model.owned_by\n        if model.pricing and \"Input (text)\" in model.pricing.details:\n            cost = model.pricing.details[\"Input (text)\"]\n        else:\n            cost = \"N/A\"\n\n        print(f\"{model.model_name:&lt;25} {provider:&lt;15} {cost:&lt;15}\")\n\n# Compare popular models\ncompare_models([\n    \"Claude-3-Opus\",\n    \"Claude-3-Sonnet\", \n    \"GPT-4\",\n    \"GPT-4-Turbo\"\n])\n</code></pre>"},{"location":"chapter4-api.html#data-quality-monitoring","title":"Data Quality Monitoring","text":"<pre><code>def check_data_quality():\n    \"\"\"Monitor data quality and coverage.\"\"\"\n    all_models = api.get_all_models()\n    priced_models = api.get_models_with_pricing()\n    need_update = api.get_models_needing_update()\n\n    print(f\"\ud83d\udcca Data Quality Report\")\n    print(f\"Total models: {len(all_models)}\")\n    print(f\"With pricing: {len(priced_models)}\")\n    print(f\"Need update: {len(need_update)}\")\n\n    # Coverage percentage\n    coverage = len(priced_models) / len(all_models) * 100 if all_models else 0\n    print(f\"Coverage: {coverage:.1f}%\")\n\n    # Error analysis\n    errors = [m for m in all_models if m.pricing_error]\n    if errors:\n        print(f\"Models with errors: {len(errors)}\")\n        error_types = {}\n        for model in errors:\n            error = model.pricing_error or \"Unknown\"\n            error_types[error] = error_types.get(error, 0) + 1\n\n        for error, count in sorted(error_types.items()):\n            print(f\"  {error}: {count}\")\n\ncheck_data_quality()\n</code></pre>"},{"location":"chapter4-api.html#real-time-monitoring","title":"Real-time Monitoring","text":"<pre><code>import time\nfrom pathlib import Path\n\ndef monitor_updates(interval: int = 60):\n    \"\"\"Monitor for data file changes and reload automatically.\"\"\"\n    from virginia_clemm_poe.config import DATA_FILE_PATH\n\n    if not DATA_FILE_PATH.exists():\n        print(\"Data file not found. Run update first.\")\n        return\n\n    last_modified = DATA_FILE_PATH.stat().st_mtime\n    print(f\"Monitoring {DATA_FILE_PATH} for changes...\")\n\n    while True:\n        try:\n            current_modified = DATA_FILE_PATH.stat().st_mtime\n            if current_modified &gt; last_modified:\n                print(\"\ud83d\udcca Data file updated, reloading...\")\n                collection = api.reload_models()\n                print(f\"\u2705 Reloaded {len(collection.data)} models\")\n                last_modified = current_modified\n\n            time.sleep(interval)\n        except KeyboardInterrupt:\n            print(\"Monitoring stopped.\")\n            break\n        except Exception as e:\n            print(f\"Error: {e}\")\n            time.sleep(interval)\n\n# Start monitoring\n# monitor_updates(60)  # Check every minute\n</code></pre>"},{"location":"chapter4-api.html#error-handling","title":"Error Handling","text":""},{"location":"chapter4-api.html#common-error-patterns","title":"Common Error Patterns","text":"<pre><code>def safe_model_access(model_id: str):\n    \"\"\"Safely access model data with comprehensive error handling.\"\"\"\n    try:\n        # Load models\n        collection = api.load_models()\n        if not collection.data:\n            print(\"No data available. Run 'virginia-clemm-poe update'\")\n            return None\n\n        # Get specific model\n        model = api.get_model_by_id(model_id)\n        if not model:\n            print(f\"Model '{model_id}' not found\")\n            # Try fuzzy search\n            results = api.search_models(model_id.lower())\n            if results:\n                print(f\"Similar models: {[m.id for m in results[:3]]}\")\n            return None\n\n        # Access pricing safely\n        if model.pricing:\n            return model\n        elif model.pricing_error:\n            print(f\"Pricing error: {model.pricing_error}\")\n            return model\n        else:\n            print(\"No pricing data available\")\n            return model\n\n    except FileNotFoundError:\n        print(\"Data file missing. Run 'virginia-clemm-poe update --all'\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return None\n</code></pre>"},{"location":"chapter4-api.html#data-validation","title":"Data Validation","text":"<pre><code>def validate_model_data(model: PoeModel) -&gt; bool:\n    \"\"\"Validate model data completeness.\"\"\"\n    issues = []\n\n    if not model.id:\n        issues.append(\"Missing model ID\")\n\n    if not model.model_name:\n        issues.append(\"Missing model name\")\n\n    if not model.owned_by:\n        issues.append(\"Missing owner information\")\n\n    if model.pricing is None and model.pricing_error is None:\n        issues.append(\"No pricing data or error information\")\n\n    if issues:\n        print(f\"Validation issues for {model.id}: {', '.join(issues)}\")\n        return False\n\n    return True\n\n# Validate all models\nmodels = api.get_all_models()\nvalid_models = [m for m in models if validate_model_data(m)]\nprint(f\"Valid models: {len(valid_models)}/{len(models)}\")\n</code></pre>"},{"location":"chapter4-api.html#best-practices","title":"Best Practices","text":""},{"location":"chapter4-api.html#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Use Caching: Don't call <code>reload_models()</code> unnecessarily</li> <li>Exact Lookups: Use <code>get_model_by_id()</code> for known IDs instead of search</li> <li>Batch Operations: Process multiple models in single loops</li> <li>Filter Early: Use specific functions like <code>get_models_with_pricing()</code></li> </ol>"},{"location":"chapter4-api.html#data-freshness","title":"Data Freshness","text":"<ol> <li>Check Timestamps: Monitor <code>pricing.checked_at</code> for data age</li> <li>Reload After Updates: Call <code>reload_models()</code> after external updates</li> <li>Monitor Coverage: Use <code>get_models_needing_update()</code> for quality checks</li> </ol>"},{"location":"chapter4-api.html#error-resilience","title":"Error Resilience","text":"<ol> <li>Check for None: Always verify pricing and bot_info existence</li> <li>Handle Missing Data: Gracefully handle missing models</li> <li>Validate Assumptions: Don't assume specific pricing fields exist</li> </ol>"},{"location":"chapter4-api.html#integration-patterns","title":"Integration Patterns","text":""},{"location":"chapter4-api.html#with-data-analysis-libraries","title":"With Data Analysis Libraries","text":"<pre><code>import pandas as pd\n\ndef models_to_dataframe():\n    \"\"\"Convert model data to pandas DataFrame for analysis.\"\"\"\n    models = api.get_models_with_pricing()\n\n    data = []\n    for model in models:\n        row = {\n            'id': model.id,\n            'name': model.model_name,\n            'provider': model.owned_by,\n            'created': model.created,\n        }\n\n        if model.pricing:\n            row['input_cost'] = model.pricing.details.get('Input (text)', None)\n            row['output_cost'] = model.pricing.details.get('Bot message', None)\n            row['pricing_date'] = model.pricing.checked_at\n\n        if model.bot_info:\n            row['creator'] = model.bot_info.creator\n\n        data.append(row)\n\n    return pd.DataFrame(data)\n\n# Create DataFrame for analysis\ndf = models_to_dataframe()\nprint(df.head())\n</code></pre>"},{"location":"chapter4-api.html#with-web-frameworks","title":"With Web Frameworks","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom virginia_clemm_poe import api\n\napp = FastAPI()\n\n@app.get(\"/models\")\ndef list_models(with_pricing: bool = False):\n    \"\"\"API endpoint to list models.\"\"\"\n    if with_pricing:\n        models = api.get_models_with_pricing()\n    else:\n        models = api.get_all_models()\n\n    return {\n        \"count\": len(models),\n        \"models\": [{\"id\": m.id, \"name\": m.model_name} for m in models]\n    }\n\n@app.get(\"/models/{model_id}\")\ndef get_model(model_id: str):\n    \"\"\"API endpoint to get specific model.\"\"\"\n    model = api.get_model_by_id(model_id)\n    if not model:\n        raise HTTPException(status_code=404, detail=\"Model not found\")\n\n    return model.dict()\n</code></pre> <p>This comprehensive API reference provides everything you need to integrate Virginia Clemm Poe into your Python applications efficiently and reliably.</p>"},{"location":"chapter5-cli.html","title":"Chapter 5: CLI Usage and Commands","text":""},{"location":"chapter5-cli.html#overview","title":"Overview","text":"<p>Virginia Clemm Poe provides a comprehensive command-line interface built with Python Fire and Rich for beautiful terminal output. The CLI is designed for both interactive exploration and automation workflows.</p>"},{"location":"chapter5-cli.html#command-structure","title":"Command Structure","text":"<p>All commands follow the pattern: <pre><code>virginia-clemm-poe &lt;command&gt; [options]\n</code></pre></p> <p>Get help for any command: <pre><code>virginia-clemm-poe &lt;command&gt; --help\n</code></pre></p>"},{"location":"chapter5-cli.html#core-commands","title":"Core Commands","text":""},{"location":"chapter5-cli.html#setup-and-configuration","title":"Setup and Configuration","text":""},{"location":"chapter5-cli.html#setup","title":"<code>setup</code>","text":"<p>Set up Chrome browser for web scraping - required before first update.</p> <pre><code># Basic setup (recommended)\nvirginia-clemm-poe setup\n\n# Troubleshooting setup with verbose output\nvirginia-clemm-poe setup --verbose\n</code></pre> <p>What it does: - Detects existing Chrome/Chromium installations - Downloads Chrome for Testing if needed (~200MB) - Configures browser automation with DevTools Protocol - Verifies browser can launch successfully</p> <p>System requirements: - Available disk space: ~200MB - Network access for browser download - Write permissions to cache directory</p> <p>Installation locations: - macOS: <code>~/Library/Caches/virginia-clemm-poe/</code> - Linux: <code>~/.cache/virginia-clemm-poe/</code> - Windows: <code>%LOCALAPPDATA%\\virginia-clemm-poe\\</code></p>"},{"location":"chapter5-cli.html#status","title":"<code>status</code>","text":"<p>Check system health and data freshness.</p> <pre><code># Quick health check\nvirginia-clemm-poe status\n\n# Detailed system diagnosis\nvirginia-clemm-poe status --verbose\n</code></pre> <p>Checks performed: - \u2705 Browser installation and accessibility - \u2705 Model dataset existence and freshness - \u2705 POE_API_KEY environment variable - \u2705 System dependencies</p> <p>Sample output: <pre><code>Virginia Clemm Poe Status\n\nBrowser Status:\n\u2713 Browser is ready\n  Path: /Users/user/.cache/virginia-clemm-poe/chrome-mac/chrome\n  User Data: /Users/user/.cache/virginia-clemm-poe/user-data\n\nData Status:\n\u2713 Model data found\n  Path: ~/.local/share/virginia-clemm-poe/poe_models.json\n  Total models: 244\n  With pricing: 239\n  With bot info: 235\n  Data is 2 days old\n\nAPI Key Status:\n\u2713 POE_API_KEY is set\n</code></pre></p>"},{"location":"chapter5-cli.html#doctor","title":"<code>doctor</code>","text":"<p>Comprehensive diagnostic tool for troubleshooting.</p> <pre><code># Run all diagnostic checks\nvirginia-clemm-poe doctor\n\n# Verbose diagnosis for support requests\nvirginia-clemm-poe doctor --verbose\n</code></pre> <p>Diagnostic checks: 1. Python Version: Ensures Python 3.12+ compatibility 2. API Key: Validates POE_API_KEY and tests connectivity 3. Browser: Verifies browser installation and launch capability 4. Network: Tests connectivity to poe.com 5. Dependencies: Checks all required packages 6. Data File: Validates JSON structure and content</p> <p>Exit codes: - <code>0</code>: All checks passed - <code>1</code>: Issues found that need attention</p>"},{"location":"chapter5-cli.html#data-management","title":"Data Management","text":""},{"location":"chapter5-cli.html#update","title":"<code>update</code>","text":"<p>Fetch latest model data from Poe - run weekly or when new models appear.</p> <pre><code># Update all data (default)\nPOE_API_KEY=your_key virginia-clemm-poe update\n\n# Update only pricing information\nvirginia-clemm-poe update --pricing\n\n# Update only bot information (faster)\nvirginia-clemm-poe update --info\n\n# Force update all models\nvirginia-clemm-poe update --force\n\n# Use custom API key\nvirginia-clemm-poe update --api_key your_key\n\n# Debug port conflicts\nvirginia-clemm-poe update --debug_port 9223\n\n# Troubleshooting with verbose output\nvirginia-clemm-poe update --verbose\n</code></pre> <p>Update process: 1. Fetches all models from Poe API 2. Launches Chrome for web scraping 3. Visits each model's page to extract pricing and metadata 4. Saves enriched dataset to local JSON file</p> <p>Parameters: - <code>--info</code>: Update only bot information - <code>--pricing</code>: Update only pricing information - <code>--all</code>: Update both (default) - <code>--force</code>: Update even models with existing data - <code>--api_key</code>: Override POE_API_KEY environment variable - <code>--debug_port</code>: Chrome DevTools port (default: 9222) - <code>--verbose</code>: Enable detailed logging</p> <p>Performance: - Full update: 5-15 minutes for ~240 models - Partial updates: 1-5 minutes depending on changes - Incremental: Only updates models missing data</p>"},{"location":"chapter5-cli.html#clear-cache","title":"<code>clear-cache</code>","text":"<p>Clear cache and stored data.</p> <pre><code># Clear all cache (default)\nvirginia-clemm-poe clear-cache\n\n# Clear only model data\nvirginia-clemm-poe clear-cache --data\n\n# Clear only browser cache\nvirginia-clemm-poe clear-cache --browser\n\n# Verbose cache clearing\nvirginia-clemm-poe clear-cache --verbose\n</code></pre> <p>Cache types: - Model data: Local JSON dataset - Browser cache: Chrome user data and profiles</p>"},{"location":"chapter5-cli.html#cache","title":"<code>cache</code>","text":"<p>Monitor cache performance and statistics.</p> <pre><code># Show cache statistics\nvirginia-clemm-poe cache\n\n# Clear all caches\nvirginia-clemm-poe cache --clear\n\n# Verbose cache management\nvirginia-clemm-poe cache --verbose\n</code></pre> <p>Statistics shown: - Cache hit rates and miss rates - Total requests and performance - Memory usage and evictions - Expired entry cleanups</p>"},{"location":"chapter5-cli.html#data-query-commands","title":"Data Query Commands","text":""},{"location":"chapter5-cli.html#search","title":"<code>search</code>","text":"<p>Find models by name or ID - primary discovery command.</p> <pre><code># Find Claude models\nvirginia-clemm-poe search claude\n\n# Find GPT models with bot info\nvirginia-clemm-poe search gpt --show_bot_info\n\n# Search without pricing data\nvirginia-clemm-poe search vision --no-show_pricing\n\n# Verbose search for debugging\nvirginia-clemm-poe search claude --verbose\n</code></pre> <p>Search features: - Case-insensitive substring matching - Searches both model IDs and names - Fuzzy matching for partial terms - Formatted table output with Rich</p> <p>Parameters: - <code>query</code>: Search term (required) - <code>--show_pricing</code>: Display pricing columns (default: True) - <code>--show_bot_info</code>: Include creator and description (default: False) - <code>--verbose</code>: Enable detailed logging</p> <p>Sample output: <pre><code>                Models matching 'claude'                \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 ID              \u2503 Created    \u2503 Input \u2503 Output \u2503 Pricing             \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 Claude-3-Opus   \u2502 2024-02-29 \u2502 text  \u2502 text   \u2502 15 points/message  \u2502\n\u2502 Claude-3-Sonnet \u2502 2024-03-04 \u2502 text  \u2502 text   \u2502 10 points/message  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nFound 2 models\n</code></pre></p>"},{"location":"chapter5-cli.html#list","title":"<code>list</code>","text":"<p>List all available models with summary statistics.</p> <pre><code># Show model summary\nvirginia-clemm-poe list\n\n# Show only models with pricing\nvirginia-clemm-poe list --with_pricing\n\n# Limit results\nvirginia-clemm-poe list --limit 10\n\n# Verbose listing\nvirginia-clemm-poe list --verbose\n</code></pre> <p>Parameters: - <code>--with_pricing</code>: Filter to models with pricing data - <code>--limit</code>: Maximum number of models to show - <code>--verbose</code>: Enable detailed logging</p> <p>Sample output: <pre><code>          Poe Models Summary           \n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Total Models \u2503 With Pricing \u2503 Need Update \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 244          \u2502 239          \u2502 5           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nShowing 244 models:\n\u2713 Claude-3-Opus\n\u2713 Claude-3-Sonnet\n\u2717 NewModel-Beta\n...\n</code></pre></p>"},{"location":"chapter5-cli.html#environment-variables","title":"Environment Variables","text":"<p>The CLI respects these environment variables:</p> Variable Description Default <code>POE_API_KEY</code> Your Poe API key (required) None <code>VCP_HEADLESS</code> Run browser in headless mode <code>true</code> <code>VCP_TIMEOUT</code> Browser timeout in milliseconds <code>30000</code> <code>VCP_LOG_LEVEL</code> Logging level (DEBUG, INFO, WARNING, ERROR) <code>INFO</code> <code>VCP_CACHE_DIR</code> Cache directory location Platform default <p>Example configuration: <pre><code>export POE_API_KEY=\"your_poe_api_key_here\"\nexport VCP_LOG_LEVEL=\"DEBUG\"\nexport VCP_TIMEOUT=\"60000\"\nvirginia-clemm-poe update --verbose\n</code></pre></p>"},{"location":"chapter5-cli.html#common-workflows","title":"Common Workflows","text":""},{"location":"chapter5-cli.html#initial-setup-workflow","title":"Initial Setup Workflow","text":"<pre><code># 1. Install package\npip install virginia-clemm-poe\n\n# 2. Set up browser\nvirginia-clemm-poe setup\n\n# 3. Set API key\nexport POE_API_KEY=\"your_api_key_here\"\n\n# 4. Verify configuration\nvirginia-clemm-poe status\n\n# 5. Fetch initial data\nvirginia-clemm-poe update\n\n# 6. Search for models\nvirginia-clemm-poe search claude\n</code></pre>"},{"location":"chapter5-cli.html#daily-maintenance-workflow","title":"Daily Maintenance Workflow","text":"<pre><code># Check system health\nvirginia-clemm-poe status\n\n# Update changed models only (fast)\nvirginia-clemm-poe update --pricing\n\n# Search for new models\nvirginia-clemm-poe search \"new\"\n\n# Check data coverage\nvirginia-clemm-poe list\n</code></pre>"},{"location":"chapter5-cli.html#research-workflow","title":"Research Workflow","text":"<pre><code># Update all data\nvirginia-clemm-poe update --all --force\n\n# Find models by capability\nvirginia-clemm-poe search \"vision\" --show_bot_info\nvirginia-clemm-poe search \"code\" --show_bot_info\n\n# Get comprehensive model list\nvirginia-clemm-poe list --with_pricing &gt; models.txt\n\n# Generate pricing comparison\nvirginia-clemm-poe search \"claude\" &gt; claude_models.txt\nvirginia-clemm-poe search \"gpt\" &gt; gpt_models.txt\n</code></pre>"},{"location":"chapter5-cli.html#troubleshooting-workflow","title":"Troubleshooting Workflow","text":"<pre><code># Run comprehensive diagnostics\nvirginia-clemm-poe doctor\n\n# Clear cache if issues persist\nvirginia-clemm-poe clear-cache\n\n# Re-setup browser\nvirginia-clemm-poe setup --verbose\n\n# Test with single model update\nvirginia-clemm-poe update --force --verbose\n\n# Check cache performance\nvirginia-clemm-poe cache\n</code></pre>"},{"location":"chapter5-cli.html#output-formats-and-styling","title":"Output Formats and Styling","text":"<p>The CLI uses Rich for beautiful terminal output:</p>"},{"location":"chapter5-cli.html#table-formatting","title":"Table Formatting","text":"<ul> <li>Borders: Unicode box-drawing characters</li> <li>Colors: Syntax highlighting for different data types</li> <li>Alignment: Smart column alignment based on content</li> <li>Wrapping: Automatic text wrapping for long descriptions</li> </ul>"},{"location":"chapter5-cli.html#status-indicators","title":"Status Indicators","text":"<ul> <li>\u2705 Green checkmark: Success/available</li> <li>\u274c Red X: Error/unavailable  </li> <li>\u26a0\ufe0f Yellow warning: Caution/needs attention</li> <li>\ud83d\udd04 Blue info: Processing/informational</li> </ul>"},{"location":"chapter5-cli.html#progress-indicators","title":"Progress Indicators","text":"<ul> <li>Spinner animations for long operations</li> <li>Progress bars for batch updates</li> <li>Real-time status updates during scraping</li> </ul>"},{"location":"chapter5-cli.html#automation-and-scripting","title":"Automation and Scripting","text":""},{"location":"chapter5-cli.html#exit-codes","title":"Exit Codes","text":"<p>Commands return standard exit codes for automation: - <code>0</code>: Success - <code>1</code>: Error or failure - <code>2</code>: Invalid arguments</p>"},{"location":"chapter5-cli.html#json-output","title":"JSON Output","text":"<p>Some commands support JSON output for programmatic use:</p> <pre><code># Export model data as JSON (planned feature)\nvirginia-clemm-poe list --format json &gt; models.json\n\n# Search with JSON output (planned feature)\nvirginia-clemm-poe search claude --format json\n</code></pre>"},{"location":"chapter5-cli.html#batch-operations","title":"Batch Operations","text":"<pre><code>#!/bin/bash\n# batch_update.sh - Update specific model categories\n\nmodels=(\"claude\" \"gpt\" \"gemini\")\n\nfor model_type in \"${models[@]}\"; do\n    echo \"Updating $model_type models...\"\n    virginia-clemm-poe search \"$model_type\" \n    echo \"Found models for $model_type\"\ndone\n</code></pre>"},{"location":"chapter5-cli.html#cicd-integration","title":"CI/CD Integration","text":"<pre><code># .github/workflows/model-data.yml\nname: Update Model Data\n\non:\n  schedule:\n    - cron: '0 6 * * 1'  # Weekly on Monday at 6 AM\n\njobs:\n  update:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.12'\n\n      - name: Install package\n        run: pip install virginia-clemm-poe\n\n      - name: Setup browser\n        run: virginia-clemm-poe setup\n\n      - name: Update model data\n        env:\n          POE_API_KEY: ${{ secrets.POE_API_KEY }}\n        run: virginia-clemm-poe update --all\n\n      - name: Check status\n        run: virginia-clemm-poe status\n</code></pre>"},{"location":"chapter5-cli.html#performance-tips","title":"Performance Tips","text":""},{"location":"chapter5-cli.html#optimization-strategies","title":"Optimization Strategies","text":"<ol> <li>Selective Updates: Use <code>--pricing</code> or <code>--info</code> for faster updates</li> <li>Cache Management: Monitor cache hit rates with <code>cache</code> command</li> <li>Incremental Updates: Avoid <code>--force</code> unless necessary</li> <li>Network Optimization: Increase timeout for slow connections</li> </ol>"},{"location":"chapter5-cli.html#resource-management","title":"Resource Management","text":"<pre><code># Monitor resource usage during updates\nexport VCP_LOG_LEVEL=\"DEBUG\"\nvirginia-clemm-poe update --verbose\n\n# Optimize for slow networks\nexport VCP_TIMEOUT=\"120000\"  # 2 minutes\nvirginia-clemm-poe update\n\n# Reduce memory usage\nvirginia-clemm-poe clear-cache --browser\nvirginia-clemm-poe update --pricing  # Only update pricing\n</code></pre>"},{"location":"chapter5-cli.html#error-recovery","title":"Error Recovery","text":"<pre><code># Automatic retry script\n#!/bin/bash\nMAX_RETRIES=3\nRETRY_COUNT=0\n\nwhile [ $RETRY_COUNT -lt $MAX_RETRIES ]; do\n    virginia-clemm-poe update\n    if [ $? -eq 0 ]; then\n        echo \"Update successful\"\n        exit 0\n    fi\n\n    RETRY_COUNT=$((RETRY_COUNT + 1))\n    echo \"Retry $RETRY_COUNT/$MAX_RETRIES\"\n    sleep 30\ndone\n\necho \"Update failed after $MAX_RETRIES retries\"\nexit 1\n</code></pre>"},{"location":"chapter5-cli.html#configuration-files","title":"Configuration Files","text":""},{"location":"chapter5-cli.html#default-locations","title":"Default Locations","text":"<p>The CLI stores configuration in platform-appropriate locations:</p> <p>Linux/macOS: - Config: <code>~/.config/virginia-clemm-poe/config.json</code> - Data: <code>~/.local/share/virginia-clemm-poe/</code> - Cache: <code>~/.cache/virginia-clemm-poe/</code> - Logs: <code>~/.local/share/virginia-clemm-poe/logs/</code></p> <p>Windows: - Config: <code>%APPDATA%\\virginia-clemm-poe\\config.json</code> - Data: <code>%LOCALAPPDATA%\\virginia-clemm-poe\\</code> - Cache: <code>%LOCALAPPDATA%\\virginia-clemm-poe\\cache\\</code> - Logs: <code>%LOCALAPPDATA%\\virginia-clemm-poe\\logs\\</code></p>"},{"location":"chapter5-cli.html#configuration-schema","title":"Configuration Schema","text":"<pre><code>{\n  \"api_key\": \"your_poe_api_key\",\n  \"browser\": {\n    \"headless\": true,\n    \"timeout\": 30000,\n    \"debug_port\": 9222,\n    \"user_agent\": \"custom_user_agent\"\n  },\n  \"cache\": {\n    \"enabled\": true,\n    \"max_age\": 3600,\n    \"max_size\": 1000\n  },\n  \"logging\": {\n    \"level\": \"INFO\",\n    \"file\": \"~/.local/share/virginia-clemm-poe/logs/app.log\",\n    \"max_size\": \"10MB\",\n    \"backup_count\": 5\n  }\n}\n</code></pre>"},{"location":"chapter5-cli.html#advanced-usage","title":"Advanced Usage","text":""},{"location":"chapter5-cli.html#custom-browser-configuration","title":"Custom Browser Configuration","text":"<pre><code># Use custom Chrome installation\nexport CHROME_PATH=\"/path/to/chrome\"\nvirginia-clemm-poe setup\n\n# Use custom user data directory\nexport VCP_USER_DATA_DIR=\"/path/to/userdata\"\nvirginia-clemm-poe update\n</code></pre>"},{"location":"chapter5-cli.html#logging-configuration","title":"Logging Configuration","text":"<pre><code># Enable debug logging\nexport VCP_LOG_LEVEL=\"DEBUG\"\nvirginia-clemm-poe update --verbose 2&gt;&amp;1 | tee update.log\n\n# Log to custom file\nexport VCP_LOG_FILE=\"/path/to/custom.log\"\nvirginia-clemm-poe update\n</code></pre>"},{"location":"chapter5-cli.html#network-configuration","title":"Network Configuration","text":"<pre><code># Configure proxy\nexport HTTP_PROXY=\"http://proxy.example.com:8080\"\nexport HTTPS_PROXY=\"http://proxy.example.com:8080\"\nvirginia-clemm-poe update\n\n# Custom timeouts\nexport VCP_TIMEOUT=\"60000\"  # 60 seconds\nexport VCP_NETWORK_TIMEOUT=\"30000\"  # 30 seconds\nvirginia-clemm-poe update\n</code></pre> <p>This comprehensive CLI reference provides everything you need to effectively use Virginia Clemm Poe from the command line, whether for interactive exploration or automated workflows.</p>"},{"location":"chapter6-models.html","title":"Chapter 6: Data Models and Structure","text":""},{"location":"chapter6-models.html#overview","title":"Overview","text":"<p>Virginia Clemm Poe uses Pydantic models to provide type-safe, validated data structures for all model information. This chapter explains the data models, their relationships, and how to work with them effectively.</p>"},{"location":"chapter6-models.html#core-data-models","title":"Core Data Models","text":""},{"location":"chapter6-models.html#architecture","title":"Architecture","text":"<p>Defines what types of data a Poe model can accept and produce.</p> <pre><code>from virginia_clemm_poe.models import Architecture\n\n# Example: Multimodal text model\narch = Architecture(\n    input_modalities=[\"text\", \"image\"],\n    output_modalities=[\"text\"],\n    modality=\"multimodal-&gt;text\"\n)\n\nprint(f\"Inputs: {arch.input_modalities}\")    # [\"text\", \"image\"]\nprint(f\"Outputs: {arch.output_modalities}\")  # [\"text\"]\nprint(f\"Mode: {arch.modality}\")              # \"multimodal-&gt;text\"\n</code></pre> <p>Properties: - <code>input_modalities: list[str]</code> - Supported input types - <code>output_modalities: list[str]</code> - Supported output types - <code>modality: str</code> - Primary modality description</p> <p>Common Modality Types: - <code>\"text-&gt;text\"</code> - Pure text models (most common) - <code>\"multimodal-&gt;text\"</code> - Accept text + images, output text - <code>\"text-&gt;image\"</code> - Text-to-image generators - <code>\"text-&gt;video\"</code> - Text-to-video generators</p>"},{"location":"chapter6-models.html#pricingdetails","title":"PricingDetails","text":"<p>Captures all possible pricing structures found on Poe.com model pages.</p> <pre><code>from virginia_clemm_poe.models import PricingDetails\n\n# Example: Standard text model pricing\npricing_details = PricingDetails(\n    input_text=\"10 points/1k tokens\",      # Input cost\n    bot_message=\"5 points/message\",         # Output cost\n    initial_points_cost=\"100 points\"       # Upfront cost\n)\n\n# Access pricing information\nprint(f\"Input cost: {pricing_details.input_text}\")\nprint(f\"Output cost: {pricing_details.bot_message}\")\n</code></pre> <p>Standard Pricing Fields: - <code>input_text</code> (alias: \"Input (text)\") - Cost per text input - <code>input_image</code> (alias: \"Input (image)\") - Cost per image input - <code>bot_message</code> (alias: \"Bot message\") - Cost per bot response - <code>chat_history</code> (alias: \"Chat history\") - Chat history access cost - <code>chat_history_cache_discount</code> - Caching discount rate</p> <p>Alternative Pricing Fields: - <code>total_cost</code> - Flat rate pricing - <code>image_output</code> - Cost per generated image - <code>video_output</code> - Cost per generated video - <code>text_input</code> - Alternative text input format - <code>per_message</code> - Cost per message interaction - <code>finetuning</code> - Model fine-tuning cost - <code>initial_points_cost</code> - Upfront cost from bot card</p> <p>Field Aliases: The model uses Pydantic field aliases to match exact text from Poe.com:</p> <pre><code># These are equivalent:\npricing.input_text\npricing.model_dump(by_alias=True)[\"Input (text)\"]\n</code></pre>"},{"location":"chapter6-models.html#pricing","title":"Pricing","text":"<p>Combines pricing details with a timestamp for data freshness tracking.</p> <pre><code>from datetime import datetime, timezone\nfrom virginia_clemm_poe.models import Pricing, PricingDetails\n\npricing = Pricing(\n    checked_at=datetime.now(timezone.utc),\n    details=PricingDetails(input_text=\"10 points/1k tokens\")\n)\n\n# Check data age\nage = datetime.now(timezone.utc) - pricing.checked_at\nprint(f\"Pricing data is {age.days} days old\")\n</code></pre> <p>Properties: - <code>checked_at: datetime</code> - UTC timestamp of last scrape - <code>details: PricingDetails</code> - Complete pricing breakdown</p>"},{"location":"chapter6-models.html#botinfo","title":"BotInfo","text":"<p>Creator and description metadata scraped from Poe.com bot info cards.</p> <pre><code>from virginia_clemm_poe.models import BotInfo\n\nbot_info = BotInfo(\n    creator=\"@anthropic\",\n    description=\"Claude is an AI assistant created by Anthropic\",\n    description_extra=\"Powered by Claude-3 Sonnet\"\n)\n\nprint(f\"Created by: {bot_info.creator}\")\nprint(f\"Description: {bot_info.description}\")\n</code></pre> <p>Properties: - <code>creator: str | None</code> - Bot creator handle (includes \"@\" prefix) - <code>description: str | None</code> - Main bot description text - <code>description_extra: str | None</code> - Additional details or disclaimers</p>"},{"location":"chapter6-models.html#poemodel","title":"PoeModel","text":"<p>The main model class representing a complete Poe.com model.</p> <pre><code>from virginia_clemm_poe.models import PoeModel, Architecture, Pricing, BotInfo\n\nmodel = PoeModel(\n    id=\"Claude-3-Opus\",\n    created=1709574492024,\n    owned_by=\"anthropic\",\n    root=\"Claude-3-Opus\",\n    architecture=Architecture(\n        input_modalities=[\"text\"],\n        output_modalities=[\"text\"],\n        modality=\"text-&gt;text\"\n    ),\n    pricing=Pricing(...),\n    bot_info=BotInfo(...)\n)\n</code></pre> <p>Core Properties: - <code>id: str</code> - Unique model identifier - <code>object: str</code> - Always \"model\" (API compatibility) - <code>created: int</code> - Unix timestamp of creation - <code>owned_by: str</code> - Organization owning the model - <code>root: str</code> - Root model name - <code>parent: str | None</code> - Parent model for variants - <code>architecture: Architecture</code> - Capability information</p> <p>Enhanced Properties: - <code>pricing: Pricing | None</code> - Scraped pricing data - <code>pricing_error: str | None</code> - Error if pricing scraping failed - <code>bot_info: BotInfo | None</code> - Scraped bot metadata</p> <p>Utility Methods:</p> <pre><code># Check if model has pricing data\nif model.has_pricing():\n    print(\"Pricing available\")\n\n# Check if model needs pricing update\nif model.needs_pricing_update():\n    print(\"Needs pricing update\")\n\n# Get primary cost for display\nprimary_cost = model.get_primary_cost()\nif primary_cost:\n    print(f\"Cost: {primary_cost}\")\n</code></pre>"},{"location":"chapter6-models.html#modelcollection","title":"ModelCollection","text":"<p>Container for working with multiple models with search capabilities.</p> <pre><code>from virginia_clemm_poe.models import ModelCollection\n\ncollection = ModelCollection(data=[model1, model2, model3])\n\n# Search for models\nclaude_models = collection.search(\"claude\")\n\n# Get specific model\nmodel = collection.get_by_id(\"Claude-3-Opus\")\n</code></pre> <p>Properties: - <code>object: str</code> - Always \"list\" (API compatibility) - <code>data: list[PoeModel]</code> - List of all models</p> <p>Methods: - <code>get_by_id(model_id)</code> - Exact ID lookup - <code>search(query)</code> - Case-insensitive substring search</p>"},{"location":"chapter6-models.html#data-relationships","title":"Data Relationships","text":""},{"location":"chapter6-models.html#hierarchy","title":"Hierarchy","text":"<pre><code>ModelCollection\n\u251c\u2500\u2500 data: list[PoeModel]\n    \u251c\u2500\u2500 architecture: Architecture\n    \u2502   \u251c\u2500\u2500 input_modalities: list[str]\n    \u2502   \u251c\u2500\u2500 output_modalities: list[str]\n    \u2502   \u2514\u2500\u2500 modality: str\n    \u251c\u2500\u2500 pricing: Pricing | None\n    \u2502   \u251c\u2500\u2500 checked_at: datetime\n    \u2502   \u2514\u2500\u2500 details: PricingDetails\n    \u2502       \u251c\u2500\u2500 input_text: str | None\n    \u2502       \u251c\u2500\u2500 bot_message: str | None\n    \u2502       \u2514\u2500\u2500 ... (other pricing fields)\n    \u2514\u2500\u2500 bot_info: BotInfo | None\n        \u251c\u2500\u2500 creator: str | None\n        \u251c\u2500\u2500 description: str | None\n        \u2514\u2500\u2500 description_extra: str | None\n</code></pre>"},{"location":"chapter6-models.html#data-sources","title":"Data Sources","text":"<ol> <li>API Data (from Poe API):</li> <li><code>id</code>, <code>created</code>, <code>owned_by</code>, <code>root</code>, <code>parent</code></li> <li> <p><code>architecture</code> information</p> </li> <li> <p>Scraped Data (from Poe website):</p> </li> <li><code>pricing</code> details and timestamp</li> <li><code>bot_info</code> metadata</li> <li><code>pricing_error</code> if scraping failed</li> </ol>"},{"location":"chapter6-models.html#working-with-models","title":"Working with Models","text":""},{"location":"chapter6-models.html#type-safety","title":"Type Safety","text":"<p>All models use Pydantic for runtime validation:</p> <pre><code>from virginia_clemm_poe.models import PoeModel\n\n# This will raise ValidationError\ntry:\n    invalid_model = PoeModel(\n        id=\"test\",\n        created=\"not_a_number\",  # Should be int\n        owned_by=\"test\",\n        root=\"test\",\n        architecture=\"invalid\"   # Should be Architecture object\n    )\nexcept ValidationError as e:\n    print(f\"Validation error: {e}\")\n</code></pre>"},{"location":"chapter6-models.html#json-serialization","title":"JSON Serialization","text":"<p>Models can be serialized to/from JSON:</p> <pre><code># Serialize to JSON\nmodel_json = model.model_dump_json()\n\n# Deserialize from JSON\nmodel_dict = json.loads(model_json)\nrestored_model = PoeModel(**model_dict)\n\n# With aliases (matches website field names)\nmodel_with_aliases = model.model_dump(by_alias=True)\n</code></pre>"},{"location":"chapter6-models.html#filtering-and-queries","title":"Filtering and Queries","text":"<p>Common patterns for working with model data:</p> <pre><code>from virginia_clemm_poe import api\n\n# Get all models\nmodels = api.get_all_models()\n\n# Filter by capability\ntext_models = [m for m in models if \"text\" in m.architecture.input_modalities]\nimage_models = [m for m in models if \"image\" in m.architecture.input_modalities]\n\n# Filter by provider\nanthropic_models = [m for m in models if m.owned_by == \"anthropic\"]\nopenai_models = [m for m in models if m.owned_by == \"openai\"]\n\n# Filter by pricing availability\npriced_models = [m for m in models if m.has_pricing()]\nfree_models = [m for m in models if m.pricing and \"free\" in m.get_primary_cost().lower()]\n\n# Filter by creation date\nimport datetime\nrecent_models = [m for m in models if m.created &gt; 1700000000]  # After Nov 2023\n</code></pre>"},{"location":"chapter6-models.html#advanced-queries","title":"Advanced Queries","text":"<pre><code># Find cheapest models (simplified cost extraction)\ndef extract_numeric_cost(cost_str):\n    \"\"\"Extract numeric cost from pricing string.\"\"\"\n    if not cost_str:\n        return float('inf')\n\n    # Simple extraction - matches \"X points\" patterns\n    import re\n    match = re.search(r'(\\d+(?:\\.\\d+)?)', cost_str)\n    return float(match.group(1)) if match else float('inf')\n\npriced_models = [m for m in models if m.has_pricing()]\ncheapest_models = sorted(\n    priced_models,\n    key=lambda m: extract_numeric_cost(m.get_primary_cost())\n)[:10]\n\n# Find models by capability combination\nmultimodal_models = [\n    m for m in models \n    if len(m.architecture.input_modalities) &gt; 1\n]\n\n# Group models by provider\nfrom collections import defaultdict\nby_provider = defaultdict(list)\nfor model in models:\n    by_provider[model.owned_by].append(model)\n\nfor provider, provider_models in by_provider.items():\n    print(f\"{provider}: {len(provider_models)} models\")\n</code></pre>"},{"location":"chapter6-models.html#data-file-structure","title":"Data File Structure","text":"<p>The local dataset is stored as JSON in <code>poe_models.json</code>:</p> <pre><code>{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"Claude-3-Opus\",\n      \"object\": \"model\",\n      \"created\": 1709574492024,\n      \"owned_by\": \"anthropic\",\n      \"permission\": [],\n      \"root\": \"Claude-3-Opus\",\n      \"parent\": null,\n      \"architecture\": {\n        \"input_modalities\": [\"text\"],\n        \"output_modalities\": [\"text\"],\n        \"modality\": \"text-&gt;text\"\n      },\n      \"pricing\": {\n        \"checked_at\": \"2024-03-15T10:30:00Z\",\n        \"details\": {\n          \"Input (text)\": \"15 points/message\",\n          \"initial_points_cost\": null\n        }\n      },\n      \"pricing_error\": null,\n      \"bot_info\": {\n        \"creator\": \"@anthropic\",\n        \"description\": \"Claude-3 Opus is Anthropic's most powerful model\",\n        \"description_extra\": null\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"chapter6-models.html#file-management","title":"File Management","text":"<pre><code>from virginia_clemm_poe.config import DATA_FILE_PATH\nimport json\n\n# Read raw JSON data\nwith open(DATA_FILE_PATH) as f:\n    raw_data = json.load(f)\n\n# Load into Pydantic models\nfrom virginia_clemm_poe.models import ModelCollection\ncollection = ModelCollection(**raw_data)\n\n# Save back to JSON\nwith open(DATA_FILE_PATH, 'w') as f:\n    json.dump(collection.model_dump(), f, indent=2)\n</code></pre>"},{"location":"chapter6-models.html#validation-and-error-handling","title":"Validation and Error Handling","text":""},{"location":"chapter6-models.html#model-validation","title":"Model Validation","text":"<pre><code>from pydantic import ValidationError\nfrom virginia_clemm_poe.models import PoeModel\n\ndef safe_model_creation(data_dict):\n    \"\"\"Safely create model with error handling.\"\"\"\n    try:\n        return PoeModel(**data_dict)\n    except ValidationError as e:\n        print(f\"Validation failed: {e}\")\n        return None\n\n# Example usage\nraw_data = {\"id\": \"test\", \"created\": \"invalid\"}\nmodel = safe_model_creation(raw_data)  # Returns None\n</code></pre>"},{"location":"chapter6-models.html#data-integrity-checks","title":"Data Integrity Checks","text":"<pre><code>def validate_collection_integrity(collection: ModelCollection):\n    \"\"\"Validate model collection data integrity.\"\"\"\n    issues = []\n\n    for i, model in enumerate(collection.data):\n        # Check required fields\n        if not model.id:\n            issues.append(f\"Model {i}: Missing ID\")\n\n        # Check pricing consistency\n        if model.pricing and model.pricing_error:\n            issues.append(f\"Model {model.id}: Has both pricing and error\")\n\n        # Check architecture validity\n        if not model.architecture.input_modalities:\n            issues.append(f\"Model {model.id}: No input modalities\")\n\n    return issues\n</code></pre>"},{"location":"chapter6-models.html#performance-considerations","title":"Performance Considerations","text":""},{"location":"chapter6-models.html#memory-usage","title":"Memory Usage","text":"<pre><code>import sys\nfrom virginia_clemm_poe import api\n\n# Check memory usage of model collection\ncollection = api.load_models()\nsize_bytes = sys.getsizeof(collection)\nmodel_count = len(collection.data)\n\nprint(f\"Collection size: {size_bytes:,} bytes\")\nprint(f\"Per model: {size_bytes / model_count:.1f} bytes\")\n</code></pre>"},{"location":"chapter6-models.html#efficient-queries","title":"Efficient Queries","text":"<pre><code># Use generator expressions for large datasets\ndef find_models_by_criteria(models, criteria_func):\n    \"\"\"Memory-efficient model filtering.\"\"\"\n    return (model for model in models if criteria_func(model))\n\n# Example: Find expensive models without loading all into memory\nexpensive_models = find_models_by_criteria(\n    models,\n    lambda m: m.has_pricing() and extract_numeric_cost(m.get_primary_cost()) &gt; 100\n)\n\n# Process one at a time\nfor model in expensive_models:\n    print(f\"Expensive: {model.id}\")\n</code></pre>"},{"location":"chapter6-models.html#custom-model-extensions","title":"Custom Model Extensions","text":""},{"location":"chapter6-models.html#extending-poemodel","title":"Extending PoeModel","text":"<pre><code>from virginia_clemm_poe.models import PoeModel\nfrom pydantic import computed_field\n\nclass ExtendedPoeModel(PoeModel):\n    \"\"\"Extended model with custom computed properties.\"\"\"\n\n    @computed_field\n    @property\n    def is_multimodal(self) -&gt; bool:\n        \"\"\"Check if model supports multiple input types.\"\"\"\n        return len(self.architecture.input_modalities) &gt; 1\n\n    @computed_field\n    @property\n    def cost_per_token_estimate(self) -&gt; float | None:\n        \"\"\"Estimate cost per token (simplified).\"\"\"\n        if not self.pricing:\n            return None\n\n        primary_cost = self.get_primary_cost()\n        if not primary_cost or \"points\" not in primary_cost:\n            return None\n\n        # Extract points and estimate\n        import re\n        match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*points', primary_cost)\n        if match:\n            return float(match.group(1)) / 1000  # Assume per 1k tokens\n\n        return None\n\n# Use extended model\ndef upgrade_to_extended(standard_model: PoeModel) -&gt; ExtendedPoeModel:\n    \"\"\"Convert standard model to extended version.\"\"\"\n    return ExtendedPoeModel(**standard_model.model_dump())\n</code></pre>"},{"location":"chapter6-models.html#custom-collections","title":"Custom Collections","text":"<pre><code>from virginia_clemm_poe.models import ModelCollection, PoeModel\n\nclass SmartModelCollection(ModelCollection):\n    \"\"\"Enhanced collection with additional query methods.\"\"\"\n\n    def get_by_provider(self, provider: str) -&gt; list[PoeModel]:\n        \"\"\"Get all models from a specific provider.\"\"\"\n        return [m for m in self.data if m.owned_by.lower() == provider.lower()]\n\n    def get_by_capability(self, input_type: str = None, output_type: str = None) -&gt; list[PoeModel]:\n        \"\"\"Get models by input/output capabilities.\"\"\"\n        results = self.data\n\n        if input_type:\n            results = [m for m in results if input_type in m.architecture.input_modalities]\n\n        if output_type:\n            results = [m for m in results if output_type in m.architecture.output_modalities]\n\n        return results\n\n    def get_price_range(self, min_cost: float = None, max_cost: float = None) -&gt; list[PoeModel]:\n        \"\"\"Get models within a price range.\"\"\"\n        results = []\n\n        for model in self.data:\n            if not model.has_pricing():\n                continue\n\n            cost = extract_numeric_cost(model.get_primary_cost())\n            if cost == float('inf'):\n                continue\n\n            if min_cost is not None and cost &lt; min_cost:\n                continue\n\n            if max_cost is not None and cost &gt; max_cost:\n                continue\n\n            results.append(model)\n\n        return results\n</code></pre> <p>This comprehensive guide to the data models provides everything you need to understand and work with Virginia Clemm Poe's type-safe, validated data structures efficiently.</p>"},{"location":"chapter7-browser.html","title":"Chapter 7: Browser Management and Web Scraping","text":""},{"location":"chapter7-browser.html#overview","title":"Overview","text":"<p>Virginia Clemm Poe uses sophisticated browser automation to scrape pricing and metadata from Poe.com that isn't available through the API. This chapter explains the browser management system, web scraping techniques, and how to troubleshoot automation issues.</p>"},{"location":"chapter7-browser.html#browser-architecture","title":"Browser Architecture","text":""},{"location":"chapter7-browser.html#playwrightauthor-integration","title":"PlaywrightAuthor Integration","text":"<p>The package uses the external PlaywrightAuthor package for robust browser management:</p> <pre><code>from virginia_clemm_poe.browser_manager import BrowserManager\n\n# Initialize browser manager\nmanager = BrowserManager(debug_port=9222, verbose=True)\n\n# Get browser instance (handled automatically)\nbrowser = await manager.get_browser()\n</code></pre> <p>Key benefits of PlaywrightAuthor: - Automatic Chrome for Testing installation - Robust browser lifecycle management - DevTools Protocol connection handling - Cross-platform compatibility</p>"},{"location":"chapter7-browser.html#browser-pool-architecture","title":"Browser Pool Architecture","text":"<p>For efficient concurrent scraping, the package uses a browser pool system:</p> <pre><code>from virginia_clemm_poe.browser_pool import BrowserPool, get_global_pool\n\n# Get global browser pool instance\npool = get_global_pool()\n\n# Use browser from pool\nasync with pool.get_browser() as browser:\n    page = await browser.new_page()\n    # ... scraping operations\n</code></pre> <p>Pool Features: - Connection Reuse: Browsers stay alive between operations - Concurrent Scraping: Multiple pages can run simultaneously - Resource Management: Automatic cleanup and memory management - Error Recovery: Handles browser crashes and restarts</p>"},{"location":"chapter7-browser.html#scraping-pipeline","title":"Scraping Pipeline","text":""},{"location":"chapter7-browser.html#data-collection-process","title":"Data Collection Process","text":"<ol> <li>API Data Fetching: Get basic model information from Poe API</li> <li>Browser Launch: Start Chrome with DevTools Protocol</li> <li>Page Navigation: Visit each model's Poe.com page</li> <li>Content Extraction: Parse pricing tables and bot info cards</li> <li>Data Validation: Validate scraped data with Pydantic models</li> <li>Storage: Save enriched dataset to local JSON file</li> </ol>"},{"location":"chapter7-browser.html#scraping-targets","title":"Scraping Targets","text":""},{"location":"chapter7-browser.html#pricing-information","title":"Pricing Information","text":"<p>Extracted from pricing tables on model pages:</p> <pre><code>&lt;!-- Example pricing table structure --&gt;\n&lt;table class=\"pricing-table\"&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Input (text)&lt;/td&gt;\n    &lt;td&gt;10 points/1k tokens&lt;/td&gt;\n  &lt;/tr&gt;\n  &lt;tr&gt;\n    &lt;td&gt;Bot message&lt;/td&gt;\n    &lt;td&gt;5 points/message&lt;/td&gt;\n  &lt;/tr&gt;\n&lt;/table&gt;\n</code></pre> <p>Pricing Fields Scraped: - Input costs (text, image) - Output costs (messages, images, video) - Special rates (cache discounts, fine-tuning) - Initial point costs from bot cards</p>"},{"location":"chapter7-browser.html#bot-information","title":"Bot Information","text":"<p>Extracted from bot info cards and description sections:</p> <pre><code>&lt;!-- Example bot info structure --&gt;\n&lt;div class=\"bot-info-card\"&gt;\n  &lt;div class=\"creator\"&gt;@anthropic&lt;/div&gt;\n  &lt;div class=\"description\"&gt;Claude is an AI assistant...&lt;/div&gt;\n  &lt;div class=\"disclaimer\"&gt;Powered by Claude-3 Sonnet&lt;/div&gt;\n&lt;/div&gt;\n</code></pre> <p>Bot Data Scraped: - Creator handles (e.g., \"@anthropic\", \"@openai\") - Main descriptions and capabilities - Additional disclaimers or details</p>"},{"location":"chapter7-browser.html#browser-management-code","title":"Browser Management Code","text":""},{"location":"chapter7-browser.html#browsermanager-class","title":"BrowserManager Class","text":"<pre><code>from virginia_clemm_poe.browser_manager import BrowserManager\n\nclass BrowserManager:\n    \"\"\"Manages browser lifecycle using playwrightauthor.\"\"\"\n\n    def __init__(self, debug_port: int = 9222, verbose: bool = False):\n        self.debug_port = debug_port\n        self.verbose = verbose\n        self._browser = None\n\n    async def get_browser(self):\n        \"\"\"Get browser instance with automatic setup.\"\"\"\n        if self._browser is None or not self._browser.is_connected():\n            from playwrightauthor import get_browser\n            self._browser = await get_browser(\n                headless=True,\n                port=self.debug_port,\n                verbose=self.verbose\n            )\n        return self._browser\n\n    @staticmethod\n    async def setup_chrome():\n        \"\"\"Ensure Chrome is installed.\"\"\"\n        from playwrightauthor.browser_manager import ensure_browser\n        ensure_browser(verbose=True)\n        return True\n</code></pre>"},{"location":"chapter7-browser.html#browser-pool-implementation","title":"Browser Pool Implementation","text":"<pre><code>from virginia_clemm_poe.browser_pool import BrowserPool\n\n# Create browser pool\npool = BrowserPool(max_browsers=3, debug_port_start=9222)\n\n# Use pool for concurrent operations\nasync def scrape_models_concurrently(model_ids):\n    tasks = []\n\n    for model_id in model_ids:\n        task = scrape_single_model(pool, model_id)\n        tasks.append(task)\n\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n    return results\n\nasync def scrape_single_model(pool, model_id):\n    async with pool.get_browser() as browser:\n        page = await browser.new_page()\n        try:\n            # Navigate and scrape\n            await page.goto(f\"https://poe.com/{model_id}\")\n            pricing_data = await extract_pricing(page)\n            return pricing_data\n        finally:\n            await page.close()\n</code></pre>"},{"location":"chapter7-browser.html#scraping-techniques","title":"Scraping Techniques","text":""},{"location":"chapter7-browser.html#page-navigation","title":"Page Navigation","text":"<pre><code>async def navigate_to_model_page(page: Page, model_id: str):\n    \"\"\"Navigate to model page with error handling.\"\"\"\n    url = f\"https://poe.com/{model_id}\"\n\n    try:\n        # Navigate with timeout\n        await page.goto(url, timeout=30000, wait_until=\"networkidle\")\n\n        # Wait for page to fully load\n        await page.wait_for_load_state(\"domcontentloaded\")\n\n        # Handle potential modals or overlays\n        await dismiss_modals(page)\n\n    except PlaywrightTimeoutError:\n        logger.warning(f\"Timeout navigating to {url}\")\n        raise\n    except Exception as e:\n        logger.error(f\"Navigation error for {model_id}: {e}\")\n        raise\n</code></pre>"},{"location":"chapter7-browser.html#modal-and-dialog-handling","title":"Modal and Dialog Handling","text":"<pre><code>async def dismiss_modals(page: Page):\n    \"\"\"Dismiss any modal dialogs that might block scraping.\"\"\"\n\n    # Common modal selectors\n    modal_selectors = [\n        \"[data-testid='modal-close']\",\n        \".modal-close\",\n        \"[aria-label='Close']\",\n        \"button:has-text('Close')\",\n        \"button:has-text('\u00d7')\"\n    ]\n\n    for selector in modal_selectors:\n        try:\n            modal = await page.query_selector(selector)\n            if modal and await modal.is_visible():\n                await modal.click()\n                await page.wait_for_timeout(1000)  # Wait for animation\n                logger.debug(f\"Dismissed modal: {selector}\")\n                break\n        except Exception:\n            continue  # Try next selector\n</code></pre>"},{"location":"chapter7-browser.html#data-extraction","title":"Data Extraction","text":""},{"location":"chapter7-browser.html#pricing-table-scraping","title":"Pricing Table Scraping","text":"<pre><code>async def extract_pricing_data(page: Page) -&gt; dict[str, str]:\n    \"\"\"Extract pricing information from pricing tables.\"\"\"\n    pricing_data = {}\n\n    # Look for pricing tables\n    tables = await page.query_selector_all(\"table\")\n\n    for table in tables:\n        rows = await table.query_selector_all(\"tr\")\n\n        for row in rows:\n            cells = await row.query_selector_all(\"td\")\n\n            if len(cells) &gt;= 2:\n                # Get label and value\n                label_element = cells[0]\n                value_element = cells[1]\n\n                label = await label_element.inner_text()\n                value = await value_element.inner_text()\n\n                # Clean and normalize\n                label = label.strip()\n                value = value.strip()\n\n                if label and value:\n                    pricing_data[label] = value\n\n    return pricing_data\n</code></pre>"},{"location":"chapter7-browser.html#bot-info-extraction","title":"Bot Info Extraction","text":"<pre><code>async def extract_bot_info(page: Page) -&gt; dict[str, str]:\n    \"\"\"Extract bot information from info cards.\"\"\"\n    bot_info = {}\n\n    # Look for creator information\n    creator_selectors = [\n        \"[data-testid='bot-creator']\",\n        \".bot-creator\",\n        \"span:has-text('@')\"\n    ]\n\n    for selector in creator_selectors:\n        try:\n            element = await page.query_selector(selector)\n            if element:\n                creator = await element.inner_text()\n                if creator.startswith('@'):\n                    bot_info['creator'] = creator\n                    break\n        except Exception:\n            continue\n\n    # Look for description\n    description_selectors = [\n        \"[data-testid='bot-description']\",\n        \".bot-description\",\n        \".model-description\"\n    ]\n\n    for selector in description_selectors:\n        try:\n            element = await page.query_selector(selector)\n            if element:\n                description = await element.inner_text()\n                if description:\n                    bot_info['description'] = description.strip()\n                    break\n        except Exception:\n            continue\n\n    return bot_info\n</code></pre>"},{"location":"chapter7-browser.html#error-handling-and-resilience","title":"Error Handling and Resilience","text":"<pre><code>async def scrape_with_retry(page: Page, model_id: str, max_retries: int = 3):\n    \"\"\"Scrape model data with retry logic.\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            # Navigate to page\n            await navigate_to_model_page(page, model_id)\n\n            # Extract data\n            pricing_data = await extract_pricing_data(page)\n            bot_info = await extract_bot_info(page)\n\n            return {\n                'pricing': pricing_data,\n                'bot_info': bot_info,\n                'scraped_at': datetime.utcnow()\n            }\n\n        except Exception as e:\n            if attempt &lt; max_retries - 1:\n                logger.warning(f\"Scraping attempt {attempt + 1} failed for {model_id}: {e}\")\n                await asyncio.sleep(2 ** attempt)  # Exponential backoff\n                continue\n            else:\n                logger.error(f\"All scraping attempts failed for {model_id}: {e}\")\n                return {\n                    'pricing': {},\n                    'bot_info': {},\n                    'error': str(e)\n                }\n</code></pre>"},{"location":"chapter7-browser.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"chapter7-browser.html#concurrent-scraping","title":"Concurrent Scraping","text":"<pre><code>async def scrape_models_batch(model_ids: list[str], batch_size: int = 5):\n    \"\"\"Scrape models in controlled batches.\"\"\"\n\n    results = []\n    pool = get_global_pool()\n\n    # Process in batches to avoid overwhelming the server\n    for i in range(0, len(model_ids), batch_size):\n        batch = model_ids[i:i + batch_size]\n\n        # Create tasks for batch\n        tasks = [scrape_single_model(pool, model_id) for model_id in batch]\n\n        # Execute batch with timeout\n        batch_results = await asyncio.gather(*tasks, return_exceptions=True)\n        results.extend(batch_results)\n\n        # Pause between batches\n        if i + batch_size &lt; len(model_ids):\n            await asyncio.sleep(1)\n\n    return results\n</code></pre>"},{"location":"chapter7-browser.html#memory-management","title":"Memory Management","text":"<pre><code>from virginia_clemm_poe.utils.memory import MemoryManagedOperation\n\nasync def memory_efficient_scraping(model_ids: list[str]):\n    \"\"\"Scrape with memory monitoring and management.\"\"\"\n\n    async with MemoryManagedOperation(\"model_scraping\") as mem_op:\n        results = []\n\n        for i, model_id in enumerate(model_ids):\n            # Check memory usage\n            if mem_op.should_gc():\n                await mem_op.cleanup()\n\n            # Scrape model\n            result = await scrape_single_model_safe(model_id)\n            results.append(result)\n\n            # Log progress\n            if i % 10 == 0:\n                mem_op.log_progress(f\"Scraped {i}/{len(model_ids)} models\")\n\n        return results\n</code></pre>"},{"location":"chapter7-browser.html#caching-strategy","title":"Caching Strategy","text":"<pre><code>from virginia_clemm_poe.utils.cache import cached, get_scraping_cache\n\n@cached(cache=get_scraping_cache(), ttl=3600, key_prefix=\"model_scrape\")\nasync def scrape_model_cached(model_id: str) -&gt; dict:\n    \"\"\"Scrape model with caching to avoid repeated requests.\"\"\"\n    pool = get_global_pool()\n\n    async with pool.get_browser() as browser:\n        page = await browser.new_page()\n        try:\n            return await scrape_model_data(page, model_id)\n        finally:\n            await page.close()\n</code></pre>"},{"location":"chapter7-browser.html#configuration-and-customization","title":"Configuration and Customization","text":""},{"location":"chapter7-browser.html#browser-settings","title":"Browser Settings","text":"<pre><code># Environment variables for browser configuration\nimport os\n\nbrowser_config = {\n    'headless': os.getenv('VCP_HEADLESS', 'true').lower() == 'true',\n    'timeout': int(os.getenv('VCP_TIMEOUT', '30000')),\n    'debug_port': int(os.getenv('VCP_DEBUG_PORT', '9222')),\n    'user_agent': os.getenv('VCP_USER_AGENT', None),\n    'viewport': {\n        'width': int(os.getenv('VCP_VIEWPORT_WIDTH', '1920')),\n        'height': int(os.getenv('VCP_VIEWPORT_HEIGHT', '1080'))\n    }\n}\n</code></pre>"},{"location":"chapter7-browser.html#scraping-parameters","title":"Scraping Parameters","text":"<pre><code># Timing configuration\nTIMING_CONFIG = {\n    'navigation_timeout': 30000,    # Page navigation timeout\n    'load_timeout': 10000,         # Element load timeout\n    'pause_between_requests': 1,    # Delay between requests\n    'retry_delay': 2,              # Delay before retry\n    'modal_wait': 1,               # Wait after modal dismiss\n}\n\n# Selector configuration\nSELECTOR_CONFIG = {\n    'pricing_table': [\n        'table[data-testid=\"pricing\"]',\n        '.pricing-table',\n        'table:has-text(\"Input\")'\n    ],\n    'bot_creator': [\n        '[data-testid=\"bot-creator\"]',\n        '.bot-creator',\n        'span:has-text(\"@\")'\n    ],\n    'bot_description': [\n        '[data-testid=\"bot-description\"]',\n        '.bot-description',\n        '.model-description'\n    ]\n}\n</code></pre>"},{"location":"chapter7-browser.html#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":""},{"location":"chapter7-browser.html#browser-connection-problems","title":"Browser Connection Problems","text":"<pre><code>async def diagnose_browser_issues():\n    \"\"\"Diagnose and report browser connectivity issues.\"\"\"\n\n    try:\n        # Test browser installation\n        from playwrightauthor.browser_manager import ensure_browser\n        browser_path, data_dir = ensure_browser(verbose=True)\n        print(f\"\u2713 Browser found at: {browser_path}\")\n\n        # Test browser launch\n        manager = BrowserManager(verbose=True)\n        browser = await manager.get_browser()\n        print(f\"\u2713 Browser connected: {browser.is_connected()}\")\n\n        # Test page creation\n        page = await browser.new_page()\n        await page.goto(\"https://poe.com\")\n        print(\"\u2713 Page navigation successful\")\n\n        await page.close()\n        await manager.close()\n\n    except Exception as e:\n        print(f\"\u2717 Browser issue: {e}\")\n        return False\n\n    return True\n</code></pre>"},{"location":"chapter7-browser.html#scraping-failures","title":"Scraping Failures","text":"<pre><code>async def debug_scraping_failure(model_id: str):\n    \"\"\"Debug why scraping fails for a specific model.\"\"\"\n\n    pool = get_global_pool()\n\n    async with pool.get_browser() as browser:\n        page = await browser.new_page()\n\n        try:\n            # Enable request/response logging\n            page.on(\"request\", lambda req: print(f\"\u2192 {req.method} {req.url}\"))\n            page.on(\"response\", lambda resp: print(f\"\u2190 {resp.status} {resp.url}\"))\n\n            # Navigate with detailed logging\n            url = f\"https://poe.com/{model_id}\"\n            print(f\"Navigating to: {url}\")\n\n            await page.goto(url, timeout=30000)\n            print(\"Navigation complete\")\n\n            # Take screenshot for debugging\n            await page.screenshot(path=f\"debug_{model_id}.png\")\n            print(f\"Screenshot saved: debug_{model_id}.png\")\n\n            # Check for pricing table\n            pricing_tables = await page.query_selector_all(\"table\")\n            print(f\"Found {len(pricing_tables)} tables\")\n\n            # Check for bot info\n            creator_elements = await page.query_selector_all(\"span:has-text('@')\")\n            print(f\"Found {len(creator_elements)} potential creator elements\")\n\n            # Get page content for manual inspection\n            content = await page.content()\n            with open(f\"debug_{model_id}.html\", \"w\") as f:\n                f.write(content)\n            print(f\"Page content saved: debug_{model_id}.html\")\n\n        finally:\n            await page.close()\n</code></pre>"},{"location":"chapter7-browser.html#performance-issues","title":"Performance Issues","text":"<pre><code>async def monitor_scraping_performance():\n    \"\"\"Monitor and report scraping performance metrics.\"\"\"\n\n    from virginia_clemm_poe.utils.timeout import with_timeout\n    import time\n\n    start_time = time.time()\n    model_count = 0\n    error_count = 0\n\n    try:\n        # Sample a few models for performance testing\n        test_models = [\"Claude-3-Opus\", \"GPT-4\", \"Claude-3-Sonnet\"]\n\n        for model_id in test_models:\n            model_start = time.time()\n\n            try:\n                async with with_timeout(30.0):\n                    await scrape_single_model_safe(model_id)\n\n                model_time = time.time() - model_start\n                print(f\"\u2713 {model_id}: {model_time:.2f}s\")\n                model_count += 1\n\n            except Exception as e:\n                print(f\"\u2717 {model_id}: {e}\")\n                error_count += 1\n\n        total_time = time.time() - start_time\n        success_rate = model_count / (model_count + error_count) * 100\n        avg_time = total_time / len(test_models)\n\n        print(f\"\\nPerformance Summary:\")\n        print(f\"Total time: {total_time:.2f}s\")\n        print(f\"Average per model: {avg_time:.2f}s\")\n        print(f\"Success rate: {success_rate:.1f}%\")\n\n    except Exception as e:\n        print(f\"Performance monitoring failed: {e}\")\n</code></pre>"},{"location":"chapter7-browser.html#best-practices","title":"Best Practices","text":""},{"location":"chapter7-browser.html#ethical-scraping","title":"Ethical Scraping","text":"<ol> <li>Rate Limiting: Respect server resources with delays between requests</li> <li>Error Handling: Gracefully handle failures without overwhelming the server</li> <li>User Agent: Use appropriate user agent strings</li> <li>Retry Logic: Implement exponential backoff for retries</li> </ol>"},{"location":"chapter7-browser.html#resource-management","title":"Resource Management","text":"<ol> <li>Browser Pooling: Reuse browser instances to reduce overhead</li> <li>Memory Monitoring: Track memory usage and trigger cleanup</li> <li>Connection Cleanup: Always close pages and browsers properly</li> <li>Timeout Handling: Set reasonable timeouts to prevent hangs</li> </ol>"},{"location":"chapter7-browser.html#reliability","title":"Reliability","text":"<ol> <li>Error Recovery: Handle network issues and browser crashes</li> <li>Data Validation: Validate scraped data before storage</li> <li>Fallback Strategies: Have backup selectors for critical elements</li> <li>Logging: Comprehensive logging for debugging and monitoring</li> </ol> <p>This comprehensive guide to browser management and web scraping provides the foundation for understanding and extending Virginia Clemm Poe's data collection capabilities.</p>"},{"location":"chapter8-configuration.html","title":"Chapter 8: Configuration and Advanced Usage","text":""},{"location":"chapter8-configuration.html#overview","title":"Overview","text":"<p>Virginia Clemm Poe provides extensive configuration options for customizing behavior, performance tuning, and integration with different environments. This chapter covers advanced configuration, custom integrations, and power-user features.</p>"},{"location":"chapter8-configuration.html#configuration-system","title":"Configuration System","text":""},{"location":"chapter8-configuration.html#configuration-hierarchy","title":"Configuration Hierarchy","text":"<p>Configuration is loaded in order of precedence:</p> <ol> <li>Command-line arguments (highest priority)</li> <li>Environment variables</li> <li>Configuration files</li> <li>Default values (lowest priority)</li> </ol>"},{"location":"chapter8-configuration.html#configuration-file-locations","title":"Configuration File Locations","text":"<p>Linux/macOS: <pre><code># Primary config file\n~/.config/virginia-clemm-poe/config.json\n\n# Alternative locations\n~/.virginia-clemm-poe/config.json\n./virginia-clemm-poe.json\n</code></pre></p> <p>Windows: <pre><code># Primary config file\n%APPDATA%\\virginia-clemm-poe\\config.json\n\n# Alternative locations\n%USERPROFILE%\\.virginia-clemm-poe\\config.json\n.\\virginia-clemm-poe.json\n</code></pre></p>"},{"location":"chapter8-configuration.html#configuration-schema","title":"Configuration Schema","text":"<pre><code>{\n  \"api\": {\n    \"key\": \"your_poe_api_key\",\n    \"base_url\": \"https://api.poe.com/v2\",\n    \"timeout\": 30,\n    \"retry_count\": 3,\n    \"rate_limit\": {\n      \"requests_per_minute\": 60,\n      \"burst_limit\": 10\n    }\n  },\n  \"browser\": {\n    \"headless\": true,\n    \"debug_port_start\": 9222,\n    \"max_browsers\": 3,\n    \"timeout\": 30000,\n    \"user_agent\": \"virginia-clemm-poe/1.0\",\n    \"viewport\": {\n      \"width\": 1920,\n      \"height\": 1080\n    },\n    \"chrome_args\": [\n      \"--no-sandbox\",\n      \"--disable-dev-shm-usage\"\n    ]\n  },\n  \"scraping\": {\n    \"concurrent_limit\": 5,\n    \"pause_between_requests\": 1.0,\n    \"retry_delay\": 2.0,\n    \"max_retries\": 3,\n    \"selectors\": {\n      \"pricing_table\": [\n        \"table[data-testid='pricing']\",\n        \".pricing-table\"\n      ],\n      \"bot_creator\": [\n        \"[data-testid='bot-creator']\",\n        \".bot-creator\"\n      ]\n    }\n  },\n  \"cache\": {\n    \"enabled\": true,\n    \"api_cache\": {\n      \"ttl\": 600,\n      \"max_size\": 1000\n    },\n    \"scraping_cache\": {\n      \"ttl\": 3600,\n      \"max_size\": 5000\n    },\n    \"global_cache\": {\n      \"ttl\": 1800,\n      \"max_size\": 2000\n    }\n  },\n  \"storage\": {\n    \"data_file\": \"~/.local/share/virginia-clemm-poe/poe_models.json\",\n    \"backup_count\": 5,\n    \"auto_backup\": true,\n    \"compression\": false\n  },\n  \"logging\": {\n    \"level\": \"INFO\",\n    \"file\": \"~/.local/share/virginia-clemm-poe/logs/app.log\",\n    \"max_size\": \"10MB\",\n    \"backup_count\": 5,\n    \"format\": \"{time:YYYY-MM-DD HH:mm:ss} | {level:&lt;8} | {name}:{function}:{line} | {message}\",\n    \"structured\": true\n  },\n  \"performance\": {\n    \"memory_limit\": \"512MB\",\n    \"gc_threshold\": 0.8,\n    \"enable_profiling\": false,\n    \"metrics_enabled\": true\n  }\n}\n</code></pre>"},{"location":"chapter8-configuration.html#environment-variables","title":"Environment Variables","text":""},{"location":"chapter8-configuration.html#core-configuration","title":"Core Configuration","text":"<pre><code># API Configuration\nexport POE_API_KEY=\"your_poe_api_key_here\"\nexport VCP_API_BASE_URL=\"https://api.poe.com/v2\"\nexport VCP_API_TIMEOUT=\"30\"\n\n# Browser Configuration\nexport VCP_HEADLESS=\"true\"\nexport VCP_DEBUG_PORT=\"9222\"\nexport VCP_BROWSER_TIMEOUT=\"30000\"\nexport VCP_USER_AGENT=\"virginia-clemm-poe/1.0\"\n\n# Scraping Configuration\nexport VCP_CONCURRENT_LIMIT=\"5\"\nexport VCP_PAUSE_SECONDS=\"1.0\"\nexport VCP_MAX_RETRIES=\"3\"\n\n# Cache Configuration\nexport VCP_CACHE_ENABLED=\"true\"\nexport VCP_CACHE_TTL=\"3600\"\nexport VCP_CACHE_MAX_SIZE=\"5000\"\n\n# Logging Configuration\nexport VCP_LOG_LEVEL=\"INFO\"\nexport VCP_LOG_FILE=\"~/.local/share/virginia-clemm-poe/logs/app.log\"\nexport VCP_STRUCTURED_LOGGING=\"true\"\n\n# Storage Configuration\nexport VCP_DATA_FILE=\"~/.local/share/virginia-clemm-poe/poe_models.json\"\nexport VCP_BACKUP_COUNT=\"5\"\nexport VCP_AUTO_BACKUP=\"true\"\n\n# Performance Configuration\nexport VCP_MEMORY_LIMIT=\"512MB\"\nexport VCP_GC_THRESHOLD=\"0.8\"\nexport VCP_ENABLE_PROFILING=\"false\"\n</code></pre>"},{"location":"chapter8-configuration.html#advanced-environment-variables","title":"Advanced Environment Variables","text":"<pre><code># Network Configuration\nexport HTTP_PROXY=\"http://proxy.example.com:8080\"\nexport HTTPS_PROXY=\"http://proxy.example.com:8080\"\nexport NO_PROXY=\"localhost,127.0.0.1\"\n\n# Browser Engine Selection\nexport CHROME_PATH=\"/path/to/custom/chrome\"\nexport VCP_USER_DATA_DIR=\"/path/to/user/data\"\nexport VCP_DISABLE_EXTENSIONS=\"true\"\n\n# Development Configuration\nexport VCP_DEBUG=\"true\"\nexport VCP_PROFILE_MEMORY=\"true\"\nexport VCP_SAVE_SCREENSHOTS=\"true\"\nexport VCP_SAVE_PAGE_CONTENT=\"true\"\n\n# CI/CD Configuration\nexport VCP_CI_MODE=\"true\"\nexport VCP_NON_INTERACTIVE=\"true\"\nexport VCP_FAIL_FAST=\"true\"\n</code></pre>"},{"location":"chapter8-configuration.html#advanced-configuration-examples","title":"Advanced Configuration Examples","text":""},{"location":"chapter8-configuration.html#high-performance-configuration","title":"High-Performance Configuration","text":"<p>For servers with ample resources:</p> <pre><code>{\n  \"browser\": {\n    \"max_browsers\": 10,\n    \"debug_port_start\": 9222,\n    \"timeout\": 60000\n  },\n  \"scraping\": {\n    \"concurrent_limit\": 20,\n    \"pause_between_requests\": 0.5,\n    \"max_retries\": 5\n  },\n  \"cache\": {\n    \"api_cache\": {\n      \"ttl\": 300,\n      \"max_size\": 5000\n    },\n    \"scraping_cache\": {\n      \"ttl\": 1800,\n      \"max_size\": 20000\n    }\n  },\n  \"performance\": {\n    \"memory_limit\": \"2GB\",\n    \"gc_threshold\": 0.7,\n    \"enable_profiling\": true\n  }\n}\n</code></pre>"},{"location":"chapter8-configuration.html#low-resource-configuration","title":"Low-Resource Configuration","text":"<p>For resource-constrained environments:</p> <pre><code>{\n  \"browser\": {\n    \"max_browsers\": 1,\n    \"timeout\": 15000,\n    \"chrome_args\": [\n      \"--no-sandbox\",\n      \"--disable-dev-shm-usage\",\n      \"--memory-pressure-off\",\n      \"--max_old_space_size=256\"\n    ]\n  },\n  \"scraping\": {\n    \"concurrent_limit\": 1,\n    \"pause_between_requests\": 2.0,\n    \"max_retries\": 2\n  },\n  \"cache\": {\n    \"api_cache\": {\n      \"max_size\": 100\n    },\n    \"scraping_cache\": {\n      \"max_size\": 500\n    }\n  },\n  \"performance\": {\n    \"memory_limit\": \"128MB\",\n    \"gc_threshold\": 0.6\n  }\n}\n</code></pre>"},{"location":"chapter8-configuration.html#development-configuration","title":"Development Configuration","text":"<p>For development and debugging:</p> <pre><code>{\n  \"browser\": {\n    \"headless\": false,\n    \"debug_port_start\": 9222,\n    \"chrome_args\": [\n      \"--disable-blink-features=AutomationControlled\",\n      \"--disable-extensions-except=/path/to/dev/extension\",\n      \"--load-extension=/path/to/dev/extension\"\n    ]\n  },\n  \"scraping\": {\n    \"pause_between_requests\": 3.0,\n    \"save_screenshots\": true,\n    \"save_page_content\": true\n  },\n  \"logging\": {\n    \"level\": \"DEBUG\",\n    \"structured\": true,\n    \"enable_console\": true\n  },\n  \"performance\": {\n    \"enable_profiling\": true,\n    \"metrics_enabled\": true\n  }\n}\n</code></pre>"},{"location":"chapter8-configuration.html#advanced-api-usage","title":"Advanced API Usage","text":""},{"location":"chapter8-configuration.html#custom-configuration-loading","title":"Custom Configuration Loading","text":"<pre><code>from virginia_clemm_poe.config import load_config, Config\n\n# Load configuration with custom file\nconfig = load_config(\"/path/to/custom/config.json\")\n\n# Override specific settings\nconfig.browser.headless = False\nconfig.scraping.concurrent_limit = 1\n\n# Use configuration in API calls\nfrom virginia_clemm_poe import api\napi.configure(config)\n</code></pre>"},{"location":"chapter8-configuration.html#configuration-validation","title":"Configuration Validation","text":"<pre><code>from virginia_clemm_poe.config import validate_config, ConfigValidationError\n\ntry:\n    config = load_config()\n    validate_config(config)\n    print(\"Configuration is valid\")\nexcept ConfigValidationError as e:\n    print(f\"Configuration error: {e}\")\n    # Handle invalid configuration\n</code></pre>"},{"location":"chapter8-configuration.html#dynamic-configuration-updates","title":"Dynamic Configuration Updates","text":"<pre><code>from virginia_clemm_poe.config import get_runtime_config, update_runtime_config\n\n# Get current runtime configuration\nruntime_config = get_runtime_config()\n\n# Update configuration at runtime\nupdate_runtime_config({\n    \"scraping.concurrent_limit\": 3,\n    \"cache.api_cache.ttl\": 1200\n})\n\n# Changes take effect immediately for new operations\n</code></pre>"},{"location":"chapter8-configuration.html#performance-tuning","title":"Performance Tuning","text":""},{"location":"chapter8-configuration.html#memory-optimization","title":"Memory Optimization","text":"<pre><code>from virginia_clemm_poe.utils.memory import configure_memory_management\n\n# Configure memory management\nconfigure_memory_management(\n    limit=\"512MB\",\n    gc_threshold=0.8,\n    enable_monitoring=True\n)\n\n# Monitor memory usage during operations\nfrom virginia_clemm_poe.utils.memory import get_memory_stats\n\nstats = get_memory_stats()\nprint(f\"Memory usage: {stats['used_mb']:.1f}MB / {stats['limit_mb']:.1f}MB\")\nprint(f\"GC collections: {stats['gc_collections']}\")\n</code></pre>"},{"location":"chapter8-configuration.html#cache-optimization","title":"Cache Optimization","text":"<pre><code>from virginia_clemm_poe.utils.cache import configure_caches, get_cache_stats\n\n# Configure cache settings\nconfigure_caches({\n    \"api_cache\": {\"ttl\": 300, \"max_size\": 1000},\n    \"scraping_cache\": {\"ttl\": 1800, \"max_size\": 5000},\n    \"global_cache\": {\"ttl\": 900, \"max_size\": 2000}\n})\n\n# Monitor cache performance\nstats = get_cache_stats()\nfor cache_name, cache_stats in stats.items():\n    hit_rate = cache_stats['hit_rate_percent']\n    print(f\"{cache_name}: {hit_rate:.1f}% hit rate\")\n</code></pre>"},{"location":"chapter8-configuration.html#concurrent-processing","title":"Concurrent Processing","text":"<pre><code>from virginia_clemm_poe.updater import ModelUpdater\nimport asyncio\n\nasync def optimized_update():\n    updater = ModelUpdater(\n        api_key=\"your_key\",\n        concurrent_limit=10,  # Increase concurrency\n        batch_size=20,        # Larger batches\n        retry_delay=1.0       # Faster retries\n    )\n\n    # Update with optimized settings\n    await updater.update_all(\n        force=False,           # Only update what's needed\n        update_pricing=True,   # Focus on pricing data\n        update_info=False      # Skip bot info for speed\n    )\n\n# Run optimized update\nasyncio.run(optimized_update())\n</code></pre>"},{"location":"chapter8-configuration.html#integration-patterns","title":"Integration Patterns","text":""},{"location":"chapter8-configuration.html#web-framework-integration","title":"Web Framework Integration","text":""},{"location":"chapter8-configuration.html#fastapi-integration","title":"FastAPI Integration","text":"<pre><code>from fastapi import FastAPI, BackgroundTasks\nfrom virginia_clemm_poe import api\nfrom virginia_clemm_poe.config import load_config\n\napp = FastAPI()\n\n# Load configuration on startup\n@app.on_event(\"startup\")\nasync def startup_event():\n    config = load_config()\n    api.configure(config)\n\n@app.get(\"/models/search/{query}\")\nasync def search_models(query: str):\n    models = api.search_models(query)\n    return {\"query\": query, \"models\": models}\n\n@app.post(\"/admin/update\")\nasync def trigger_update(background_tasks: BackgroundTasks):\n    background_tasks.add_task(run_update_task)\n    return {\"message\": \"Update started\"}\n\nasync def run_update_task():\n    from virginia_clemm_poe.updater import ModelUpdater\n    updater = ModelUpdater(api_key=os.environ[\"POE_API_KEY\"])\n    await updater.update_all()\n</code></pre>"},{"location":"chapter8-configuration.html#django-integration","title":"Django Integration","text":"<pre><code># settings.py\nVIRGINIA_CLEMM_POE = {\n    'API_KEY': os.environ.get('POE_API_KEY'),\n    'CACHE_ENABLED': True,\n    'CONCURRENT_LIMIT': 5,\n    'DATA_FILE': os.path.join(BASE_DIR, 'data', 'poe_models.json')\n}\n\n# management/commands/update_models.py\nfrom django.core.management.base import BaseCommand\nfrom virginia_clemm_poe.updater import ModelUpdater\nimport asyncio\n\nclass Command(BaseCommand):\n    help = 'Update Poe model data'\n\n    def handle(self, *args, **options):\n        from django.conf import settings\n\n        updater = ModelUpdater(\n            api_key=settings.VIRGINIA_CLEMM_POE['API_KEY']\n        )\n        asyncio.run(updater.update_all())\n\n        self.stdout.write(\n            self.style.SUCCESS('Successfully updated model data')\n        )\n</code></pre>"},{"location":"chapter8-configuration.html#database-integration","title":"Database Integration","text":""},{"location":"chapter8-configuration.html#sqlalchemy-integration","title":"SQLAlchemy Integration","text":"<pre><code>from sqlalchemy import create_engine, Column, String, DateTime, Text\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nimport json\n\nBase = declarative_base()\n\nclass PoeModelRecord(Base):\n    __tablename__ = 'poe_models'\n\n    id = Column(String, primary_key=True)\n    model_name = Column(String)\n    owned_by = Column(String)\n    created = Column(DateTime)\n    pricing_data = Column(Text)  # JSON\n    bot_info_data = Column(Text)  # JSON\n    last_updated = Column(DateTime)\n\ndef sync_to_database():\n    \"\"\"Sync Virginia Clemm Poe data to database.\"\"\"\n    from virginia_clemm_poe import api\n\n    engine = create_engine('sqlite:///poe_models.db')\n    Base.metadata.create_all(engine)\n    Session = sessionmaker(bind=engine)\n    session = Session()\n\n    models = api.get_all_models()\n\n    for model in models:\n        record = session.query(PoeModelRecord).filter_by(id=model.id).first()\n        if not record:\n            record = PoeModelRecord(id=model.id)\n            session.add(record)\n\n        record.model_name = model.model_name\n        record.owned_by = model.owned_by\n        record.created = datetime.fromtimestamp(model.created)\n        record.pricing_data = json.dumps(model.pricing.model_dump() if model.pricing else None)\n        record.bot_info_data = json.dumps(model.bot_info.model_dump() if model.bot_info else None)\n        record.last_updated = datetime.utcnow()\n\n    session.commit()\n    session.close()\n</code></pre>"},{"location":"chapter8-configuration.html#monitoring-integration","title":"Monitoring Integration","text":""},{"location":"chapter8-configuration.html#prometheus-metrics","title":"Prometheus Metrics","text":"<pre><code>from prometheus_client import Counter, Histogram, Gauge, start_http_server\nfrom virginia_clemm_poe.utils.metrics import register_metrics\n\n# Register custom metrics\nSCRAPING_REQUESTS = Counter('vcp_scraping_requests_total', 'Total scraping requests', ['model_id', 'status'])\nSCRAPING_DURATION = Histogram('vcp_scraping_duration_seconds', 'Scraping request duration', ['model_id'])\nCACHE_HIT_RATE = Gauge('vcp_cache_hit_rate', 'Cache hit rate', ['cache_name'])\n\ndef monitor_scraping():\n    \"\"\"Monitor scraping operations with Prometheus metrics.\"\"\"\n\n    @SCRAPING_DURATION.time()\n    def scrape_with_metrics(model_id):\n        try:\n            result = scrape_model(model_id)\n            SCRAPING_REQUESTS.labels(model_id=model_id, status='success').inc()\n            return result\n        except Exception as e:\n            SCRAPING_REQUESTS.labels(model_id=model_id, status='error').inc()\n            raise\n\n    # Start metrics server\n    start_http_server(8000)\n\n    return scrape_with_metrics\n</code></pre>"},{"location":"chapter8-configuration.html#grafana-dashboard","title":"Grafana Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Virginia Clemm Poe Monitoring\",\n    \"panels\": [\n      {\n        \"title\": \"Scraping Success Rate\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(vcp_scraping_requests_total{status=\\\"success\\\"}[5m]) / rate(vcp_scraping_requests_total[5m]) * 100\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Cache Hit Rates\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"vcp_cache_hit_rate\",\n            \"legendFormat\": \"{{cache_name}}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Scraping Duration\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, rate(vcp_scraping_duration_seconds_bucket[5m]))\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"chapter8-configuration.html#security-configuration","title":"Security Configuration","text":""},{"location":"chapter8-configuration.html#api-key-management","title":"API Key Management","text":"<pre><code># Using environment variables (recommended)\nimport os\napi_key = os.environ.get('POE_API_KEY')\n\n# Using keyring for secure storage\nimport keyring\nkeyring.set_password('virginia-clemm-poe', 'api_key', 'your_key')\napi_key = keyring.get_password('virginia-clemm-poe', 'api_key')\n\n# Using AWS Secrets Manager\nimport boto3\nclient = boto3.client('secretsmanager')\nresponse = client.get_secret_value(SecretId='virginia-clemm-poe/api-key')\napi_key = response['SecretString']\n</code></pre>"},{"location":"chapter8-configuration.html#network-security","title":"Network Security","text":"<pre><code># Configure proxy settings\nimport httpx\n\nproxy_config = {\n    'http://': 'http://proxy.example.com:8080',\n    'https://': 'http://proxy.example.com:8080'\n}\n\n# SSL/TLS configuration\nssl_config = {\n    'verify': True,  # Verify SSL certificates\n    'cert': '/path/to/client/cert.pem',  # Client certificate\n    'trust_env': True  # Trust environment proxy settings\n}\n\n# Configure HTTP client with security settings\nclient = httpx.AsyncClient(\n    proxies=proxy_config,\n    **ssl_config,\n    timeout=30.0\n)\n</code></pre>"},{"location":"chapter8-configuration.html#data-security","title":"Data Security","text":"<pre><code># Encrypt sensitive data at rest\nfrom cryptography.fernet import Fernet\n\ndef encrypt_data_file(data_file_path: str, key: bytes):\n    \"\"\"Encrypt model data file.\"\"\"\n    fernet = Fernet(key)\n\n    with open(data_file_path, 'rb') as f:\n        data = f.read()\n\n    encrypted_data = fernet.encrypt(data)\n\n    with open(f\"{data_file_path}.encrypted\", 'wb') as f:\n        f.write(encrypted_data)\n\ndef decrypt_data_file(encrypted_file_path: str, key: bytes) -&gt; dict:\n    \"\"\"Decrypt and load model data.\"\"\"\n    fernet = Fernet(key)\n\n    with open(encrypted_file_path, 'rb') as f:\n        encrypted_data = f.read()\n\n    decrypted_data = fernet.decrypt(encrypted_data)\n    return json.loads(decrypted_data)\n</code></pre>"},{"location":"chapter8-configuration.html#deployment-configurations","title":"Deployment Configurations","text":""},{"location":"chapter8-configuration.html#docker-configuration","title":"Docker Configuration","text":"<pre><code># Dockerfile\nFROM python:3.12-slim\n\n# Install system dependencies for Chrome\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    wget \\\n    gnupg \\\n    ca-certificates \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install Virginia Clemm Poe\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Create app user\nRUN useradd -m -u 1000 vcp\nUSER vcp\n\n# Setup application\nWORKDIR /app\nCOPY --chown=vcp:vcp . .\n\n# Setup browser\nRUN virginia-clemm-poe setup\n\n# Configuration\nENV VCP_HEADLESS=true\nENV VCP_LOG_LEVEL=INFO\nENV VCP_CACHE_ENABLED=true\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=60s \\\n    CMD virginia-clemm-poe status || exit 1\n\nCMD [\"virginia-clemm-poe\", \"update\", \"--all\"]\n</code></pre>"},{"location":"chapter8-configuration.html#kubernetes-configuration","title":"Kubernetes Configuration","text":"<pre><code># deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: virginia-clemm-poe\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: virginia-clemm-poe\n  template:\n    metadata:\n      labels:\n        app: virginia-clemm-poe\n    spec:\n      containers:\n      - name: virginia-clemm-poe\n        image: virginia-clemm-poe:latest\n        env:\n        - name: POE_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: poe-api-key\n              key: api-key\n        - name: VCP_HEADLESS\n          value: \"true\"\n        - name: VCP_LOG_LEVEL\n          value: \"INFO\"\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n        volumeMounts:\n        - name: data-volume\n          mountPath: /data\n        - name: config-volume\n          mountPath: /config\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: vcp-data\n      - name: config-volume\n        configMap:\n          name: vcp-config\n</code></pre> <p>This comprehensive configuration guide provides everything needed to customize and optimize Virginia Clemm Poe for any environment or use case.</p>"},{"location":"chapter9-troubleshooting.html","title":"Chapter 9: Troubleshooting and FAQ","text":""},{"location":"chapter9-troubleshooting.html#quick-diagnostics","title":"Quick Diagnostics","text":""},{"location":"chapter9-troubleshooting.html#health-check-commands","title":"Health Check Commands","text":"<p>Start with these commands to identify issues:</p> <pre><code># Comprehensive system check\nvirginia-clemm-poe doctor\n\n# Check current status\nvirginia-clemm-poe status\n\n# Test basic functionality\nvirginia-clemm-poe search \"test\"\n\n# Clear cache if issues persist\nvirginia-clemm-poe clear-cache\n</code></pre>"},{"location":"chapter9-troubleshooting.html#common-issue-indicators","title":"Common Issue Indicators","text":"Symptom Likely Cause Quick Fix \"No model data found\" Missing or corrupted data file <code>virginia-clemm-poe update</code> \"POE_API_KEY not set\" Missing API key <code>export POE_API_KEY=your_key</code> \"Browser not available\" Chrome not installed <code>virginia-clemm-poe setup</code> \"Cannot reach poe.com\" Network connectivity Check internet/proxy settings Slow updates Resource constraints Reduce concurrent limit"},{"location":"chapter9-troubleshooting.html#installation-issues","title":"Installation Issues","text":""},{"location":"chapter9-troubleshooting.html#python-version-problems","title":"Python Version Problems","text":"<p>Error: <code>Package requires Python 3.12+</code></p> <p>Solution: <pre><code># Check current version\npython --version\n\n# Install Python 3.12+ using pyenv\ncurl https://pyenv.run | bash\npyenv install 3.12.0\npyenv global 3.12.0\n\n# Or use system package manager\n# Ubuntu/Debian:\nsudo apt update &amp;&amp; sudo apt install python3.12\n\n# macOS:\nbrew install python@3.12\n</code></pre></p>"},{"location":"chapter9-troubleshooting.html#package-installation-failures","title":"Package Installation Failures","text":"<p>Error: <code>pip install virginia-clemm-poe fails</code></p> <p>Common causes and solutions:</p> <ol> <li> <p>Outdated pip: <pre><code>pip install --upgrade pip\npip install virginia-clemm-poe\n</code></pre></p> </li> <li> <p>Network issues: <pre><code>pip install --trusted-host pypi.org --trusted-host pypi.python.org virginia-clemm-poe\n</code></pre></p> </li> <li> <p>Permission errors: <pre><code>pip install --user virginia-clemm-poe\n# or\npython -m pip install virginia-clemm-poe\n</code></pre></p> </li> <li> <p>Dependency conflicts: <pre><code># Create clean environment\npython -m venv fresh_env\nsource fresh_env/bin/activate\npip install virginia-clemm-poe\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#browser-setup-issues","title":"Browser Setup Issues","text":"<p>Error: <code>Failed to install browser dependencies</code></p> <p>Solutions:</p> <ol> <li> <p>Manual Chrome installation: <pre><code># Ubuntu/Debian\nwget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -\nsudo sh -c 'echo \"deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main\" &gt;&gt; /etc/apt/sources.list.d/google-chrome.list'\nsudo apt update &amp;&amp; sudo apt install google-chrome-stable\n\n# macOS\nbrew install --cask google-chrome\n\n# Windows\n# Download from https://www.google.com/chrome/\n</code></pre></p> </li> <li> <p>Check disk space: <pre><code>df -h  # Ensure at least 500MB free space\n</code></pre></p> </li> <li> <p>Permissions: <pre><code># Fix cache directory permissions\nchmod -R 755 ~/.cache/virginia-clemm-poe/\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#api-and-authentication-issues","title":"API and Authentication Issues","text":""},{"location":"chapter9-troubleshooting.html#api-key-problems","title":"API Key Problems","text":"<p>Error: <code>Invalid API key</code> or <code>Authentication failed</code></p> <p>Solutions:</p> <ol> <li> <p>Verify API key format: <pre><code># API key should be a long alphanumeric string\necho $POE_API_KEY | wc -c  # Should be 40+ characters\n</code></pre></p> </li> <li> <p>Get new API key:</p> </li> <li>Visit https://poe.com/api_key</li> <li>Generate new key</li> <li> <p>Update environment variable</p> </li> <li> <p>Check key permissions:</p> </li> <li>Ensure key has model listing permissions</li> <li>Some keys may be rate-limited</li> </ol>"},{"location":"chapter9-troubleshooting.html#network-connectivity-issues","title":"Network Connectivity Issues","text":"<p>Error: <code>Cannot reach poe.com</code> or <code>Connection timeout</code></p> <p>Solutions:</p> <ol> <li> <p>Test connectivity: <pre><code>curl -I https://poe.com\ncurl -I https://api.poe.com/v2/models\n</code></pre></p> </li> <li> <p>Proxy configuration: <pre><code>export HTTP_PROXY=\"http://proxy.example.com:8080\"\nexport HTTPS_PROXY=\"http://proxy.example.com:8080\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>Corporate firewall:</p> </li> <li>Contact IT for API access approval</li> <li>Use corporate proxy settings</li> <li> <p>Consider VPN if needed</p> </li> <li> <p>DNS issues: <pre><code># Test DNS resolution\nnslookup poe.com\n# Try different DNS servers\nexport DNS_SERVER=\"8.8.8.8\"\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#browser-and-scraping-issues","title":"Browser and Scraping Issues","text":""},{"location":"chapter9-troubleshooting.html#browser-launch-failures","title":"Browser Launch Failures","text":"<p>Error: <code>Failed to get browser</code> or <code>Chrome process exited</code></p> <p>Solutions:</p> <ol> <li> <p>Check Chrome installation: <pre><code># Test manual Chrome launch\ngoogle-chrome --version\nchromium --version\n</code></pre></p> </li> <li> <p>Port conflicts: <pre><code># Check if port is in use\nnetstat -tulpn | grep :9222\n\n# Use different port\nvirginia-clemm-poe update --debug_port 9223\n</code></pre></p> </li> <li> <p>Insufficient resources: <pre><code># Check system resources\nfree -m  # Memory\ndf -h    # Disk space\n\n# Use low-resource mode\nexport VCP_MEMORY_LIMIT=\"256MB\"\nvirginia-clemm-poe update --verbose\n</code></pre></p> </li> <li> <p>Headless mode issues: <pre><code># Try non-headless mode for debugging\nexport VCP_HEADLESS=\"false\"\nvirginia-clemm-poe update --verbose\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#scraping-timeouts","title":"Scraping Timeouts","text":"<p>Error: <code>Navigation timeout</code> or <code>Element not found</code></p> <p>Solutions:</p> <ol> <li> <p>Increase timeouts: <pre><code>export VCP_TIMEOUT=\"60000\"  # 60 seconds\nvirginia-clemm-poe update --verbose\n</code></pre></p> </li> <li> <p>Reduce concurrency: <pre><code>export VCP_CONCURRENT_LIMIT=\"1\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>Network delays: <pre><code>export VCP_PAUSE_SECONDS=\"3.0\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>Debug specific models: <pre><code># Enable verbose logging\nvirginia-clemm-poe update --verbose\n\n# Check logs for failing models\ntail -f ~/.local/share/virginia-clemm-poe/logs/app.log\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#anti-bot-detection","title":"Anti-Bot Detection","text":"<p>Error: <code>Access denied</code> or <code>Captcha required</code></p> <p>Solutions:</p> <ol> <li> <p>Rate limiting: <pre><code># Slow down requests\nexport VCP_PAUSE_SECONDS=\"5.0\"\nexport VCP_CONCURRENT_LIMIT=\"1\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>User agent rotation: <pre><code>export VCP_USER_AGENT=\"Mozilla/5.0 (compatible; virginia-clemm-poe/1.0)\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>Proxy rotation: <pre><code># Use different proxy\nexport HTTP_PROXY=\"http://proxy2.example.com:8080\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>Wait and retry: <pre><code># Wait before retrying\nsleep 3600  # 1 hour\nvirginia-clemm-poe update --force\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#performance-issues","title":"Performance Issues","text":""},{"location":"chapter9-troubleshooting.html#slow-updates","title":"Slow Updates","text":"<p>Problem: Updates take too long</p> <p>Solutions:</p> <ol> <li> <p>Increase concurrency (if resources allow): <pre><code>export VCP_CONCURRENT_LIMIT=\"10\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>Selective updates: <pre><code># Update only pricing\nvirginia-clemm-poe update --pricing\n\n# Skip force update\nvirginia-clemm-poe update  # Only updates missing data\n</code></pre></p> </li> <li> <p>Cache optimization: <pre><code># Clear old cache\nvirginia-clemm-poe clear-cache\n\n# Optimize cache settings\nexport VCP_CACHE_TTL=\"7200\"  # 2 hours\nvirginia-clemm-poe update\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#memory-issues","title":"Memory Issues","text":"<p>Error: <code>Out of memory</code> or system becomes unresponsive</p> <p>Solutions:</p> <ol> <li> <p>Reduce memory usage: <pre><code>export VCP_MEMORY_LIMIT=\"256MB\"\nexport VCP_CONCURRENT_LIMIT=\"1\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>Enable garbage collection: <pre><code>export VCP_GC_THRESHOLD=\"0.7\"\nvirginia-clemm-poe update --verbose\n</code></pre></p> </li> <li> <p>Clear browser cache: <pre><code>virginia-clemm-poe clear-cache --browser\n</code></pre></p> </li> <li> <p>Process batching: <pre><code># Update in smaller batches\nvirginia-clemm-poe update --limit 50\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#high-cpu-usage","title":"High CPU Usage","text":"<p>Problem: Process uses too much CPU</p> <p>Solutions:</p> <ol> <li> <p>Reduce browser instances: <pre><code>export VCP_MAX_BROWSERS=\"1\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>Add delays: <pre><code>export VCP_PAUSE_SECONDS=\"2.0\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>Lower priority: <pre><code>nice -n 10 virginia-clemm-poe update\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#data-issues","title":"Data Issues","text":""},{"location":"chapter9-troubleshooting.html#corrupted-data-file","title":"Corrupted Data File","text":"<p>Error: <code>Invalid JSON</code> or <code>Validation error</code></p> <p>Solutions:</p> <ol> <li> <p>Restore from backup: <pre><code># Check for backups\nls ~/.local/share/virginia-clemm-poe/backups/\n\n# Restore latest backup\ncp ~/.local/share/virginia-clemm-poe/backups/poe_models_*.json \\\n   ~/.local/share/virginia-clemm-poe/poe_models.json\n</code></pre></p> </li> <li> <p>Force fresh update: <pre><code># Remove corrupted file\nrm ~/.local/share/virginia-clemm-poe/poe_models.json\n\n# Fetch fresh data\nvirginia-clemm-poe update --all\n</code></pre></p> </li> <li> <p>Validate data manually: <pre><code>import json\nfrom virginia_clemm_poe.config import DATA_FILE_PATH\n\ntry:\n    with open(DATA_FILE_PATH) as f:\n        data = json.load(f)\n    print(\"JSON is valid\")\nexcept json.JSONDecodeError as e:\n    print(f\"JSON error at line {e.lineno}: {e.msg}\")\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#missing-or-incomplete-data","title":"Missing or Incomplete Data","text":"<p>Problem: Some models missing pricing or bot info</p> <p>Solutions:</p> <ol> <li> <p>Force update specific areas: <pre><code># Update only missing pricing\nvirginia-clemm-poe update --pricing --force\n\n# Update only missing bot info\nvirginia-clemm-poe update --info --force\n</code></pre></p> </li> <li> <p>Check for errors: <pre><code># Look for pricing errors in data\nvirginia-clemm-poe search \"\" --verbose | grep -i error\n</code></pre></p> </li> <li> <p>Manual verification: <pre><code>from virginia_clemm_poe import api\n\n# Check data completeness\nmodels = api.get_all_models()\nneed_update = api.get_models_needing_update()\n\nprint(f\"Total models: {len(models)}\")\nprint(f\"Need update: {len(need_update)}\")\n\n# List models with errors\nfor model in models:\n    if model.pricing_error:\n        print(f\"{model.id}: {model.pricing_error}\")\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#environment-specific-issues","title":"Environment-Specific Issues","text":""},{"location":"chapter9-troubleshooting.html#docker-issues","title":"Docker Issues","text":"<p>Problem: Browser doesn't work in container</p> <p>Solutions:</p> <ol> <li> <p>Add required arguments: <pre><code>ENV VCP_CHROME_ARGS=\"--no-sandbox,--disable-dev-shm-usage,--disable-gpu\"\n</code></pre></p> </li> <li> <p>Install dependencies: <pre><code>RUN apt-get update &amp;&amp; apt-get install -y \\\n    fonts-liberation \\\n    libasound2 \\\n    libatk-bridge2.0-0 \\\n    libgtk-3-0 \\\n    libnspr4 \\\n    libnss3 \\\n    libx11-xcb1 \\\n    libxcomposite1 \\\n    libxss1 \\\n    xdg-utils\n</code></pre></p> </li> <li> <p>Use privileged mode: <pre><code>docker run --privileged virginia-clemm-poe\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#cicd-issues","title":"CI/CD Issues","text":"<p>Problem: Automated runs fail</p> <p>Solutions:</p> <ol> <li> <p>CI-specific configuration: <pre><code>export VCP_CI_MODE=\"true\"\nexport VCP_HEADLESS=\"true\"\nexport VCP_NON_INTERACTIVE=\"true\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>GitHub Actions example: <pre><code>- name: Setup browser\n  run: |\n    sudo apt-get update\n    sudo apt-get install -y google-chrome-stable\n    virginia-clemm-poe setup\n\n- name: Update models\n  env:\n    POE_API_KEY: ${{ secrets.POE_API_KEY }}\n    VCP_HEADLESS: true\n  run: virginia-clemm-poe update --all\n</code></pre></p> </li> <li> <p>Handle rate limits: <pre><code># Longer delays in CI\nexport VCP_PAUSE_SECONDS=\"10.0\"\nexport VCP_CONCURRENT_LIMIT=\"1\"\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#windows-specific-issues","title":"Windows-Specific Issues","text":"<p>Problem: Path or permission issues on Windows</p> <p>Solutions:</p> <ol> <li> <p>Use PowerShell: <pre><code>$env:POE_API_KEY=\"your_key\"\nvirginia-clemm-poe update\n</code></pre></p> </li> <li> <p>Fix path issues: <pre><code># Use full paths\n$env:VCP_DATA_FILE=\"C:\\Users\\YourName\\AppData\\Local\\virginia-clemm-poe\\poe_models.json\"\n</code></pre></p> </li> <li> <p>Antivirus exclusions:</p> </li> <li>Add virginia-clemm-poe cache directory to exclusions</li> <li>Temporarily disable real-time protection</li> </ol>"},{"location":"chapter9-troubleshooting.html#debugging-techniques","title":"Debugging Techniques","text":""},{"location":"chapter9-troubleshooting.html#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code># Maximum verbosity\nexport VCP_LOG_LEVEL=\"DEBUG\"\nvirginia-clemm-poe update --verbose 2&gt;&amp;1 | tee debug.log\n\n# Structured logging\nexport VCP_STRUCTURED_LOGGING=\"true\"\nvirginia-clemm-poe update --verbose\n</code></pre>"},{"location":"chapter9-troubleshooting.html#browser-debugging","title":"Browser Debugging","text":"<pre><code># Save screenshots and page content\nexport VCP_SAVE_SCREENSHOTS=\"true\"\nexport VCP_SAVE_PAGE_CONTENT=\"true\"\nvirginia-clemm-poe update --verbose\n\n# Check saved files\nls ~/.local/share/virginia-clemm-poe/debug/\n</code></pre>"},{"location":"chapter9-troubleshooting.html#network-debugging","title":"Network Debugging","text":"<pre><code># Monitor network traffic\nexport VCP_LOG_REQUESTS=\"true\"\nvirginia-clemm-poe update --verbose\n\n# Use proxy for inspection\nexport HTTP_PROXY=\"http://localhost:8080\"  # Burp Suite or similar\nvirginia-clemm-poe update\n</code></pre>"},{"location":"chapter9-troubleshooting.html#memory-debugging","title":"Memory Debugging","text":"<pre><code>from virginia_clemm_poe.utils.memory import enable_memory_profiling\n\n# Enable memory profiling\nenable_memory_profiling()\n\n# Run operation\nvirginia-clemm-poe update --verbose\n\n# Check memory report\ncat ~/.local/share/virginia-clemm-poe/logs/memory_profile.log\n</code></pre>"},{"location":"chapter9-troubleshooting.html#getting-help","title":"Getting Help","text":""},{"location":"chapter9-troubleshooting.html#information-to-gather","title":"Information to Gather","text":"<p>When seeking help, provide:</p> <ol> <li> <p>System information: <pre><code>virginia-clemm-poe doctor &gt; system_info.txt\npython --version\nuname -a  # Linux/macOS\nsysteminfo  # Windows\n</code></pre></p> </li> <li> <p>Error logs: <pre><code># Recent logs\ntail -n 100 ~/.local/share/virginia-clemm-poe/logs/app.log\n\n# Full debug run\nvirginia-clemm-poe update --verbose 2&gt;&amp;1 | tee full_debug.log\n</code></pre></p> </li> <li> <p>Configuration: <pre><code># Environment variables\nenv | grep VCP\n\n# Configuration file\ncat ~/.config/virginia-clemm-poe/config.json\n</code></pre></p> </li> </ol>"},{"location":"chapter9-troubleshooting.html#support-channels","title":"Support Channels","text":"<ol> <li>GitHub Issues: Create detailed issue</li> <li>Documentation: Check official docs</li> <li>Community: Join discussions and ask questions</li> </ol>"},{"location":"chapter9-troubleshooting.html#bug-report-template","title":"Bug Report Template","text":"<pre><code>## Bug Description\nBrief description of the issue\n\n## Steps to Reproduce\n1. Step one\n2. Step two\n3. Step three\n\n## Expected Behavior\nWhat should happen\n\n## Actual Behavior\nWhat actually happens\n\n## Environment\n- OS: \n- Python version: \n- Virginia Clemm Poe version: \n- Browser: \n\n## Logs\n```bash\n# Paste relevant logs here\n</code></pre>"},{"location":"chapter9-troubleshooting.html#configuration","title":"Configuration","text":"<pre><code>// Paste relevant config here\n</code></pre>"},{"location":"chapter9-troubleshooting.html#additional-context","title":"Additional Context","text":"<p>Any other relevant information ```</p>"},{"location":"chapter9-troubleshooting.html#frequently-asked-questions","title":"Frequently Asked Questions","text":""},{"location":"chapter9-troubleshooting.html#general-questions","title":"General Questions","text":"<p>Q: How often should I update the model data? A: Weekly updates are usually sufficient. More frequent updates may be needed when new models are released.</p> <p>Q: Can I use this without a Poe API key? A: No, the API key is required to fetch the initial model list from Poe.com.</p> <p>Q: Is it safe to run multiple update processes simultaneously? A: No, this can cause data corruption. Use the built-in concurrency controls instead.</p> <p>Q: Why are some models missing pricing data? A: Some models may have pricing errors, be in beta, or have updated page layouts that the scraper doesn't recognize yet.</p>"},{"location":"chapter9-troubleshooting.html#technical-questions","title":"Technical Questions","text":"<p>Q: How much data does the package store locally? A: Typically 2-10MB for the complete dataset, depending on the number of models.</p> <p>Q: Can I customize the scraping selectors? A: Yes, through configuration files or environment variables (see Chapter 8).</p> <p>Q: How do I integrate with my existing data pipeline? A: See the integration examples in Chapter 8 for database and API integrations.</p> <p>Q: What happens if Poe.com changes their website structure? A: The scraper may fail for new layouts. Update to the latest version or report the issue.</p>"},{"location":"chapter9-troubleshooting.html#performance-questions","title":"Performance Questions","text":"<p>Q: Why is the first update so slow? A: The first update scrapes all models. Subsequent updates only process changed models.</p> <p>Q: How can I speed up updates? A: Increase concurrency limits, use selective updates (--pricing or --info), and ensure good network connectivity.</p> <p>Q: Does the package cache data? A: Yes, it uses multiple cache layers for API responses, scraping results, and processed data.</p> <p>This comprehensive troubleshooting guide should help resolve most issues you might encounter with Virginia Clemm Poe.</p>"},{"location":"models/index.html","title":"Models Database","text":""},{"location":"models/index.html#interactive-table","title":"Interactive Table","text":""},{"location":"models/index.html#all-models","title":"All Models","text":"<p>Browse all available Poe models:</p> <ul> <li>App-Creator by @poe_tools</li> <li>Aya-Expanse-32B by @cohere</li> <li>Aya-Vision by @cohere</li> <li>Bria-Eraser by @fal</li> <li>Cartesia by @cartesiateam</li> <li>ChatGPT-4o-Latest by @openai</li> <li>Clarity-Upscaler by @fal</li> <li>Claude-Haiku-3 by @anthropic</li> <li>Claude-Haiku-3.5 by @anthropic</li> <li>Claude-Haiku-3.5-Search by @anthropic</li> <li>Claude-Opus-3 by @anthropic</li> <li>Claude-Opus-4 by @anthropic</li> <li>Claude-Opus-4-1 by @anthropic</li> <li>Claude-Opus-4-Reasoning by @anthropic</li> <li>Claude-Opus-4-Search by @anthropic</li> <li>Claude-Sonnet-3.5 by @anthropic</li> <li>Claude-Sonnet-3.5-June by @anthropic</li> <li>Claude-Sonnet-3.5-Search by @anthropic</li> <li>Claude-Sonnet-3.7 by @anthropic</li> <li>Claude-Sonnet-3.7-Reasoning by @anthropic</li> <li>Claude-Sonnet-3.7-Search by @anthropic</li> <li>Claude-Sonnet-4 by @anthropic</li> <li>Claude-Sonnet-4-Reasoning by @anthropic</li> <li>Claude-Sonnet-4-Search by @anthropic</li> <li>Command-R by @cohere</li> <li>Command-R-Plus by @cohere</li> <li>DALL-E-3 by @openai</li> <li>DeepClaude by @empiriolabsai</li> <li>DeepSeek-R1 by @togetherai</li> <li>DeepSeek-R1-DI by @deepinfra</li> <li>DeepSeek-R1-Distill by @groq</li> <li>DeepSeek-R1-FW by @fireworksai</li> <li>DeepSeek-R1-Turbo-DI by @deepinfra</li> <li>DeepSeek-V3 by @togetherai</li> <li>DeepSeek-V3-DI by @deepinfra</li> <li>DeepSeek-V3-Turbo-DI by @deepinfra</li> <li>Deepseek-V3-FW by @fireworksai</li> <li>Dream-Machine by @lumalabs</li> <li>ElevenLabs by @elevenlabsco</li> <li>FLUX-Fill by @fal</li> <li>FLUX-Inpaint by @fal</li> <li>FLUX-dev by @fal</li> <li>FLUX-dev-DI by @deepinfra</li> <li>FLUX-dev-finetuner by @fal</li> <li>FLUX-pro by @fal</li> <li>FLUX-pro-1-T by @togetherai</li> <li>FLUX-pro-1.1 by @fal</li> <li>FLUX-pro-1.1-T by @togetherai</li> <li>FLUX-pro-1.1-ultra by @fal</li> <li>FLUX-schnell by @fal</li> <li>FLUX-schnell-DI by @deepinfra</li> <li>Flux-1-Dev-FW by @fireworksai</li> <li>Flux-1-Schnell-FW by @fireworksai</li> <li>Flux-Kontext-Max by @fal</li> <li>Flux-Kontext-Pro by @fal</li> <li>Flux-Schnell-T by @togetherai</li> <li>GLM-4.5 by @fireworksai</li> <li>GPT-3.5-Turbo by @openai</li> <li>GPT-3.5-Turbo-Instruct by @openai</li> <li>GPT-3.5-Turbo-Raw by @openai</li> <li>GPT-4-Classic by @openai</li> <li>GPT-4-Classic-0314 by @openai</li> <li>GPT-4-Turbo by @openai</li> <li>GPT-4.1 by @openai</li> <li>GPT-4.1-mini by @openai</li> <li>GPT-4.1-nano by @openai</li> <li>GPT-4o by @openai</li> <li>GPT-4o-Aug by @openai</li> <li>GPT-4o-Search by @openai</li> <li>GPT-4o-mini by @openai</li> <li>GPT-4o-mini-Search by @openai</li> <li>GPT-Image-1 by @openai</li> <li>GPT-OSS-120B-T by @togetherai</li> <li>GPT-Researcher by @gptrdev</li> <li>Gemini-1.5-Flash by @google</li> <li>Gemini-1.5-Flash-Search by @google</li> <li>Gemini-1.5-Pro by @google</li> <li>Gemini-1.5-Pro-Search by @google</li> <li>Gemini-2.0-Flash by @google</li> <li>Gemini-2.0-Flash-Lite by @google</li> <li>Gemini-2.0-Flash-Preview by @google</li> <li>Gemini-2.5-Flash by @google</li> <li>Gemini-2.5-Flash-Lite-Preview by @google</li> <li>Gemini-2.5-Pro by @google</li> <li>Gemma-2-27b-T by @togetherai</li> <li>Gemma-3-27B by @empiriolabsai</li> <li>Grok-2 by @xai</li> <li>Grok-3 by @xai</li> <li>Grok-3-Mini by @xai</li> <li>Grok-4 by @xai</li> <li>Hailuo-02 by @MiniMax</li> <li>Hailuo-02-Standard by @fal</li> <li>Hailuo-AI by @fal</li> <li>Hailuo-Director-01 by @fal</li> <li>Hailuo-Live by @fal</li> <li>Hailuo-Speech-02 by @fal</li> <li>Hermes-3-70B by @hyperbolic</li> <li>Hidream-I1-full by @fal</li> <li>Ideogram by @ideogramai</li> <li>Ideogram-v2 by @ideogramai</li> <li>Ideogram-v2a by @ideogramai</li> <li>Ideogram-v2a-Turbo by @ideogramai</li> <li>Ideogram-v3 by @fal</li> <li>Imagen-3 by @google</li> <li>Imagen-3-Fast by @google</li> <li>Imagen-4 by @google</li> <li>Imagen-4-Fast by @google</li> <li>Imagen-4-Ultra-Exp by @google</li> <li>Inception-Mercury by @inceptionlabsai</li> <li>Inception-Mercury-Coder by @inceptionlabsai</li> <li>Kimi-K2 by @fireworksai</li> <li>Kimi-K2-T by @togetherai</li> <li>Kling-1.5-Pro by @fal</li> <li>Kling-1.6-Pro by @fal</li> <li>Kling-2.0-Master by @fal</li> <li>Kling-2.1-Master by @fal</li> <li>Kling-2.1-Pro by @fal</li> <li>Kling-2.1-Std by @fal</li> <li>Kling-Pro-Effects by @fal</li> <li>LivePortrait by @fal</li> <li>Llama-3-70B-FP16 by @hyperbolic</li> <li>Llama-3-70B-T by @togetherai</li> <li>Llama-3-70b-Groq by @groq</li> <li>Llama-3-70b-Inst-FW by @fireworksai</li> <li>Llama-3-8B-T by @togetherai</li> <li>Llama-3-8b-Groq by @groq</li> <li>Llama-3.1-405B by @meta</li> <li>Llama-3.1-405B-FP16 by @hyperbolic</li> <li>Llama-3.1-405B-FW by @fireworksai</li> <li>Llama-3.1-405B-T by @togetherai</li> <li>Llama-3.1-70B by @meta</li> <li>Llama-3.1-70B-FP16 by @hyperbolic</li> <li>Llama-3.1-70B-FW by @fireworksai</li> <li>Llama-3.1-70B-T by @togetherai</li> <li>Llama-3.1-8B by @meta</li> <li>Llama-3.1-8B-DI by @deepinfra</li> <li>Llama-3.1-8B-FP16 by @hyperbolic</li> <li>Llama-3.1-8B-FW by @fireworksai</li> <li>Llama-3.1-8B-T-128k by @togetherai</li> <li>Llama-3.1-Nemotron by @togetherai</li> <li>Llama-3.3-70B by @togetherai</li> <li>Llama-3.3-70B-DI by @deepinfra</li> <li>Llama-3.3-70B-FW by @fireworksai</li> <li>Llama-3.3-70B-Vers by @OpenSourceLab</li> <li>Llama-4-Maverick by @fireworksai</li> <li>Llama-4-Maverick-B10 by @baseten</li> <li>Llama-4-Maverick-T by @togetherai</li> <li>Llama-4-Scout by @fireworksai</li> <li>Llama-4-Scout-B10 by @baseten</li> <li>Llama-4-Scout-T by @togetherai</li> <li>Llama-4-Scout-nitro by @cerebrasai</li> <li>Luma-Photon by @fal</li> <li>Luma-Photon-Flash by @fal</li> <li>Lyria by @google</li> <li>MarkItDown by @opentools</li> <li>MiniMax-M1 by @MiniMax</li> <li>Mistral-7B-v0.3-DI by @deepinfra</li> <li>Mistral-7B-v0.3-T by @togetherai</li> <li>Mistral-Large-2 by @mistral</li> <li>Mistral-Medium by @mistral</li> <li>Mistral-NeMo by @OpenSourceLab</li> <li>Mistral-Small-3 by @mistral</li> <li>Mistral-Small-3.1 by @empiriolabsai</li> <li>Mistral-Small-3.2 by @OpenSourceLab</li> <li>Mixtral8x22b-Inst-FW by @fireworksai</li> <li>Mochi-preview by @fal</li> <li>OpenAI-GPT-OSS-120B by @fireworksai</li> <li>OpenAI-GPT-OSS-20B by @fireworksai</li> <li>Orpheus-TTS by @fal</li> <li>Perplexity-Deep-Research by @empiriolabsai</li> <li>Perplexity-R1-1776 by @empiriolabsai</li> <li>Perplexity-Sonar by @empiriolabsai</li> <li>Perplexity-Sonar-Pro by @empiriolabsai</li> <li>Perplexity-Sonar-Rsn by @empiriolabsai</li> <li>Perplexity-Sonar-Rsn-Pro by @empiriolabsai</li> <li>Phi-4-DI by @deepinfra</li> <li>Phoenix-1.0 by @leonardoai</li> <li>Pika by @pikalabs</li> <li>Pixverse-v4.5 by @fal</li> <li>PlayAI-Dialog by @fal</li> <li>PlayAI-TTS by @fal</li> <li>Poe-System-Bot by @poe</li> <li>Python by @poe</li> <li>QwQ-32B-B10 by @baseten</li> <li>QwQ-32B-Preview-T by @togetherai</li> <li>QwQ-32B-T by @togetherai</li> <li>Qwen-2.5-72B-T by @togetherai</li> <li>Qwen-2.5-7B-T by @togetherai</li> <li>Qwen-2.5-Coder-32B-T by @togetherai</li> <li>Qwen-2.5-VL-32b by @fireworksai</li> <li>Qwen-3-235B-0527-T by @togetherai</li> <li>Qwen-72B-T by @togetherai</li> <li>Qwen-QwQ-32b-preview by @fireworksai</li> <li>Qwen2-72B-Instruct-T by @togetherai</li> <li>Qwen2.5-Coder-32B by @hyperbolic</li> <li>Qwen2.5-VL-72B-T by @togetherai</li> <li>Qwen3-235B-2507-FW by @fireworksai</li> <li>Qwen3-235B-A22B by @baseten</li> <li>Qwen3-235B-A22B-DI by @deepinfra</li> <li>Qwen3-32B-nitro by @cerebrasai</li> <li>Qwen3-Coder-480B-FW by @fireworksai</li> <li>Ray2 by @lumalabs</li> <li>Recraft-V3 by @fal</li> <li>Reka-Core by @reka</li> <li>Reka-Flash by @reka</li> <li>Reka-Research by @reka</li> <li>Restyler by @fal</li> <li>Retro-Diffusion-Core by @retrodiffusion</li> <li>Runway by @runwayml</li> <li>Runway-Gen-4-Turbo by @runwayml</li> <li>Sana-T2I by @fal</li> <li>Seedance-1.0-Lite by @fal</li> <li>Seedance-1.0-Pro by @fal</li> <li>Seedream-3.0 by @fal</li> <li>Sketch-to-Image by @fal</li> <li>Solar-Pro-2 by @upstage</li> <li>Sora by @fal</li> <li>StableDiffusion3-2B by @fal</li> <li>StableDiffusion3.5-L by @fal</li> <li>StableDiffusion3.5-T by @fal</li> <li>StableDiffusionXL by @stabilityai</li> <li>Tako by @trytako</li> <li>TopazLabs by @topazlabsco</li> <li>Trellis-3D by @fal</li> <li>TwelveLabs by @twelvelabsai</li> <li>Unreal-Speech-TTS by @UnrealSpeech</li> <li>Veo-2 by @google</li> <li>Veo-2-Video by @fal</li> <li>Veo-3 by @google</li> <li>Veo-3-Fast by @fal</li> <li>Wan-2.1 by @fal</li> <li>Wan-2.2 by @fal</li> <li>Web-Search by @poe</li> <li>o1 by @openai</li> <li>o1-mini by @openai</li> <li>o1-pro by @openai</li> <li>o3 by @openai</li> <li>o3-deep-research by @openai</li> <li>o3-mini by @openai</li> <li>o3-mini-high by @openai</li> <li>o3-pro by @openai</li> <li>o4-mini by @openai</li> <li>o4-mini-deep-research by @openai</li> <li>remove-background by @fal</li> </ul>"},{"location":"models/App-Creator.html","title":"App-Creator","text":""},{"location":"models/App-Creator.html#bot-information","title":"Bot Information","text":"<p>Creator: @poe_tools</p> <p>Description: Specializes in building interactive web applications designed for publishing as apps on Poe. Available at a reduced early-access price for a limited time. Powered by Claude Sonnet 4.</p> <p>See what's new: https://creator.poe.com/changelog?tag=canvas-apps</p> <p>Extra: Powered by Anthropic: claude-sonnet-4-20250514. Learn more</p>"},{"location":"models/App-Creator.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/App-Creator.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 12 points/1k tokens |</p> <p>| Input Image | 12 points/1k tokens |</p> <p>| Bot Message | 21 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 24+ points |</p> <p>Last Checked: 2025-08-05 23:15:13.821272</p>"},{"location":"models/App-Creator.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>App-Creator</code></p> <p>Object Type: model</p> <p>Created: 1737569087127</p> <p>Owned By: poe</p> <p>Root: App-Creator</p>"},{"location":"models/Aya-Expanse-32B.html","title":"Aya-Expanse-32B","text":""},{"location":"models/Aya-Expanse-32B.html#bot-information","title":"Bot Information","text":"<p>Creator: @cohere</p> <p>Description: Aya Expanse is a 32B open-weight research release of a model with highly advanced multilingual capabilities. Aya supports state-of-art generative capabilities in 23 languages: Arabic, Chinese (simplified &amp; traditional), Czech, Dutch, English, French, German, Greek, Hebrew, Hindi, Indonesian, Italian, Japanese, Korean, Persian, Polish, Portuguese, Romanian, Russian, Spanish, Turkish, Ukrainian, and Vietnamese.</p> <p>Extra: Powered by a server managed by @cohere. Learn more</p>"},{"location":"models/Aya-Expanse-32B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Aya-Expanse-32B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 170 points/message |</p> <p>| Initial Points Cost | 170 points |</p> <p>Last Checked: 2025-08-05 23:15:20.551128</p>"},{"location":"models/Aya-Expanse-32B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Aya-Expanse-32B</code></p> <p>Object Type: model</p> <p>Created: 1739905182986</p> <p>Owned By: poe</p> <p>Root: Aya-Expanse-32B</p>"},{"location":"models/Aya-Vision.html","title":"Aya-Vision","text":""},{"location":"models/Aya-Vision.html#bot-information","title":"Bot Information","text":"<p>Creator: @cohere</p> <p>Description: Aya Vision is a 32B open-weights multimodal model with advanced capabilities optimized for a variety of vision-language use cases. It is model trained to excel in 23 languages in both vision and text: Arabic, Chinese (simplified &amp; traditional), Czech, Dutch, English, French, German, Greek, Hebrew, Hindi, Indonesian, Italian, Japanese, Korean, Persian, Polish, Portuguese, Romanian, Russian, Spanish, Turkish, Ukrainian, and Vietnamese.</p> <p>Extra: Powered by a server managed by @cohere. Learn more</p>"},{"location":"models/Aya-Vision.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Aya-Vision.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 0 points/message |</p> <p>| Initial Points Cost | 0 points |</p> <p>Last Checked: 2025-08-05 23:15:27.275730</p>"},{"location":"models/Aya-Vision.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Aya-Vision</code></p> <p>Object Type: model</p> <p>Created: 1741042614242</p> <p>Owned By: poe</p> <p>Root: Aya-Vision</p>"},{"location":"models/Bria-Eraser.html","title":"Bria-Eraser","text":""},{"location":"models/Bria-Eraser.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Bria Eraser enables precise removal of unwanted objects from images while maintaining high-quality outputs. Trained exclusively on licensed data for safe and risk-free commercial use. Send an image and a black-and-white mask image denoting the objects to be cleared out from the image. The input prompt is only used to create the filename of the output image.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Bria-Eraser.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Bria-Eraser.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 1334 points / message |</p> <p>| Initial Points Cost | 1334 points |</p> <p>Last Checked: 2025-08-05 23:15:34.046916</p>"},{"location":"models/Bria-Eraser.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Bria-Eraser</code></p> <p>Object Type: model</p> <p>Created: 1739957916196</p> <p>Owned By: poe</p> <p>Root: Bria-Eraser</p>"},{"location":"models/Cartesia.html","title":"Cartesia","text":""},{"location":"models/Cartesia.html#bot-information","title":"Bot Information","text":"<p>Creator: @cartesiateam</p> <p>Description: Generates audio based on your prompt using the latest Cartesia's Sonic 2.0 text-to-speech model in your voice of choice (see below)</p> <p>Add --voice [Voice Name] to the end of a message to customize the voice used or to handle different language inputs (e.g. \u4f60\u597d --voice Chinese Commercial Woman). All of Cartesia's voices are supported on Poe. </p> <p>The following voices are supported covering 14 languages (English, French, German, Spanish, Portuguese, Chinese, Japanese, Hindi, Italian, Korean, Dutch, Polish, Russian, Swedish, Turkish):</p> <p>Here's the alphabetical list of all the top voice names:</p> <p>\"1920's Radioman\" Aadhya Adele Alabama Man Alina American Voiceover Man Ananya Anna Announcer Man Apoorva ASMR Lady Australian Customer Support Man Australian Man Australian Narrator Lady Australian Salesman Australian Woman Barbershop Man Brenda British Customer Support Lady British Lady British Reading Lady Brooke California Girl Calm French Woman Calm Lady Camille Carson Casper Cathy Cathy Chongz Classy British Man Commercial Lady Commercial Man Confident British Man Connie Corinne Customer Support Lady Customer Support Man Dallas Dave David Devansh Elena Ellen Ethan Female Nurse Florence Francesca French Conversational Lady French Narrator Lady French Narrator Man Friendly Australian Man Friendly French Man Friendly Reading Man Friendly Sidekick German Conversational Woman German Conversation Man German Reporter Man German Woman Grace Griffin Happy Carson Helpful French Lady Helpful Woman Hindi Calm Man Hinglish Speaking Woman Indian Lady Indian Man Isabel Ishan Jacqueline Janvi Japanese Male Conversational Joan of Ark John Jordan Katie Keith Kenneth Kentucky Man Korean Support Woman Laidback Woman Lena Lily Whisper Little Gaming Girl Little Narrator Girl Liv Lukas Luke Madame Mischief Madison Maria Mateo Mexican Man Mexican Woman Mia Middle Eastern Woman Midwestern Man Midwestern Woman Movieman Nathan Newslady Newsman New York Man Nico Nonfiction Man Olivia Orion Peninsular Spanish Narrator Lady Pleasant Brazilian Lady Pleasant Man Polite Man Princess Professional Woman Rebecca Reflective Woman Ronald Russian Storyteller Man Salesman Samantha Angry Samantha Happy Sarah Sarah Curious Savannah Silas Sophie Southern Man Southern Woman Spanish Narrator Woman Spanish Reporter Woman Spanish-speaking Reporter Man Sportsman Stacy Stern French Man Steve Storyteller Lady Sweet Lady Tatiana Taylor Teacher Lady The Merchant Tutorial Man Wise Guide Man Wise Lady Wise Man Wizardman Yogaman Young Shy Japanese Woman Zia</p> <p>Extra: Powered by a server managed by @cartesiateam. Learn more</p>"},{"location":"models/Cartesia.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: audio</p> <p>Modality: text-&gt;audio</p>"},{"location":"models/Cartesia.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Text Input | 934 points / 1k characters |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:15:40.728102</p>"},{"location":"models/Cartesia.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Cartesia</code></p> <p>Object Type: model</p> <p>Created: 1731968187492</p> <p>Owned By: poe</p> <p>Root: Cartesia</p>"},{"location":"models/ChatGPT-4o-Latest.html","title":"ChatGPT-4o-Latest","text":""},{"location":"models/ChatGPT-4o-Latest.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: Dynamic model continuously updated to the current version of GPT-4o in ChatGPT. Stronger than GPT-3.5 in quantitative questions (math and physics), creative writing, and many other challenging tasks. Supports context window of 128k tokens, cannot generate images.</p> <p>Extra: Powered by OpenAI: chatgpt-4o-latest. Learn more</p>"},{"location":"models/ChatGPT-4o-Latest.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/ChatGPT-4o-Latest.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 150 points/1k tokens |</p> <p>| Input Image | 150 points/1k tokens |</p> <p>| Bot Message | 302 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 335+ points |</p> <p>Last Checked: 2025-08-05 23:15:47.594449</p>"},{"location":"models/ChatGPT-4o-Latest.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>ChatGPT-4o-Latest</code></p> <p>Object Type: model</p> <p>Created: 1723609331341</p> <p>Owned By: poe</p> <p>Root: ChatGPT-4o-Latest</p>"},{"location":"models/Clarity-Upscaler.html","title":"Clarity-Upscaler","text":""},{"location":"models/Clarity-Upscaler.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Upscales images with high fidelity to the original image. Use \"--upscale_factor\" (value is a number between 1 and 4) to set the upscaled images' size (2 means the output image is 2x in size, etc.).  \"--creativity\" and \"--clarity\" can be set between 0 and 1 to alter the faithfulness to the original image and the sharpness, respectively. This bot supports .jpg and .png images.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Clarity-Upscaler.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Clarity-Upscaler.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 850 points / megapixel |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:15:54.768248</p>"},{"location":"models/Clarity-Upscaler.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Clarity-Upscaler</code></p> <p>Object Type: model</p> <p>Created: 1736160594594</p> <p>Owned By: poe</p> <p>Root: Clarity-Upscaler</p>"},{"location":"models/Claude-Haiku-3.5-Search.html","title":"Claude-Haiku-3.5-Search","text":""},{"location":"models/Claude-Haiku-3.5-Search.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Haiku 3.5 with access to real-time information from the web.</p> <p>Extra: Powered by Anthropic: claude-3-5-haiku-20241022. Learn more</p>"},{"location":"models/Claude-Haiku-3.5-Search.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Haiku-3.5-Search.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 30 points/1k tokens |</p> <p>| Input Image | 30 points/1k tokens |</p> <p>| Bot Message | 92 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 99+ points |</p> <p>Last Checked: 2025-08-05 23:16:15.185407</p>"},{"location":"models/Claude-Haiku-3.5-Search.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Haiku-3.5-Search</code></p> <p>Object Type: model</p> <p>Created: 1747285932473</p> <p>Owned By: poe</p> <p>Root: Claude-Haiku-3.5-Search</p>"},{"location":"models/Claude-Haiku-3.5.html","title":"Claude-Haiku-3.5","text":""},{"location":"models/Claude-Haiku-3.5.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: The latest generation of Anthropic's fastest model. Claude Haiku 3.5 has fast speeds and improved instruction following.</p> <p>Extra: Powered by Anthropic: claude-3-5-haiku-20241022. Learn more</p>"},{"location":"models/Claude-Haiku-3.5.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Haiku-3.5.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 30 points/1k tokens |</p> <p>| Input Image | 30 points/1k tokens |</p> <p>| Bot Message | 42 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 49+ points |</p> <p>Last Checked: 2025-08-05 23:16:08.345743</p>"},{"location":"models/Claude-Haiku-3.5.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Haiku-3.5</code></p> <p>Object Type: model</p> <p>Created: 1727818578813</p> <p>Owned By: poe</p> <p>Root: Claude-Haiku-3.5</p>"},{"location":"models/Claude-Haiku-3.html","title":"Claude-Haiku-3","text":""},{"location":"models/Claude-Haiku-3.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Anthropic's Claude Haiku 3 outperforms models in its intelligence category on performance, speed and cost without the need for specialized fine-tuning. The compute points value is subject to change. For most use cases, https://poe.com/Claude-Haiku-3.5 will be better.</p> <p>Extra: Powered by Anthropic: claude-3-haiku-20240307. Learn more</p>"},{"location":"models/Claude-Haiku-3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Haiku-3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 10 points/1k tokens |</p> <p>| Input Image | 10 points/1k tokens |</p> <p>| Bot Message | 19 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 22+ points |</p> <p>Last Checked: 2025-08-05 23:16:01.532861</p>"},{"location":"models/Claude-Haiku-3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Haiku-3</code></p> <p>Object Type: model</p> <p>Created: 1709942726436</p> <p>Owned By: poe</p> <p>Root: Claude-Haiku-3</p>"},{"location":"models/Claude-Opus-3.html","title":"Claude-Opus-3","text":""},{"location":"models/Claude-Opus-3.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Anthropic's Claude Opus 3 can handle complex analysis, longer tasks with multiple steps, and higher-order math and coding tasks. Supports 200k tokens of context (approximately 150k English words).</p> <p>Extra: Powered by Anthropic: claude-3-opus-20240229. Learn more</p>"},{"location":"models/Claude-Opus-3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Opus-3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 585 points/1k tokens |</p> <p>| Input Image | 585 points/1k tokens |</p> <p>| Bot Message | 1918 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 2052+ points |</p> <p>Last Checked: 2025-08-05 23:16:22.197900</p>"},{"location":"models/Claude-Opus-3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Opus-3</code></p> <p>Object Type: model</p> <p>Created: 1709574492024</p> <p>Owned By: poe</p> <p>Root: Claude-Opus-3</p>"},{"location":"models/Claude-Opus-4-1.html","title":"Claude-Opus-4-1","text":""},{"location":"models/Claude-Opus-4-1.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Opus 4.1 from Anthropic, supports customizable thinking budget (up to 32k tokens) and 200k context window. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 31999 to the end of your message.</p> <p>Extra: Powered by Anthropic: claude-opus-4-1-20250805. Learn more</p>"},{"location":"models/Claude-Opus-4-1.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Opus-4-1.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 585 points/1k tokens |</p> <p>| Input Image | 585 points/1k tokens |</p> <p>| Bot Message | 1000 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 1134+ points |</p> <p>Last Checked: 2025-08-05 23:16:36.364727</p>"},{"location":"models/Claude-Opus-4-1.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Opus-4-1</code></p> <p>Object Type: model</p> <p>Created: 1754419185968</p> <p>Owned By: poe</p> <p>Root: Claude-Opus-4-1</p>"},{"location":"models/Claude-Opus-4-Reasoning.html","title":"Claude-Opus-4-Reasoning","text":""},{"location":"models/Claude-Opus-4-Reasoning.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Opus 4 from Anthropic, supports customizable thinking budget (up to 30k tokens) and 200k context window. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 30,768 to the end of your message.</p> <p>Extra: Powered by Anthropic: claude-opus-4-20250514. Learn more</p>"},{"location":"models/Claude-Opus-4-Reasoning.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Opus-4-Reasoning.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 585 points/1k tokens |</p> <p>| Input Image | 585 points/1k tokens |</p> <p>| Bot Message | 5782 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 5916+ points |</p> <p>Last Checked: 2025-08-05 23:16:43.181755</p>"},{"location":"models/Claude-Opus-4-Reasoning.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Opus-4-Reasoning</code></p> <p>Object Type: model</p> <p>Created: 1747865908863</p> <p>Owned By: poe</p> <p>Root: Claude-Opus-4-Reasoning</p>"},{"location":"models/Claude-Opus-4-Search.html","title":"Claude-Opus-4-Search","text":""},{"location":"models/Claude-Opus-4-Search.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Opus 4 with access to real-time information from the web. Supports customizable thinking budget of up to 126k tokens. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 126,000 to the end of your message.</p> <p>Extra: Powered by Anthropic: claude-opus-4-20250514. Learn more</p>"},{"location":"models/Claude-Opus-4-Search.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Opus-4-Search.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 585 points/1k tokens |</p> <p>| Input Image | 585 points/1k tokens |</p> <p>| Bot Message | 4222 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 4356+ points |</p> <p>Last Checked: 2025-08-05 23:16:50.012200</p>"},{"location":"models/Claude-Opus-4-Search.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Opus-4-Search</code></p> <p>Object Type: model</p> <p>Created: 1750451340055</p> <p>Owned By: poe</p> <p>Root: Claude-Opus-4-Search</p>"},{"location":"models/Claude-Opus-4.html","title":"Claude-Opus-4","text":""},{"location":"models/Claude-Opus-4.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Opus 4 from Anthropic, supports customizable thinking budget (up to 30k tokens) and 200k context window. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 30,768 to the end of your message.</p> <p>Extra: Powered by Anthropic: claude-opus-4-20250514. Learn more</p>"},{"location":"models/Claude-Opus-4.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Opus-4.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 585 points/1k tokens |</p> <p>| Input Image | 585 points/1k tokens |</p> <p>| Bot Message | 4817 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 4951+ points |</p> <p>Last Checked: 2025-08-05 23:16:29.098274</p>"},{"location":"models/Claude-Opus-4.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Opus-4</code></p> <p>Object Type: model</p> <p>Created: 1747863925397</p> <p>Owned By: poe</p> <p>Root: Claude-Opus-4</p>"},{"location":"models/Claude-Sonnet-3.5-June.html","title":"Claude-Sonnet-3.5-June","text":""},{"location":"models/Claude-Sonnet-3.5-June.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Anthropic's legacy Sonnet 3.5 model, specifically the June 2024 snapshot (for the latest, please use https://poe.com/Claude-Sonnet-3.5). Excels in complex tasks like coding, writing, analysis and visual processing; generally, more verbose than the more concise October 2024 snapshot.</p> <p>Extra: Powered by Anthropic: claude-3-5-sonnet-20240620. Learn more</p>"},{"location":"models/Claude-Sonnet-3.5-June.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Sonnet-3.5-June.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 115 points/1k tokens |</p> <p>| Input Image | 115 points/1k tokens |</p> <p>| Bot Message | 363 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 390+ points |</p> <p>Last Checked: 2025-08-05 23:17:03.682147</p>"},{"location":"models/Claude-Sonnet-3.5-June.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Sonnet-3.5-June</code></p> <p>Object Type: model</p> <p>Created: 1731966954824</p> <p>Owned By: poe</p> <p>Root: Claude-Sonnet-3.5-June</p>"},{"location":"models/Claude-Sonnet-3.5-Search.html","title":"Claude-Sonnet-3.5-Search","text":""},{"location":"models/Claude-Sonnet-3.5-Search.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Sonnet 3.5 with access to real-time information from the web.</p> <p>Extra: Powered by Anthropic: claude-3-5-sonnet-20241022. Learn more</p>"},{"location":"models/Claude-Sonnet-3.5-Search.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Sonnet-3.5-Search.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 115 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 438 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 465+ points |</p> <p>Last Checked: 2025-08-05 23:17:10.530327</p>"},{"location":"models/Claude-Sonnet-3.5-Search.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Sonnet-3.5-Search</code></p> <p>Object Type: model</p> <p>Created: 1747285956234</p> <p>Owned By: poe</p> <p>Root: Claude-Sonnet-3.5-Search</p>"},{"location":"models/Claude-Sonnet-3.5.html","title":"Claude-Sonnet-3.5","text":""},{"location":"models/Claude-Sonnet-3.5.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Anthropic's Claude Sonnet 3.5 using the October 22, 2024 model snapshot. Excels in complex tasks like coding, writing, analysis and visual processing. Has a context window of 200k of tokens (approximately 150k English words).</p> <p>Extra: Powered by Anthropic: claude-3-5-sonnet-v2-20241022. Learn more</p>"},{"location":"models/Claude-Sonnet-3.5.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Sonnet-3.5.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 115 points/1k tokens |</p> <p>| Input Image | 115 points/1k tokens |</p> <p>| Bot Message | 243 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 270+ points |</p> <p>Last Checked: 2025-08-05 23:16:56.792948</p>"},{"location":"models/Claude-Sonnet-3.5.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Sonnet-3.5</code></p> <p>Object Type: model</p> <p>Created: 1717554300318</p> <p>Owned By: poe</p> <p>Root: Claude-Sonnet-3.5</p>"},{"location":"models/Claude-Sonnet-3.7-Reasoning.html","title":"Claude-Sonnet-3.7-Reasoning","text":""},{"location":"models/Claude-Sonnet-3.7-Reasoning.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Reasoning capabilities on by default. Claude Sonnet 3.7 is a hybrid reasoning model, producing near-instant responses or extended, step-by-step thinking. Recommended for complex math or coding problems. Supports a 200k token context window. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 126,000 to the end of your message.</p> <p>Extra: Powered by Anthropic: claude-3-7-sonnet-20250219. Learn more</p>"},{"location":"models/Claude-Sonnet-3.7-Reasoning.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Sonnet-3.7-Reasoning.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 115 points/1k tokens |</p> <p>| Input Image | 115 points/1k tokens |</p> <p>| Bot Message | 1695 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 1722+ points |</p> <p>Last Checked: 2025-08-05 23:17:25.144538</p>"},{"location":"models/Claude-Sonnet-3.7-Reasoning.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Sonnet-3.7-Reasoning</code></p> <p>Object Type: model</p> <p>Created: 1739926096905</p> <p>Owned By: poe</p> <p>Root: Claude-Sonnet-3.7-Reasoning</p>"},{"location":"models/Claude-Sonnet-3.7-Search.html","title":"Claude-Sonnet-3.7-Search","text":""},{"location":"models/Claude-Sonnet-3.7-Search.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Sonnet 3.7 with access to real-time information from the web. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 126,000 to the end of your message.</p> <p>Extra: Powered by Anthropic: claude-3-7-sonnet-20250219. Learn more</p>"},{"location":"models/Claude-Sonnet-3.7-Search.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Sonnet-3.7-Search.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 115 points/1k tokens |</p> <p>| Input Image | 115 points/1k tokens |</p> <p>| Bot Message | 1491 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 1518+ points |</p> <p>Last Checked: 2025-08-05 23:17:31.960532</p>"},{"location":"models/Claude-Sonnet-3.7-Search.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Sonnet-3.7-Search</code></p> <p>Object Type: model</p> <p>Created: 1747285973996</p> <p>Owned By: poe</p> <p>Root: Claude-Sonnet-3.7-Search</p>"},{"location":"models/Claude-Sonnet-3.7.html","title":"Claude-Sonnet-3.7","text":""},{"location":"models/Claude-Sonnet-3.7.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Sonnet 3.7 is a hybrid reasoning model, producing near-instant responses or extended, step-by-step thinking. For the maximum extending thinking, please use https://poe.com/Claude-Sonnet-Reasoning-3.7. Supports a 200k token context window. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 16,384 to the end of your message.</p> <p>Extra: Powered by Anthropic: claude-3-7-sonnet-20250219. Learn more</p>"},{"location":"models/Claude-Sonnet-3.7.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Sonnet-3.7.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 115 points/1k tokens |</p> <p>| Input Image | 115 points/1k tokens |</p> <p>| Bot Message | 1017 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 1044+ points |</p> <p>Last Checked: 2025-08-05 23:17:17.451270</p>"},{"location":"models/Claude-Sonnet-3.7.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Sonnet-3.7</code></p> <p>Object Type: model</p> <p>Created: 1739926818142</p> <p>Owned By: poe</p> <p>Root: Claude-Sonnet-3.7</p>"},{"location":"models/Claude-Sonnet-4-Reasoning.html","title":"Claude-Sonnet-4-Reasoning","text":""},{"location":"models/Claude-Sonnet-4-Reasoning.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Sonnet 4 from Anthropic, supports customizable thinking budget (up to 60k tokens) and 200k context window. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 61,440 to the end of your message.</p> <p>Extra: Powered by Anthropic: claude-sonnet-4-20250514. Learn more</p>"},{"location":"models/Claude-Sonnet-4-Reasoning.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Sonnet-4-Reasoning.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 115 points/1k tokens |</p> <p>| Input Image | 115 points/1k tokens |</p> <p>| Bot Message | 1601 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 1628+ points |</p> <p>Last Checked: 2025-08-05 23:17:45.523552</p>"},{"location":"models/Claude-Sonnet-4-Reasoning.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Sonnet-4-Reasoning</code></p> <p>Object Type: model</p> <p>Created: 1747865657124</p> <p>Owned By: poe</p> <p>Root: Claude-Sonnet-4-Reasoning</p>"},{"location":"models/Claude-Sonnet-4-Search.html","title":"Claude-Sonnet-4-Search","text":""},{"location":"models/Claude-Sonnet-4-Search.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Sonnet 4 with access to real-time information from the web. Supports customizable thinking budget of up to 126k tokens. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 126,000 to the end of your message.</p> <p>Extra: Powered by Anthropic: claude-sonnet-4-20250514. Learn more</p>"},{"location":"models/Claude-Sonnet-4-Search.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Sonnet-4-Search.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 115 points/1k tokens |</p> <p>| Input Image | 115 points/1k tokens |</p> <p>| Bot Message | 843 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 870+ points |</p> <p>Last Checked: 2025-08-05 23:17:52.359681</p>"},{"location":"models/Claude-Sonnet-4-Search.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Sonnet-4-Search</code></p> <p>Object Type: model</p> <p>Created: 1750451236340</p> <p>Owned By: poe</p> <p>Root: Claude-Sonnet-4-Search</p>"},{"location":"models/Claude-Sonnet-4.html","title":"Claude-Sonnet-4","text":""},{"location":"models/Claude-Sonnet-4.html#bot-information","title":"Bot Information","text":"<p>Creator: @anthropic</p> <p>Description: Claude Sonnet 4 from Anthropic, supports customizable thinking budget (up to 30k tokens) and 200k context window. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 30,768 to the end of your message.</p> <p>Extra: Powered by Anthropic: claude-sonnet-4-20250514. Learn more</p>"},{"location":"models/Claude-Sonnet-4.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Claude-Sonnet-4.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 115 points/1k tokens |</p> <p>| Input Image | 115 points/1k tokens |</p> <p>| Bot Message | 911 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 90% discount oncached chat history |</p> <p>| Initial Points Cost | 938+ points |</p> <p>Last Checked: 2025-08-05 23:17:38.693428</p>"},{"location":"models/Claude-Sonnet-4.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Claude-Sonnet-4</code></p> <p>Object Type: model</p> <p>Created: 1747860708348</p> <p>Owned By: poe</p> <p>Root: Claude-Sonnet-4</p>"},{"location":"models/Command-R-Plus.html","title":"Command-R-Plus","text":""},{"location":"models/Command-R-Plus.html#bot-information","title":"Bot Information","text":"<p>Creator: @cohere</p> <p>Description: A supercharged version of Command R. I can search the web for up to date information and respond in over 10 languages!</p> <p>Extra: Powered by a server managed by @cohere. Learn more</p>"},{"location":"models/Command-R-Plus.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Command-R-Plus.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1130 points/message |</p> <p>| Initial Points Cost | 1130 points |</p> <p>Last Checked: 2025-08-05 23:18:08.873554</p>"},{"location":"models/Command-R-Plus.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Command-R-Plus</code></p> <p>Object Type: model</p> <p>Created: 1712716481132</p> <p>Owned By: poe</p> <p>Root: Command-R-Plus</p>"},{"location":"models/Command-R.html","title":"Command-R","text":""},{"location":"models/Command-R.html#bot-information","title":"Bot Information","text":"<p>Creator: @cohere</p> <p>Description: I can search the web for up to date information and respond in over 10 languages!</p> <p>Extra: Powered by a server managed by @cohere. Learn more</p>"},{"location":"models/Command-R.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Command-R.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 170 points/message |</p> <p>| Initial Points Cost | 170 points |</p> <p>Last Checked: 2025-08-05 23:17:59.794855</p>"},{"location":"models/Command-R.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Command-R</code></p> <p>Object Type: model</p> <p>Created: 1711035788709</p> <p>Owned By: poe</p> <p>Root: Command-R</p>"},{"location":"models/DALL-E-3.html","title":"DALL-E-3","text":""},{"location":"models/DALL-E-3.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI's most powerful image generation model. Generates high quality images with intricate details based on the user's most recent prompt. For most prompts, https://poe.com/FLUX-pro-1.1-ultra or https://poe.com/FLUX-dev or https://poe.com/Imagen3 will produce better results. Use \"--aspect\" to select an aspect ratio (e.g --aspect 1:1). Valid aspect ratios are 1:1, 7:4, &amp; 4:7.</p> <p>Extra: Powered by a server managed by @openai. Learn more</p>"},{"location":"models/DALL-E-3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/DALL-E-3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1500 points/message |</p> <p>| Initial Points Cost | 1500 points |</p> <p>Last Checked: 2025-08-05 23:18:17.711665</p>"},{"location":"models/DALL-E-3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>DALL-E-3</code></p> <p>Object Type: model</p> <p>Created: 1699306131647</p> <p>Owned By: poe</p> <p>Root: DALL-E-3</p>"},{"location":"models/DeepClaude.html","title":"DeepClaude","text":""},{"location":"models/DeepClaude.html#bot-information","title":"Bot Information","text":"<p>Creator: @empiriolabsai</p> <p>Description: DeepClaude is a high-performance LLM inference that combines DeepSeek R1's Chain of Thought (CoT) reasoning capabilities with Anthropic Claude's creative and code generation prowess. It provides a unified interface for leveraging the strengths of both models while maintaining complete control over your data. Learn more: https://deepclaude.com/</p> <p>Extra: Powered by a server managed by @empiriolabsai. Learn more</p>"},{"location":"models/DeepClaude.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/DeepClaude.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Per Message | 5334 points |</p> <p>| Initial Points Cost | 5334 points |</p> <p>Last Checked: 2025-08-05 23:18:24.603323</p>"},{"location":"models/DeepClaude.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>DeepClaude</code></p> <p>Object Type: model</p> <p>Created: 1740454833334</p> <p>Owned By: poe</p> <p>Root: DeepClaude</p>"},{"location":"models/DeepSeek-R1-DI.html","title":"DeepSeek-R1-DI","text":""},{"location":"models/DeepSeek-R1-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: Top open-source reasoning LLM rivaling OpenAI's o1 model; delivers top-tier performance across math, code, and reasoning tasks at a fraction of the cost. All data you provide this bot will not be used in training, and is sent only to DeepInfra, a US-based company.</p> <p>Supports 64k tokens of input context and 8k tokens of output context. Quantization: FP8 (official).</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/DeepSeek-R1-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/DeepSeek-R1-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 200 points/message |</p> <p>| Initial Points Cost | 200 points |</p> <p>Last Checked: 2025-08-05 23:18:38.148028</p>"},{"location":"models/DeepSeek-R1-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>DeepSeek-R1-DI</code></p> <p>Object Type: model</p> <p>Created: 1740487208576</p> <p>Owned By: poe</p> <p>Root: DeepSeek-R1-DI</p>"},{"location":"models/DeepSeek-R1-Distill.html","title":"DeepSeek-R1-Distill","text":""},{"location":"models/DeepSeek-R1-Distill.html#bot-information","title":"Bot Information","text":"<p>Creator: @groq</p> <p>Description: DeepSeek-r1-distill-llama-70b is a fine-tuned version of Llama 3.3 70B using samples generated by DeepSeek-R1 being served from GroqCloud\u2122 for instant reasoning and with full 128k context window. Outputs creative &amp; human-like chains of thought at blazing speeds; for the original version with full-length responses use: https://poe.com/DeepSeek-R1-FW</p> <p>Extra: Powered by Groq. Learn more</p>"},{"location":"models/DeepSeek-R1-Distill.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/DeepSeek-R1-Distill.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 150 points/message |</p> <p>| Initial Points Cost | 150 points |</p> <p>Last Checked: 2025-08-05 23:18:45.122844</p>"},{"location":"models/DeepSeek-R1-Distill.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>DeepSeek-R1-Distill</code></p> <p>Object Type: model</p> <p>Created: 1738098004778</p> <p>Owned By: poe</p> <p>Root: DeepSeek-R1-Distill</p>"},{"location":"models/DeepSeek-R1-FW.html","title":"DeepSeek-R1-FW","text":""},{"location":"models/DeepSeek-R1-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: State-of-the-art large reasoning model problem solving, math, and coding performance at a fraction of the cost; explains its chain of thought. All data you provide this bot will not be used in training, and is sent only to Fireworks AI, a US-based company. Supports 164k tokens of input context and 164k tokens of output context. Uses the latest May 28th, 2025 snapshot.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/DeepSeek-R1-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/DeepSeek-R1-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 600 points/message |</p> <p>| Initial Points Cost | 600 points |</p> <p>Last Checked: 2025-08-05 23:18:51.993132</p>"},{"location":"models/DeepSeek-R1-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>DeepSeek-R1-FW</code></p> <p>Object Type: model</p> <p>Created: 1737499802568</p> <p>Owned By: poe</p> <p>Root: DeepSeek-R1-FW</p>"},{"location":"models/DeepSeek-R1-Turbo-DI.html","title":"DeepSeek-R1-Turbo-DI","text":""},{"location":"models/DeepSeek-R1-Turbo-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: Top open-source reasoning LLM rivaling OpenAI's o1 model; delivers top-tier performance across math, code, and reasoning tasks at a fraction of the cost. Turbo model is quantized to achieve higher speeds. All data you provide this bot will not be used in training, and is sent only to DeepInfra, a US-based company.</p> <p>Supports 32k tokens of input context and 8k tokens of output context. Quantization: FP4 (turbo).</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/DeepSeek-R1-Turbo-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/DeepSeek-R1-Turbo-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 500 points/message |</p> <p>| Initial Points Cost | 500 points |</p> <p>Last Checked: 2025-08-05 23:18:58.847977</p>"},{"location":"models/DeepSeek-R1-Turbo-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>DeepSeek-R1-Turbo-DI</code></p> <p>Object Type: model</p> <p>Created: 1741250889407</p> <p>Owned By: poe</p> <p>Root: DeepSeek-R1-Turbo-DI</p>"},{"location":"models/DeepSeek-R1.html","title":"DeepSeek-R1","text":""},{"location":"models/DeepSeek-R1.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Top open-source reasoning LLM rivaling OpenAI's o1 model; delivers top-tier performance across math, code, and reasoning tasks at a fraction of the cost. All data you provide this bot will not be used in training, and is sent only to Together AI, a US-based company. Supports 164k tokens of input context and 33k tokens of output context. Uses the latest May 28th snapshot (DeepSeek-R1-0528).</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/DeepSeek-R1.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/DeepSeek-R1.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 600 points/message |</p> <p>| Initial Points Cost | 600 points |</p> <p>Last Checked: 2025-08-05 23:18:31.361879</p>"},{"location":"models/DeepSeek-R1.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>DeepSeek-R1</code></p> <p>Object Type: model</p> <p>Created: 1737571591125</p> <p>Owned By: poe</p> <p>Root: DeepSeek-R1</p>"},{"location":"models/DeepSeek-V3-DI.html","title":"DeepSeek-V3-DI","text":""},{"location":"models/DeepSeek-V3-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: Deepseek-v3 \u2013 the new top open-source LLM. Achieves state-of-the-art performance in tasks such as coding, mathematics, and reasoning. All data you submit to this bot is governed by the Poe privacy policy and is only sent to DeepInfra, a US-based company.</p> <p>Supports 64k tokens of input context and 8k tokens of output context. Quantization: FP8 (official).</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/DeepSeek-V3-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/DeepSeek-V3-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 145 points/message |</p> <p>| Initial Points Cost | 145 points |</p> <p>Last Checked: 2025-08-05 23:19:12.696299</p>"},{"location":"models/DeepSeek-V3-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>DeepSeek-V3-DI</code></p> <p>Object Type: model</p> <p>Created: 1739797458982</p> <p>Owned By: poe</p> <p>Root: DeepSeek-V3-DI</p>"},{"location":"models/DeepSeek-V3-Turbo-DI.html","title":"DeepSeek-V3-Turbo-DI","text":""},{"location":"models/DeepSeek-V3-Turbo-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: Deepseek-v3 \u2013 the new top open-source LLM. Achieves state-of-the-art performance in tasks such as coding, mathematics, and reasoning. Turbo variant is quantized to achieve higher speeds. All data you submit to this bot is governed by the Poe privacy policy and is only sent to DeepInfra, a US-based company.</p> <p>Supports 32k tokens of input context and 8k tokens of output context. Quantization: FP4 (turbo).</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/DeepSeek-V3-Turbo-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/DeepSeek-V3-Turbo-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 195 points/message |</p> <p>| Initial Points Cost | 195 points |</p> <p>Last Checked: 2025-08-05 23:19:19.809551</p>"},{"location":"models/DeepSeek-V3-Turbo-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>DeepSeek-V3-Turbo-DI</code></p> <p>Object Type: model</p> <p>Created: 1741250579199</p> <p>Owned By: poe</p> <p>Root: DeepSeek-V3-Turbo-DI</p>"},{"location":"models/DeepSeek-V3.html","title":"DeepSeek-V3","text":""},{"location":"models/DeepSeek-V3.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: DeepSeek-V3 \u2013 the new top open-source LLM. Updated to the March 24, 2025 checkpoint. Achieves state-of-the-art performance in tasks such as coding, mathematics, and reasoning. All data you submit to this bot is governed by the Poe privacy policy and is only sent to Together, a US-based company. Supports 131k context window and max output of 12k tokens.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/DeepSeek-V3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/DeepSeek-V3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 415 points/message |</p> <p>| Initial Points Cost | 415 points |</p> <p>Last Checked: 2025-08-05 23:19:05.755817</p>"},{"location":"models/DeepSeek-V3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>DeepSeek-V3</code></p> <p>Object Type: model</p> <p>Created: 1735963694067</p> <p>Owned By: poe</p> <p>Root: DeepSeek-V3</p>"},{"location":"models/Deepseek-V3-FW.html","title":"Deepseek-V3-FW","text":""},{"location":"models/Deepseek-V3-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: DeepSeek-V3 is an open-source Mixture-of-Experts (MoE) language model; able to perform well on competitive benchmarks with cost-effective training &amp; inference. All data submitted to this bot is governed by the Poe privacy policy and is sent to Fireworks, a US-based company. Supports 131k context window and max output of 131k tokens. Updated to serve the latest March 24th, 2025 snapshot.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Deepseek-V3-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Deepseek-V3-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 300 points/message |</p> <p>| Initial Points Cost | 300 points |</p> <p>Last Checked: 2025-08-05 23:19:26.926273</p>"},{"location":"models/Deepseek-V3-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Deepseek-V3-FW</code></p> <p>Object Type: model</p> <p>Created: 1735687236887</p> <p>Owned By: poe</p> <p>Root: Deepseek-V3-FW</p>"},{"location":"models/Dream-Machine.html","title":"Dream-Machine","text":""},{"location":"models/Dream-Machine.html#bot-information","title":"Bot Information","text":"<p>Creator: @lumalabs</p> <p>Description: Luma AI's Dream Machine is an AI model that makes high-quality, realistic videos fast from text and images. Iterate at the speed of thought, create action-packed shots, and dream worlds with consistent characters on Poe today!</p> <p>To specify the aspect ratio of your video add --aspect_ratio (1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21). To loop your video add --loop True.</p> <p>Extra: Powered by a server managed by @lumalabs. Learn more</p>"},{"location":"models/Dream-Machine.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Dream-Machine.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 12000 points/message |</p> <p>| Initial Points Cost | 12000 points |</p> <p>Last Checked: 2025-08-05 23:19:34.534115</p>"},{"location":"models/Dream-Machine.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Dream-Machine</code></p> <p>Object Type: model</p> <p>Created: 1726690715197</p> <p>Owned By: poe</p> <p>Root: Dream-Machine</p>"},{"location":"models/ElevenLabs.html","title":"ElevenLabs","text":""},{"location":"models/ElevenLabs.html#bot-information","title":"Bot Information","text":"<p>Creator: @elevenlabsco</p> <p>Description: ElevenLabs' leading text-to-speech technology converts your text into natural-sounding speech, using the Turbo v2.5 model. Simply send a text prompt, and the bot will generate audio using your choice of available voices. If you link a URL or a PDF, it will do its best to read it aloud to you. The overall default voice is Jessica, an American-English female.</p> <p>Add --voice \"Voice Name\" to the end of a message (e.g. \"Hello world --voice Eric\") to customize the voice used. Add --language and the two-letter, Language ISO-639-1 code to your message if you notice pronunciation errors; table of ISO-639-1 codes here: https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes (e.g. zh for Chinese, es for Spanish, hi for Hindi)</p> <p>The following voices are supported and recommended for each language:</p> <p>English -- Sarah, George, River, Matilda, Will, Jessica, Brian, Lily, Monika Sogam Chinese -- James Gao, Martin Li, Will, River Spanish -- David Martin, Will, Efrayn, Alejandro, Sara Martin, Regina Martin Hindi -- Ranga, Niraj, Liam, Raju, Leo, Manu, Vihana Huja, Kanika, River, Monika Sogam, Muskaan, Saanu, Riya, Devi Arabic -- Bill, Mo Wiseman, Haytham, George, Mona, Sarah, Sana, Laura German -- Bill, Otto, Leon Stern, Mila, Emilia, Lea, Leonie Indonesian -- Jessica, Putra, Mahaputra Portuguese -- Will, Muhammad, Onildo, Lily, Jessica, Alice Vietnamese -- Bill, Liam, Trung Caha, Van Phuc, Ca Dao, Trang, Jessica, Alice, Matilda Filipino -- Roger, Brian, Alice, Matilda French -- Roger, Louis, Emilie Swedish -- Will, Chris, Jessica, Charlotte Turkish -- Cavit Pancar, Sohbet Adami, Belma, Sultan, Mahidevran Romanian -- Eric, Bill, Brian, Charlotte, Lily Italian -- Carmelo, Luca, Alice, Lily Polish -- Robert, Rob, Eric, Pawel, Lily, Alice Norwegian -- Chris, Charlotte Czech -- Pawel Finnish -- Callum, River Hungarian -- Brian, Sarah Japanese -- Alice</p> <p>Extra: Powered by a server managed by @elevenlabsco. Learn more</p>"},{"location":"models/ElevenLabs.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: audio</p> <p>Modality: text-&gt;audio</p>"},{"location":"models/ElevenLabs.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 1 point / character |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:19:42.115656</p>"},{"location":"models/ElevenLabs.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>ElevenLabs</code></p> <p>Object Type: model</p> <p>Created: 1730153913289</p> <p>Owned By: poe</p> <p>Root: ElevenLabs</p>"},{"location":"models/FLUX-Fill.html","title":"FLUX-Fill","text":""},{"location":"models/FLUX-Fill.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Given an image and a mask (separate images), fills in the region of the image given by the mask as per the prompt. The base image should be the first image attached and the black-and-white mask should be the second image; a text prompt is required and should specify what you want the model to inpaint in the white area of the mask.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/FLUX-Fill.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/FLUX-Fill.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 992 points / message |</p> <p>| Initial Points Cost | 992 points |</p> <p>Last Checked: 2025-08-05 23:19:49.031543</p>"},{"location":"models/FLUX-Fill.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-Fill</code></p> <p>Object Type: model</p> <p>Created: 1736787123399</p> <p>Owned By: poe</p> <p>Root: FLUX-Fill</p>"},{"location":"models/FLUX-Inpaint.html","title":"FLUX-Inpaint","text":""},{"location":"models/FLUX-Inpaint.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Given an image and a mask (separate images), fills in the region of the image given by the mask as per the prompt. The base image should be the first image attached and the black-and-white mask should be the second image; a text prompt is required and should specify what you want the model to inpaint in the white area of the mask.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/FLUX-Inpaint.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/FLUX-Inpaint.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 992 points / message |</p> <p>| Initial Points Cost | 992 points |</p> <p>Last Checked: 2025-08-05 23:19:56.486168</p>"},{"location":"models/FLUX-Inpaint.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-Inpaint</code></p> <p>Object Type: model</p> <p>Created: 1736797755390</p> <p>Owned By: poe</p> <p>Root: FLUX-Inpaint</p>"},{"location":"models/FLUX-dev-DI.html","title":"FLUX-dev-DI","text":""},{"location":"models/FLUX-dev-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: High quality image generator using FLUX dev model. Top of the line prompt following, visual quality and output diversity. This model is a text to image generation only and does not accept attachments. To further customize the prompt, you can follow the parameters available:</p> <p>To set width, use \"--width\". Valid pixel options from 128 up to 1920. Default value: 1024 To set height, use \"--height\". Valid pixel options from 128, up to 1920. Default value: 1024 To set seed, use \"--seed\" for reproducible result. Options from 1 up to 2**32. Default value: random To set inference, use \"--num_inference_steps\". Options from 1 up to 50. Default: 25</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/FLUX-dev-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/FLUX-dev-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 165 points/message |</p> <p>| Initial Points Cost | 165 points |</p> <p>Last Checked: 2025-08-05 23:20:10.330382</p>"},{"location":"models/FLUX-dev-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-dev-DI</code></p> <p>Object Type: model</p> <p>Created: 1750507284607</p> <p>Owned By: poe</p> <p>Root: FLUX-dev-DI</p>"},{"location":"models/FLUX-dev-finetuner.html","title":"FLUX-dev-finetuner","text":""},{"location":"models/FLUX-dev-finetuner.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Fine-tune the FLUX dev model with your own pictures! Upload 8-12 of them (same subject, only one subject in the picture, ideally from different poses and backgrounds) and wait ~2-5 minutes to create your own finetuned bot that will generate pictures of this subject in whatever setting you want.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/FLUX-dev-finetuner.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/FLUX-dev-finetuner.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Finetuning | 56667 points / message |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:20:18.224623</p>"},{"location":"models/FLUX-dev-finetuner.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-dev-finetuner</code></p> <p>Object Type: model</p> <p>Created: 1727479142160</p> <p>Owned By: poe</p> <p>Root: FLUX-dev-finetuner</p>"},{"location":"models/FLUX-dev.html","title":"FLUX-dev","text":""},{"location":"models/FLUX-dev.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: High-performance image generation with top of the line prompt following, visual quality, image detail and output diversity. This is a more efficient version of FLUX-pro, balancing quality and speed. Use \"--aspect\" to select an aspect ratio (e.g --aspect 1:1). Valid aspect ratios are 16:9, 4:3, 1:1, 3:4, 9:16.  Send an image to have this model reimagine/regenerate it via FLUX Redux.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/FLUX-dev.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/FLUX-dev.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 567 points / message |</p> <p>| Initial Points Cost | 567 points |</p> <p>Last Checked: 2025-08-05 23:20:03.360248</p>"},{"location":"models/FLUX-dev.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-dev</code></p> <p>Object Type: model</p> <p>Created: 1722521612508</p> <p>Owned By: poe</p> <p>Root: FLUX-dev</p>"},{"location":"models/FLUX-pro-1-T.html","title":"FLUX-pro-1-T","text":""},{"location":"models/FLUX-pro-1-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: The flagship model in the FLUX.1 lineup. Excels in prompt following, visual quality, image detail, and output diversity.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/FLUX-pro-1-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/FLUX-pro-1-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1250 points/message |</p> <p>| Initial Points Cost | 1250 points |</p> <p>Last Checked: 2025-08-05 23:20:31.853626</p>"},{"location":"models/FLUX-pro-1-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-pro-1-T</code></p> <p>Object Type: model</p> <p>Created: 1730863349678</p> <p>Owned By: poe</p> <p>Root: FLUX-pro-1-T</p>"},{"location":"models/FLUX-pro-1.1-T.html","title":"FLUX-pro-1.1-T","text":""},{"location":"models/FLUX-pro-1.1-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: The best state of the art image model from BFL. FLUX 1.1 Pro generates images six times faster than its predecessor, FLUX 1 Pro, while also improving image quality, prompt adherence, and output diversity.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/FLUX-pro-1.1-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/FLUX-pro-1.1-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1000 points/message |</p> <p>| Initial Points Cost | 1000 points |</p> <p>Last Checked: 2025-08-05 23:20:45.747196</p>"},{"location":"models/FLUX-pro-1.1-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-pro-1.1-T</code></p> <p>Object Type: model</p> <p>Created: 1730863432942</p> <p>Owned By: poe</p> <p>Root: FLUX-pro-1.1-T</p>"},{"location":"models/FLUX-pro-1.1-ultra.html","title":"FLUX-pro-1.1-ultra","text":""},{"location":"models/FLUX-pro-1.1-ultra.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: State-of-the-art image generation with four times the resolution of standard FLUX-1.1-pro. Best-in-class prompt adherence and pixel-perfect image detail. Use \"--aspect\" to select an aspect ratio (e.g --aspect 1:1). Add \"--raw\" (no other arguments needed) for an overall less processed, everyday aesthetic. Valid aspect ratios are 21:9, 16:9, 4:3, 1:1, 3:4, 9:16, &amp; 9:21. Send  an image to have this model reimagine/regenerate it via FLUX Redux, and use \"--strength\" (e.g --strength 0.7) to control the impact of the text prompt (1 gives greater influence, 0 means very little).\"--raw true\" to enable raw photographic detail.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/FLUX-pro-1.1-ultra.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/FLUX-pro-1.1-ultra.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 2000 points / message |</p> <p>| Initial Points Cost | 2000 points |</p> <p>Last Checked: 2025-08-05 23:20:52.759536</p>"},{"location":"models/FLUX-pro-1.1-ultra.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-pro-1.1-ultra</code></p> <p>Object Type: model</p> <p>Created: 1731696606126</p> <p>Owned By: poe</p> <p>Root: FLUX-pro-1.1-ultra</p>"},{"location":"models/FLUX-pro-1.1.html","title":"FLUX-pro-1.1","text":""},{"location":"models/FLUX-pro-1.1.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: State-of-the-art image generation with top-of-the-line prompt following, visual quality, image detail and output diversity. This is the most powerful version of FLUX 1.1, use \"--aspect\" to select an aspect ratio (e.g --aspect 1:1). Valid aspect ratios are 16:9, 4:3, 1:1, 3:4, 9:16. Send an image to have this model reimagine/regenerate it via FLUX Redux.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/FLUX-pro-1.1.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/FLUX-pro-1.1.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 1334 points / message |</p> <p>| Initial Points Cost | 1334 points |</p> <p>Last Checked: 2025-08-05 23:20:38.897480</p>"},{"location":"models/FLUX-pro-1.1.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-pro-1.1</code></p> <p>Object Type: model</p> <p>Created: 1727968438767</p> <p>Owned By: poe</p> <p>Root: FLUX-pro-1.1</p>"},{"location":"models/FLUX-pro.html","title":"FLUX-pro","text":""},{"location":"models/FLUX-pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: State-of-the-art image generation with top of the line prompt following, visual quality, image detail and output diversity. This is the most powerful version of FLUX.1. Use \"--aspect\" to select an aspect ratio (e.g --aspect 1:1). Valid aspect ratios are 16:9, 4:3, 1:1, 3:4, 9:16. Send an image to have this model reimagine/regenerate it via FLUX Redux.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/FLUX-pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/FLUX-pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 1667 points / message |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:20:25.099162</p>"},{"location":"models/FLUX-pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-pro</code></p> <p>Object Type: model</p> <p>Created: 1722529535890</p> <p>Owned By: poe</p> <p>Root: FLUX-pro</p>"},{"location":"models/FLUX-schnell-DI.html","title":"FLUX-schnell-DI","text":""},{"location":"models/FLUX-schnell-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: This is the fastest version of FLUX, featuring highly optimized abstract models that excel at creative and unconventional renders. To further customize the prompt, you can follow the parameters available:</p> <p>To set width, use \"--width\". Valid pixel options from 128 up to 1920. Default value: 1024 To set height, use \"--height\". Valid pixel options from 128, up to 1920. Default value: 1024 To set seed, use \"--seed\" for reproducible result. Options from 1 up to 2**32. Default value: random To set inference, use \"--num_inference_steps\". Options from 1 up to 50. Default: 1</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/FLUX-schnell-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/FLUX-schnell-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 33 points/message |</p> <p>| Initial Points Cost | 33 points |</p> <p>Last Checked: 2025-08-05 23:21:07.325562</p>"},{"location":"models/FLUX-schnell-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-schnell-DI</code></p> <p>Object Type: model</p> <p>Created: 1750333477944</p> <p>Owned By: poe</p> <p>Root: FLUX-schnell-DI</p>"},{"location":"models/FLUX-schnell.html","title":"FLUX-schnell","text":""},{"location":"models/FLUX-schnell.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Turbo speed image generation with strengths in prompt following, visual quality, image detail and output diversity. This is the fastest version of FLUX.1. Use \"--aspect\" to select an aspect ratio (e.g --aspect 1:1). Valid aspect ratios are 16:9, 4:3, 1:1, 3:4, 9:16. Send an image to have this model reimagine/regenerate it via FLUX Redux.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/FLUX-schnell.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/FLUX-schnell.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 40 points / message |</p> <p>| Initial Points Cost | 40 points |</p> <p>Last Checked: 2025-08-05 23:20:59.827907</p>"},{"location":"models/FLUX-schnell.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>FLUX-schnell</code></p> <p>Object Type: model</p> <p>Created: 1722523149211</p> <p>Owned By: poe</p> <p>Root: FLUX-schnell</p>"},{"location":"models/Flux-1-Dev-FW.html","title":"Flux-1-Dev-FW","text":""},{"location":"models/Flux-1-Dev-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: FLUX.1 [dev] is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions.</p> <p>Key Features 1. Cutting-edge output quality, second only to our state-of-the-art model FLUX.1 [pro]. 2. Competitive prompt following, matching the performance of closed source alternatives. 3. Trained using guidance distillation, making FLUX.1 [dev] more efficient. 4. Open weights to drive new scientific research, and empower artists to develop innovative workflows. 5. Generated outputs can be used for personal, scientific, and commercial purposes as described in the FLUX.1 [dev] Non-Commercial License.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Flux-1-Dev-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Flux-1-Dev-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 375 points/message |</p> <p>| Initial Points Cost | 375 points |</p> <p>Last Checked: 2025-08-05 23:21:14.396193</p>"},{"location":"models/Flux-1-Dev-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Flux-1-Dev-FW</code></p> <p>Object Type: model</p> <p>Created: 1729618505818</p> <p>Owned By: poe</p> <p>Root: Flux-1-Dev-FW</p>"},{"location":"models/Flux-1-Schnell-FW.html","title":"Flux-1-Schnell-FW","text":""},{"location":"models/Flux-1-Schnell-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: FLUX.1 [schnell] is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions.</p> <p>Key Features 1. Cutting-edge output quality and competitive prompt following, matching the performance of closed source alternatives. 2. Trained using latent adversarial diffusion distillation, FLUX.1 [schnell] can generate high-quality images in only 1 to 4 steps. 3. Released under the apache-2.0 licence, the model can be used for personal, scientific, and commercial purposes.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Flux-1-Schnell-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Flux-1-Schnell-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 35 points/message |</p> <p>| Initial Points Cost | 35 points |</p> <p>Last Checked: 2025-08-05 23:21:22.057689</p>"},{"location":"models/Flux-1-Schnell-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Flux-1-Schnell-FW</code></p> <p>Object Type: model</p> <p>Created: 1729619977045</p> <p>Owned By: poe</p> <p>Root: Flux-1-Schnell-FW</p>"},{"location":"models/Flux-Kontext-Max.html","title":"Flux-Kontext-Max","text":""},{"location":"models/Flux-Kontext-Max.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: FLUX.1 Kontext [max] is a new premium model from Black Forest Labs that brings maximum performance across all aspects. Send a prompt to generate an image, or send an image along with an instruction to edit the image.  Use <code>--aspect</code> to set the aspect ratio for text-to-image-generation. Available aspect ratio (21:9, 16:9, 4:3, 1:1, 3:4, 9:16, &amp; 9:21)</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Flux-Kontext-Max.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Flux-Kontext-Max.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 2667 points / message |</p> <p>| Initial Points Cost | 2667 points |</p> <p>Last Checked: 2025-08-05 23:21:29.173255</p>"},{"location":"models/Flux-Kontext-Max.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Flux-Kontext-Max</code></p> <p>Object Type: model</p> <p>Created: 1748526727201</p> <p>Owned By: poe</p> <p>Root: Flux-Kontext-Max</p>"},{"location":"models/Flux-Kontext-Pro.html","title":"Flux-Kontext-Pro","text":""},{"location":"models/Flux-Kontext-Pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: The FLUX.1 Kontext [pro] model delivers state-of-the-art image generation results with unprecedented prompt following, photorealistic rendering, flawless typography, and image editing capabilities. Send a prompt to generate an image, or send an image along with an instruction to edit the image. Use <code>--aspect</code> to set the aspect ratio for text-to-image-generation. Available aspect ratio (21:9, 16:9, 4:3, 1:1, 3:4, 9:16, &amp; 9:21)</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Flux-Kontext-Pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Flux-Kontext-Pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 1334 points / message |</p> <p>| Initial Points Cost | 1334 points |</p> <p>Last Checked: 2025-08-05 23:21:36.157410</p>"},{"location":"models/Flux-Kontext-Pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Flux-Kontext-Pro</code></p> <p>Object Type: model</p> <p>Created: 1748527242279</p> <p>Owned By: poe</p> <p>Root: Flux-Kontext-Pro</p>"},{"location":"models/Flux-Schnell-T.html","title":"Flux-Schnell-T","text":""},{"location":"models/Flux-Schnell-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Lightning-fast AI image generation model that excels in producing high-quality visuals in just seconds. Great for quick prototyping or real-time use cases. This is the fastest version of FLUX.1.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Flux-Schnell-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Flux-Schnell-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 70 points/message |</p> <p>| Initial Points Cost | 70 points |</p> <p>Last Checked: 2025-08-05 23:21:43.063596</p>"},{"location":"models/Flux-Schnell-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Flux-Schnell-T</code></p> <p>Object Type: model</p> <p>Created: 1730862046687</p> <p>Owned By: poe</p> <p>Root: Flux-Schnell-T</p>"},{"location":"models/GLM-4.5.html","title":"GLM-4.5","text":""},{"location":"models/GLM-4.5.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: The GLM-4.5 series models are foundation models designed for intelligent agents. GLM-4.5 has 355 billion total parameters with 32 billion active parameters. It unifies reasoning, coding, and intelligent agent capabilities to meet the complex demands of intelligent agent applications.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/GLM-4.5.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GLM-4.5.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 180 points/message |</p> <p>| Initial Points Cost | 180 points |</p> <p>Last Checked: 2025-08-05 23:21:49.915138</p>"},{"location":"models/GLM-4.5.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GLM-4.5</code></p> <p>Object Type: model</p> <p>Created: 1753915796429</p> <p>Owned By: poe</p> <p>Root: GLM-4.5</p>"},{"location":"models/GPT-3.5-Turbo-Instruct.html","title":"GPT-3.5-Turbo-Instruct","text":""},{"location":"models/GPT-3.5-Turbo-Instruct.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: Powered by gpt-3.5-turbo-instruct.</p> <p>Extra: Powered by OpenAI: gpt-3.5-turbo-instruct. Learn more</p>"},{"location":"models/GPT-3.5-Turbo-Instruct.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-3.5-Turbo-Instruct.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 45 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 8 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 18+ points |</p> <p>Last Checked: 2025-08-05 23:22:03.798705</p>"},{"location":"models/GPT-3.5-Turbo-Instruct.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-3.5-Turbo-Instruct</code></p> <p>Object Type: model</p> <p>Created: 1695250309273</p> <p>Owned By: poe</p> <p>Root: GPT-3.5-Turbo-Instruct</p>"},{"location":"models/GPT-3.5-Turbo-Raw.html","title":"GPT-3.5-Turbo-Raw","text":""},{"location":"models/GPT-3.5-Turbo-Raw.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: Powered by gpt-3.5-turbo without a system prompt.</p> <p>Extra: Powered by OpenAI: gpt-3.5-turbo-0125. Learn more</p>"},{"location":"models/GPT-3.5-Turbo-Raw.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-3.5-Turbo-Raw.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 15 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 11 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 15+ points |</p> <p>Last Checked: 2025-08-05 23:22:11.148957</p>"},{"location":"models/GPT-3.5-Turbo-Raw.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-3.5-Turbo-Raw</code></p> <p>Object Type: model</p> <p>Created: 1695849978857</p> <p>Owned By: poe</p> <p>Root: GPT-3.5-Turbo-Raw</p>"},{"location":"models/GPT-3.5-Turbo.html","title":"GPT-3.5-Turbo","text":""},{"location":"models/GPT-3.5-Turbo.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI\u2019s GPT 3.5 Turbo model is a powerful language generation system designed to provide highly coherent, contextually relevant, and detailed responses. Supports 16,384 tokens of context. For most tasks, https://poe.com/GPT-4o or https://poe.com/GPT-4o-Mini will be better.</p> <p>Extra: Powered by OpenAI: gpt-3.5-turbo-0125. Learn more</p>"},{"location":"models/GPT-3.5-Turbo.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-3.5-Turbo.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 15 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 9 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 13+ points |</p> <p>Last Checked: 2025-08-05 23:21:56.930715</p>"},{"location":"models/GPT-3.5-Turbo.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-3.5-Turbo</code></p> <p>Object Type: model</p> <p>Created: 1694610718926</p> <p>Owned By: poe</p> <p>Root: GPT-3.5-Turbo</p>"},{"location":"models/GPT-4-Classic-0314.html","title":"GPT-4-Classic-0314","text":""},{"location":"models/GPT-4-Classic-0314.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI's GPT-4 model. Powered by gpt-4-0314 (non-Turbo) for text input and gpt-4o for image input. For most use cases, https://poe.com/GPT-4o will perform significantly better.</p> <p>Extra: Powered by OpenAI: gpt-4-0314. Learn more</p>"},{"location":"models/GPT-4-Classic-0314.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4-Classic-0314.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 900 points/1k tokens |</p> <p>| Input Image | 900 points/1k tokens |</p> <p>| Bot Message | 334 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 532+ points |</p> <p>Last Checked: 2025-08-05 23:22:25.061131</p>"},{"location":"models/GPT-4-Classic-0314.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4-Classic-0314</code></p> <p>Object Type: model</p> <p>Created: 1724707714433</p> <p>Owned By: poe</p> <p>Root: GPT-4-Classic-0314</p>"},{"location":"models/GPT-4-Classic.html","title":"GPT-4-Classic","text":""},{"location":"models/GPT-4-Classic.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI's GPT-4 model. Powered by gpt-4-0613 (non-Turbo) for text input and gpt-4o for image input. For most use cases, https://poe.com/GPT-4o will perform better.</p> <p>Extra: Powered by OpenAI: gpt-4-0613. Learn more</p>"},{"location":"models/GPT-4-Classic.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4-Classic.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 900 points/1k tokens |</p> <p>| Input Image | 900 points/1k tokens |</p> <p>| Bot Message | 559 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 757+ points |</p> <p>Last Checked: 2025-08-05 23:22:18.026353</p>"},{"location":"models/GPT-4-Classic.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4-Classic</code></p> <p>Object Type: model</p> <p>Created: 1711404454811</p> <p>Owned By: poe</p> <p>Root: GPT-4-Classic</p>"},{"location":"models/GPT-4-Turbo.html","title":"GPT-4-Turbo","text":""},{"location":"models/GPT-4-Turbo.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: Powered by OpenAI's GPT-4 Turbo with Vision. For most tasks, https://poe.com/GPT-4o will perform better. Supports 128k tokens of context. Requests with images will be routed to @GPT-4o.</p> <p>Extra: Powered by OpenAI: gpt-4-turbo-2024-04-09. Learn more</p>"},{"location":"models/GPT-4-Turbo.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4-Turbo.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 300 points/1k tokens |</p> <p>| Input Image | 300 points/1k tokens |</p> <p>| Bot Message | 285 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 351+ points |</p> <p>Last Checked: 2025-08-05 23:22:31.663097</p>"},{"location":"models/GPT-4-Turbo.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4-Turbo</code></p> <p>Object Type: model</p> <p>Created: 1694610718932</p> <p>Owned By: poe</p> <p>Root: GPT-4-Turbo</p>"},{"location":"models/GPT-4.1-mini.html","title":"GPT-4.1-mini","text":""},{"location":"models/GPT-4.1-mini.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: GPT-4.1 mini is a small, fast &amp; affordable model that matches or beats GPT-4o in many intelligence and vision-related tasks. Supports 1M tokens of context.</p> <p>Extra: Powered by OpenAI: gpt-4.1-mini-2025-04-14. Learn more</p>"},{"location":"models/GPT-4.1-mini.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4.1-mini.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 12 points/1k tokens |</p> <p>| Input Image | 12 points/1k tokens |</p> <p>| Bot Message | 22 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 75% discount oncached chat history |</p> <p>| Initial Points Cost | 25+ points |</p> <p>Last Checked: 2025-08-05 23:22:45.530107</p>"},{"location":"models/GPT-4.1-mini.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4.1-mini</code></p> <p>Object Type: model</p> <p>Created: 1744675260112</p> <p>Owned By: poe</p> <p>Root: GPT-4.1-mini</p>"},{"location":"models/GPT-4.1-nano.html","title":"GPT-4.1-nano","text":""},{"location":"models/GPT-4.1-nano.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: GPT-4.1 nano is an extremely fast and cheap model, ideal for text/vision summarization/categorization tasks. Supports native vision and 1M input tokens of context.</p> <p>Extra: Powered by OpenAI: gpt-4.1-nano-2025-04-14. Learn more</p>"},{"location":"models/GPT-4.1-nano.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4.1-nano.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 3 points/1k tokens |</p> <p>| Input Image | 3 points/1k tokens |</p> <p>| Bot Message | 6 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 75% discount oncached chat history |</p> <p>| Initial Points Cost | 7+ points |</p> <p>Last Checked: 2025-08-05 23:22:52.385639</p>"},{"location":"models/GPT-4.1-nano.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4.1-nano</code></p> <p>Object Type: model</p> <p>Created: 1744675276376</p> <p>Owned By: poe</p> <p>Root: GPT-4.1-nano</p>"},{"location":"models/GPT-4.1.html","title":"GPT-4.1","text":""},{"location":"models/GPT-4.1.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI\u2019s latest flagship model with significantly improved coding skills, long context (1M tokens), and improved instruction following. Supports native vision, and generally has more intelligence than GPT-4o.</p> <p>Extra: Powered by OpenAI: gpt-4.1-2025-04-14. Learn more</p>"},{"location":"models/GPT-4.1.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4.1.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 60 points/1k tokens |</p> <p>| Input Image | 60 points/1k tokens |</p> <p>| Bot Message | 193 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 75% discount oncached chat history |</p> <p>| Initial Points Cost | 206+ points |</p> <p>Last Checked: 2025-08-05 23:22:38.740327</p>"},{"location":"models/GPT-4.1.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4.1</code></p> <p>Object Type: model</p> <p>Created: 1744675047923</p> <p>Owned By: poe</p> <p>Root: GPT-4.1</p>"},{"location":"models/GPT-4o-Aug.html","title":"GPT-4o-Aug","text":""},{"location":"models/GPT-4o-Aug.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI's most powerful model, GPT-4o, using the August 2024 model snapshot. Stronger than GPT-3.5 in quantitative questions (math and physics), creative writing, and many other challenging tasks. To use the latest Nov 2024 model snapshot, please use https://poe.com/GPT-4o.</p> <p>Extra: Powered by OpenAI: gpt-4o-2024-08-06. Learn more</p>"},{"location":"models/GPT-4o-Aug.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4o-Aug.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 75 points/1k tokens |</p> <p>| Input Image | 75 points/1k tokens |</p> <p>| Bot Message | 128 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 50% discount oncached chat history |</p> <p>| Initial Points Cost | 145+ points |</p> <p>Last Checked: 2025-08-05 23:23:06.785217</p>"},{"location":"models/GPT-4o-Aug.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4o-Aug</code></p> <p>Object Type: model</p> <p>Created: 1732149774348</p> <p>Owned By: poe</p> <p>Root: GPT-4o-Aug</p>"},{"location":"models/GPT-4o-Search.html","title":"GPT-4o-Search","text":""},{"location":"models/GPT-4o-Search.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI's fine-tuned model for searching the web for real-time information. For less expensive messages, consider https://poe.com/GPT-4o-mini-Search. Uses medium search context size, currently in preview, supports 128k tokens of context. Does not support image search.</p> <p>Extra: Powered by OpenAI: gpt-4o-search-preview. Learn more</p>"},{"location":"models/GPT-4o-Search.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4o-Search.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 75 points/1k tokens |</p> <p>| Bot Message | 1232 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 1249+ points |</p> <p>Last Checked: 2025-08-05 23:23:13.685733</p>"},{"location":"models/GPT-4o-Search.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4o-Search</code></p> <p>Object Type: model</p> <p>Created: 1741720622451</p> <p>Owned By: poe</p> <p>Root: GPT-4o-Search</p>"},{"location":"models/GPT-4o-mini-Search.html","title":"GPT-4o-mini-Search","text":""},{"location":"models/GPT-4o-mini-Search.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI's fine-tuned model for searching the web for real-time information. For higher-performance, consider https://poe.com/GPT-4o-Search. Uses medium search context size, currently in preview, supports 128k tokens of context. Does not support image search.</p> <p>Extra: Powered by OpenAI: gpt-4o-mini-search-preview. Learn more</p>"},{"location":"models/GPT-4o-mini-Search.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4o-mini-Search.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 5 points/1k tokens |</p> <p>| Bot Message | 831 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 832+ points |</p> <p>Last Checked: 2025-08-05 23:23:27.757333</p>"},{"location":"models/GPT-4o-mini-Search.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4o-mini-Search</code></p> <p>Object Type: model</p> <p>Created: 1741724009166</p> <p>Owned By: poe</p> <p>Root: GPT-4o-mini-Search</p>"},{"location":"models/GPT-4o-mini.html","title":"GPT-4o-mini","text":""},{"location":"models/GPT-4o-mini.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: This intelligent small model from OpenAI is significantly smarter, cheaper, and just as fast as GPT-3.5 Turbo.</p> <p>Extra: Powered by OpenAI: gpt-4o-mini-2024-07-18. Learn more</p>"},{"location":"models/GPT-4o-mini.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4o-mini.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 5 points/1k tokens |</p> <p>| Input Image | 5 points/1k tokens |</p> <p>| Bot Message | 5 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 50% discount oncached chat history |</p> <p>| Initial Points Cost | 6+ points |</p> <p>Last Checked: 2025-08-05 23:23:20.637183</p>"},{"location":"models/GPT-4o-mini.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4o-mini</code></p> <p>Object Type: model</p> <p>Created: 1721338046069</p> <p>Owned By: poe</p> <p>Root: GPT-4o-mini</p>"},{"location":"models/GPT-4o.html","title":"GPT-4o","text":""},{"location":"models/GPT-4o.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI's GPT-4o answers user prompts in a natural, engaging &amp; tailored writing with strong overall world knowledge. Uses GPT-Image-1 to create and edit images conversationally. For fine-grained image generation control (e.g. image quality), use https://poe.com/GPT-Image-1. Supports context window of 128k tokens.</p> <p>Extra: Powered by OpenAI: gpt-4o-2024-11-20. Learn more</p>"},{"location":"models/GPT-4o.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-4o.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 75 points/1k tokens |</p> <p>| Input Image | 75 points/1k tokens |</p> <p>| Bot Message | 187 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 50% discount oncached chat history |</p> <p>| Initial Points Cost | Variable points |</p> <p>| Image Generation | Additional costs based on the \"Image Generation\" section below |</p> <p>Last Checked: 2025-08-05 23:22:59.250841</p>"},{"location":"models/GPT-4o.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-4o</code></p> <p>Object Type: model</p> <p>Created: 1715641234752</p> <p>Owned By: poe</p> <p>Root: GPT-4o</p>"},{"location":"models/GPT-Image-1.html","title":"GPT-Image-1","text":""},{"location":"models/GPT-Image-1.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI's model that powers image generation in ChatGPT, offering exceptional prompt adherence, level of detail, and quality. It supports editing, restyling, and combining images attached to the latest user query. For a conversational editing experience, use https://poe.com/GPT-4o (all users) or https://poe.com/Assistant (subscribers) instead.</p> <p>Optional parameters: * --aspect (options: 1:1, 3:2, 2:3): Aspect ratio of the output image * --quality (options: high, medium, low): Image resolution * --use_mask: Indicates that the last attached image is a mask for inpainting (editing specific regions). The mask must match the dimensions of the base image, with transparent (zero-alpha) areas showing which parts to edit.</p> <p>Extra: Powered by a server managed by @openai. Learn more</p>"},{"location":"models/GPT-Image-1.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/GPT-Image-1.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 151 points/1k tokens |</p> <p>| Initial Points Cost | Variable points |</p> <p>| Input (Images) | 301 points/1k tokens |</p> <p>| High Fidelity Editing | 2000 points |</p> <p>| Output (Image) | Based on output image quality and resolution (see table below) |</p> <p>Last Checked: 2025-08-05 23:23:34.836895</p>"},{"location":"models/GPT-Image-1.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-Image-1</code></p> <p>Object Type: model</p> <p>Created: 1743434309185</p> <p>Owned By: poe</p> <p>Root: GPT-Image-1</p>"},{"location":"models/GPT-OSS-120B-T.html","title":"GPT-OSS-120B-T","text":""},{"location":"models/GPT-OSS-120B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: OpenAI's GPT-OSS-120B delivers sophisticated chain-of-thought reasoning capabilities in a fully open model. Built with community feedback and released under Apache 2.0, this 120B parameter model provides transparency, customization, and deployment flexibility for organizations requiring complete data security &amp; privacy control.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/GPT-OSS-120B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-OSS-120B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 50 points/message |</p> <p>| Initial Points Cost | 50 points |</p> <p>Last Checked: 2025-08-05 23:23:42.232404</p>"},{"location":"models/GPT-OSS-120B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-OSS-120B-T</code></p> <p>Object Type: model</p> <p>Created: 1754415494029</p> <p>Owned By: poe</p> <p>Root: GPT-OSS-120B-T</p>"},{"location":"models/GPT-Researcher.html","title":"GPT-Researcher","text":""},{"location":"models/GPT-Researcher.html#bot-information","title":"Bot Information","text":"<p>Creator: @gptrdev</p> <p>Description: GPT Researcher is an agent that conducts deep research on any topic and generates a comprehensive report with citations. GPT Researcher is powered by Tavily's search engine.</p> <p>GPTR is based on the popular open source project: https://github.com/assafelovic/gpt-researcher -- by integrating Tavily search, it is optimized for curation and ranking of trusted research sources. Learn more at https://gptr.dev or https://tavily.com</p> <p>Extra: Powered by a server managed by @gptrdev. Learn more</p>"},{"location":"models/GPT-Researcher.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/GPT-Researcher.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Text Input | 100 points / token |</p> <p>| Initial Points Cost | Variable points |</p> <p>| Research Analysis | 200 points / research |</p> <p>| Research Response | 150 points / research |</p> <p>Last Checked: 2025-08-05 23:23:49.279887</p>"},{"location":"models/GPT-Researcher.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>GPT-Researcher</code></p> <p>Object Type: model</p> <p>Created: 1735901906014</p> <p>Owned By: poe</p> <p>Root: GPT-Researcher</p>"},{"location":"models/Gemini-1.5-Flash-Search.html","title":"Gemini-1.5-Flash-Search","text":""},{"location":"models/Gemini-1.5-Flash-Search.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Gemini 1.5 Flash enhanced by Grounding with Google Search for up-to-date information, and balances model performance and speed. For most use cases, https://poe.com/Gemini-2.0-Flash will perform better and supports grounding. Grounding model currently supports text only.</p> <p>Extra: Powered by Google: gemini-1.5-flash-002. Learn more</p>"},{"location":"models/Gemini-1.5-Flash-Search.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemini-1.5-Flash-Search.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 1 point/1k characters |</p> <p>| Bot Message | 3 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 4+ points |</p> <p>Last Checked: 2025-08-05 23:24:03.483648</p>"},{"location":"models/Gemini-1.5-Flash-Search.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemini-1.5-Flash-Search</code></p> <p>Object Type: model</p> <p>Created: 1710801504184</p> <p>Owned By: poe</p> <p>Root: Gemini-1.5-Flash-Search</p>"},{"location":"models/Gemini-1.5-Flash.html","title":"Gemini-1.5-Flash","text":""},{"location":"models/Gemini-1.5-Flash.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Gemini model optimized for narrower or high-frequency tasks where the speed of the model\u2019s response time matters the most. For most use cases, https://poe.com/Gemini-2.0-Flash will be better. The model accepts text, image, and video input from the entire conversation and provides text output, with a restriction of one video per message.</p> <p>Extra: Powered by Google: gemini-1.5-flash-002. Learn more</p>"},{"location":"models/Gemini-1.5-Flash.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemini-1.5-Flash.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 1 point/1k characters |</p> <p>| Input Image | 1 point/image |</p> <p>| Bot Message | 2 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 3+ points |</p> <p>| Input (Video) | 1 point/second |</p> <p>Last Checked: 2025-08-05 23:23:56.330740</p>"},{"location":"models/Gemini-1.5-Flash.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemini-1.5-Flash</code></p> <p>Object Type: model</p> <p>Created: 1715720620412</p> <p>Owned By: poe</p> <p>Root: Gemini-1.5-Flash</p>"},{"location":"models/Gemini-1.5-Pro-Search.html","title":"Gemini-1.5-Pro-Search","text":""},{"location":"models/Gemini-1.5-Pro-Search.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Gemini 1.5 Pro enhanced by Grounding with Google Search for up-to-date information, and balances model performance and speed. For most tasks, https://poe.com/Gemini-2.5-Pro will perform better and supports grounding. Grounding model currently supports text only.</p> <p>Extra: Powered by Google: gemini-1.5-pro-002. Learn more</p>"},{"location":"models/Gemini-1.5-Pro-Search.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemini-1.5-Pro-Search.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 5 points/1k characters |</p> <p>| Bot Message | 41 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 46+ points |</p> <p>Last Checked: 2025-08-05 23:24:17.101628</p>"},{"location":"models/Gemini-1.5-Pro-Search.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemini-1.5-Pro-Search</code></p> <p>Object Type: model</p> <p>Created: 1713221016407</p> <p>Owned By: poe</p> <p>Root: Gemini-1.5-Pro-Search</p>"},{"location":"models/Gemini-1.5-Pro.html","title":"Gemini-1.5-Pro","text":""},{"location":"models/Gemini-1.5-Pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Powered by gemini-1.5-pro-002. The multi-modal model from Google's Gemini family that balances model performance and speed. The model accepts text, image, and video input from the entire conversation and provides text output, with a restriction of one video per message.</p> <p>Extra: Powered by Google: gemini-1.5-pro-002. Learn more</p>"},{"location":"models/Gemini-1.5-Pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemini-1.5-Pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 5 points/1k characters |</p> <p>| Input Image | 5 points/image |</p> <p>| Bot Message | 30 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 35+ points |</p> <p>| Input (Video) | 5 points/second |</p> <p>Last Checked: 2025-08-05 23:24:10.361916</p>"},{"location":"models/Gemini-1.5-Pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemini-1.5-Pro</code></p> <p>Object Type: model</p> <p>Created: 1711587293628</p> <p>Owned By: poe</p> <p>Root: Gemini-1.5-Pro</p>"},{"location":"models/Gemini-2.0-Flash-Lite.html","title":"Gemini-2.0-Flash-Lite","text":""},{"location":"models/Gemini-2.0-Flash-Lite.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Gemini 2.0 Flash Lite is a new model variant from Google that is our most cost-efficient model yet, and often considered a spiritual successor to Gemini 1.5 Flash in terms of capability, context window size and cost. Does not support web search (if you need search, we recommend using https://poe.com/Gemini-2.0-Flash), supports 1 million tokens of input context.</p> <p>Extra: Powered by Google: gemini-2.0-flash-lite-001. Learn more</p>"},{"location":"models/Gemini-2.0-Flash-Lite.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemini-2.0-Flash-Lite.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 1 point/1k tokens |</p> <p>| Input Image | 1 point/1k tokens |</p> <p>| Bot Message | 5 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 6+ points |</p> <p>| Input (Video) | 1 point/second |</p> <p>Last Checked: 2025-08-05 23:24:31.048897</p>"},{"location":"models/Gemini-2.0-Flash-Lite.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemini-2.0-Flash-Lite</code></p> <p>Object Type: model</p> <p>Created: 1738780480313</p> <p>Owned By: poe</p> <p>Root: Gemini-2.0-Flash-Lite</p>"},{"location":"models/Gemini-2.0-Flash-Preview.html","title":"Gemini-2.0-Flash-Preview","text":""},{"location":"models/Gemini-2.0-Flash-Preview.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Gemini-2.0-Flash-Preview is designed for creative conversations, offering built-in image generation and the ability to understand both visuals and text. It excels at editing images through natural conversations and can even interpret videos! However, it doesn\u2019t provide web searches or access to real-time information.</p> <p>Extra: Powered by Google: gemini-2.0-flash-preview-image-generation. Learn more</p>"},{"location":"models/Gemini-2.0-Flash-Preview.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Gemini-2.0-Flash-Preview.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 2 points/message |</p> <p>| Initial Points Cost | 2 points |</p> <p>Last Checked: 2025-08-05 23:24:38.164410</p>"},{"location":"models/Gemini-2.0-Flash-Preview.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemini-2.0-Flash-Preview</code></p> <p>Object Type: model</p> <p>Created: 1741921762534</p> <p>Owned By: poe</p> <p>Root: Gemini-2.0-Flash-Preview</p>"},{"location":"models/Gemini-2.0-Flash.html","title":"Gemini-2.0-Flash","text":""},{"location":"models/Gemini-2.0-Flash.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Gemini 2.0 Flash is Google's most popular model yet with enhanced performance and blazingly fast response times; supports web search grounding so can intelligently answer questions related to recent events. Notably, 2.0 Flash even outperforms 1.5 Pro on key benchmarks, at twice the speed. Supports 1 million tokens of input context.</p> <p>Extra: Powered by Google: gemini-2.0-flash-001. Learn more</p>"},{"location":"models/Gemini-2.0-Flash.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemini-2.0-Flash.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 2 points/1k tokens |</p> <p>| Input Image | 2 points/1k tokens |</p> <p>| Bot Message | 6 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 7+ points |</p> <p>| Input (Video) | 1 point/second |</p> <p>Last Checked: 2025-08-05 23:24:23.907981</p>"},{"location":"models/Gemini-2.0-Flash.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemini-2.0-Flash</code></p> <p>Object Type: model</p> <p>Created: 1733958136993</p> <p>Owned By: poe</p> <p>Root: Gemini-2.0-Flash</p>"},{"location":"models/Gemini-2.5-Flash-Lite-Preview.html","title":"Gemini-2.5-Flash-Lite-Preview","text":""},{"location":"models/Gemini-2.5-Flash-Lite-Preview.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: A lightweight Gemini 2.5 Flash reasoning model optimized for cost efficiency and low latency. Supports web search. Supports 1 million tokens of input context. For more complex queries, use https://poe.com/Gemini-2.5-Pro or https://poe.com/Gemini-2.5-Flash</p> <p>To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 24,576 to the end of your message.</p> <p>Extra: Powered by Google: gemini-2.5-flash-lite-preview-06-17. Learn more</p>"},{"location":"models/Gemini-2.5-Flash-Lite-Preview.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemini-2.5-Flash-Lite-Preview.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemini-2.5-Flash-Lite-Preview</code></p> <p>Object Type: model</p> <p>Created: 1750348180783</p> <p>Owned By: poe</p> <p>Root: Gemini-2.5-Flash-Lite-Preview</p>"},{"location":"models/Gemini-2.5-Flash.html","title":"Gemini-2.5-Flash","text":""},{"location":"models/Gemini-2.5-Flash.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Gemini 2.5 Flash builds upon the popular foundation of Google's 2.0 Flash, this new version delivers a major upgrade in reasoning capabilities, search capabilities, and image/video understanding while still prioritizing speed and cost. Supports 1M tokens of input context.</p> <p>To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 24,576 to the end of your message.</p> <p>Extra: Powered by Google: gemini-2.5-flash. Learn more</p>"},{"location":"models/Gemini-2.5-Flash.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemini-2.5-Flash.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 3 points/1k tokens |</p> <p>| Input Image | 3 points/1k tokens |</p> <p>| Bot Message | 8 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 9+ points |</p> <p>| Input (Video) | 1 point/second |</p> <p>Last Checked: 2025-08-05 23:24:45.534393</p>"},{"location":"models/Gemini-2.5-Flash.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemini-2.5-Flash</code></p> <p>Object Type: model</p> <p>Created: 1745638152572</p> <p>Owned By: poe</p> <p>Root: Gemini-2.5-Flash</p>"},{"location":"models/Gemini-2.5-Pro.html","title":"Gemini-2.5-Pro","text":""},{"location":"models/Gemini-2.5-Pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Gemini 2.5 Pro is Google's advanced model with frontier performance on various key benchmarks; supports web search and 1 million tokens of input context. To instruct the bot to use more thinking effort, add --thinking_budget and a number ranging from 0 to 32,768 to the end of your message.</p> <p>Extra: Powered by Google: gemini-2.5-pro. Learn more</p>"},{"location":"models/Gemini-2.5-Pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemini-2.5-Pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 13 points/1k tokens |</p> <p>| Input Image | 13 points/1k tokens |</p> <p>| Bot Message | 332 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 335+ points |</p> <p>| Input (Video) | 4 points/second |</p> <p>Last Checked: 2025-08-05 23:24:59.111047</p>"},{"location":"models/Gemini-2.5-Pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemini-2.5-Pro</code></p> <p>Object Type: model</p> <p>Created: 1738780524168</p> <p>Owned By: poe</p> <p>Root: Gemini-2.5-Pro</p>"},{"location":"models/Gemma-2-27b-T.html","title":"Gemma-2-27b-T","text":""},{"location":"models/Gemma-2-27b-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Gemma 2 27B Instruct from Google. For most use cases, https://poe.com/Gemini-2.0-Flash or https://poe.com/Gemini-2.0-Pro will produce better results.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Gemma-2-27b-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemma-2-27b-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 90 points/message |</p> <p>| Initial Points Cost | 90 points |</p> <p>Last Checked: 2025-08-05 23:25:06.097695</p>"},{"location":"models/Gemma-2-27b-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemma-2-27b-T</code></p> <p>Object Type: model</p> <p>Created: 1721258568677</p> <p>Owned By: poe</p> <p>Root: Gemma-2-27b-T</p>"},{"location":"models/Gemma-3-27B.html","title":"Gemma-3-27B","text":""},{"location":"models/Gemma-3-27B.html#bot-information","title":"Bot Information","text":"<p>Creator: @empiriolabsai</p> <p>Description: Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 27B is Google's latest open source model, successor to Gemma 2</p> <p>Extra: Powered by a server managed by @empiriolabsai. Learn more</p>"},{"location":"models/Gemma-3-27B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Gemma-3-27B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Per Message | 134 points |</p> <p>| Initial Points Cost | 134 points |</p> <p>Last Checked: 2025-08-05 23:25:13.184251</p>"},{"location":"models/Gemma-3-27B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Gemma-3-27B</code></p> <p>Object Type: model</p> <p>Created: 1742186137210</p> <p>Owned By: poe</p> <p>Root: Gemma-3-27B</p>"},{"location":"models/Grok-2.html","title":"Grok-2","text":""},{"location":"models/Grok-2.html#bot-information","title":"Bot Information","text":"<p>Creator: @xai</p> <p>Description: Grok 2 is xAI's latest and most intelligent language model. It features state-of-the-art capabilities in coding, reasoning, and answering questions. It excels at handling complex and multi-step tasks. Grok 2 does not have access to real-time information from X or the internet as part of its integration with Poe.</p> <p>Extra: Powered by a server managed by @xai. Learn more</p>"},{"location":"models/Grok-2.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Grok-2.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 67 points/1k tokens |</p> <p>| Input Image | 18 points/image |</p> <p>| Bot Message | 169 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 185+ points |</p> <p>Last Checked: 2025-08-05 23:25:21.464057</p>"},{"location":"models/Grok-2.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Grok-2</code></p> <p>Object Type: model</p> <p>Created: 1736893314102</p> <p>Owned By: poe</p> <p>Root: Grok-2</p>"},{"location":"models/Grok-3-Mini.html","title":"Grok-3-Mini","text":""},{"location":"models/Grok-3-Mini.html#bot-information","title":"Bot Information","text":"<p>Creator: @xai</p> <p>Description: xAI's February 2025 release with strong performance across many domains but at a more affordable price point. Supports reasoning with a configurable reasoning effort level, and 131k tokens of context; doesn't have access to the X data feed. To instruct the bot to use more reasoning effort, add --reasoning_effort to the end of your message with one of \"low\" or \"high\".</p> <p>Extra: Powered by a server managed by @xai. Learn more</p>"},{"location":"models/Grok-3-Mini.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Grok-3-Mini.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 10 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 37 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 40+ points |</p> <p>Last Checked: 2025-08-05 23:25:36.036731</p>"},{"location":"models/Grok-3-Mini.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Grok-3-Mini</code></p> <p>Object Type: model</p> <p>Created: 1744388431404</p> <p>Owned By: poe</p> <p>Root: Grok-3-Mini</p>"},{"location":"models/Grok-3.html","title":"Grok-3","text":""},{"location":"models/Grok-3.html#bot-information","title":"Bot Information","text":"<p>Creator: @xai</p> <p>Description: xAI's February 2025 flagship release representing nearly state-of-the-art performance in several reasoning/problem solving domains. The API doesn't yet support reasoning mode for Grok 3, but does for https://poe.com/Grok-3-Mini; this bot also doesn't have access to the X data feed. Supports 131k tokens of context, uses Grok 2 for native vision.</p> <p>Extra: Powered by a server managed by @xai. Learn more</p>"},{"location":"models/Grok-3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Grok-3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 100 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 833 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 856+ points |</p> <p>Last Checked: 2025-08-05 23:25:28.709101</p>"},{"location":"models/Grok-3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Grok-3</code></p> <p>Object Type: model</p> <p>Created: 1744341886555</p> <p>Owned By: poe</p> <p>Root: Grok-3</p>"},{"location":"models/Grok-4.html","title":"Grok-4","text":""},{"location":"models/Grok-4.html#bot-information","title":"Bot Information","text":"<p>Creator: @xai</p> <p>Description: Grok 4 is xAI's latest and most intelligent language model. It features state-of-the-art capabilities in coding, reasoning, and answering questions. It excels at handling complex and multi-step tasks. Reasoning traces are not available via the xAI API.</p> <p>Extra: Powered by a server managed by @xai. Learn more</p>"},{"location":"models/Grok-4.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Grok-4.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 100 points/1k tokens |</p> <p>| Input Image | 90 points/image |</p> <p>| Bot Message | 750 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 773+ points |</p> <p>Last Checked: 2025-08-05 23:25:42.816787</p>"},{"location":"models/Grok-4.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Grok-4</code></p> <p>Object Type: model</p> <p>Created: 1752143407651</p> <p>Owned By: poe</p> <p>Root: Grok-4</p>"},{"location":"models/Hailuo-02-Standard.html","title":"Hailuo-02-Standard","text":""},{"location":"models/Hailuo-02-Standard.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: MiniMax Hailuo-02 Video Generation model: Advanced image-to-video generation model with 768p resolution. Send a prompt with an image for image-to-video, and just a prompt for text-to-video generation. Use <code>--duration</code> to set the video duration (6 or 10 seconds).</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Hailuo-02-Standard.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Hailuo-02-Standard.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 1500 points / second |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:25:56.927553</p>"},{"location":"models/Hailuo-02-Standard.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Hailuo-02-Standard</code></p> <p>Object Type: model</p> <p>Created: 1750266147410</p> <p>Owned By: poe</p> <p>Root: Hailuo-02-Standard</p>"},{"location":"models/Hailuo-02.html","title":"Hailuo-02","text":""},{"location":"models/Hailuo-02.html#bot-information","title":"Bot Information","text":"<p>Creator: @MiniMax</p> <p>Description: Hailuo-02, MiniMax's latest video generation model. Generates 6-second, 768p videos, just submit a text prompt or an image with a prompt describing the desired video behavior, and it will create it; typically takes ~5 minutes for generation time. Strong motion effects and ultra-clear quality.</p> <p>Extra: Powered by a server managed by @MiniMax. Learn more</p>"},{"location":"models/Hailuo-02.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Hailuo-02.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | 7000+ |</p> <p>| 768P-6S Video | 14000 credits per video |</p> <p>Last Checked: 2025-08-05 23:25:50.075692</p>"},{"location":"models/Hailuo-02.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Hailuo-02</code></p> <p>Object Type: model</p> <p>Created: 1750150747414</p> <p>Owned By: poe</p> <p>Root: Hailuo-02</p>"},{"location":"models/Hailuo-AI.html","title":"Hailuo-AI","text":""},{"location":"models/Hailuo-AI.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Best-in-class text and image to video model by MiniMax.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Hailuo-AI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Hailuo-AI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 14167 points / message |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:26:03.811511</p>"},{"location":"models/Hailuo-AI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Hailuo-AI</code></p> <p>Object Type: model</p> <p>Created: 1729194728486</p> <p>Owned By: poe</p> <p>Root: Hailuo-AI</p>"},{"location":"models/Hailuo-Director-01.html","title":"Hailuo-Director-01","text":""},{"location":"models/Hailuo-Director-01.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Generate video clips more accurately with respect to natural language descriptions and using camera movement instructions for shot control. Both text-to-video and image-to-video are supported. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Hailuo-Director-01.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Hailuo-Director-01.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 16667 points / message |</p> <p>| Initial Points Cost | 16667 points |</p> <p>Last Checked: 2025-08-05 23:26:10.693794</p>"},{"location":"models/Hailuo-Director-01.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Hailuo-Director-01</code></p> <p>Object Type: model</p> <p>Created: 1749502785341</p> <p>Owned By: poe</p> <p>Root: Hailuo-Director-01</p>"},{"location":"models/Hailuo-Live.html","title":"Hailuo-Live","text":""},{"location":"models/Hailuo-Live.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Hailuo Live, the latest model from Minimax, sets a new standard for bringing still images to life. From breathtakingly vivid motion to finely tuned expressions, this state-of-the-art model enables your characters to captivate, move, and shine like never before. It excels in bring art and drawings to life, exceptional realism without morphing, emotional range, and unparalleled character consistency.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Hailuo-Live.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Hailuo-Live.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 14167 points / message |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:26:18.071920</p>"},{"location":"models/Hailuo-Live.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Hailuo-Live</code></p> <p>Object Type: model</p> <p>Created: 1734370063740</p> <p>Owned By: poe</p> <p>Root: Hailuo-Live</p>"},{"location":"models/Hailuo-Speech-02.html","title":"Hailuo-Speech-02","text":""},{"location":"models/Hailuo-Speech-02.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Generate speech from text prompts using the MiniMax Speech-02 model. Include <code>--hd</code> at the end of your prompt for higher quality output with a higher price. You may set language with <code>--language</code>, voice with<code>--voice</code>, pitch with <code>--pitch</code>, speed with <code>--speed</code>, and volume with <code>--volume</code>. Please check the UI for allowed values for each parameter.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Hailuo-Speech-02.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: audio</p> <p>Modality: text-&gt;audio</p>"},{"location":"models/Hailuo-Speech-02.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| Hd Output | 3334 points / 1000 characters |</p> <p>| Turbo Output | 2000 points / 1000 characters |</p> <p>Last Checked: 2025-08-05 23:26:25.018163</p>"},{"location":"models/Hailuo-Speech-02.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Hailuo-Speech-02</code></p> <p>Object Type: model</p> <p>Created: 1749503032615</p> <p>Owned By: poe</p> <p>Root: Hailuo-Speech-02</p>"},{"location":"models/Hermes-3-70B.html","title":"Hermes-3-70B","text":""},{"location":"models/Hermes-3-70B.html#bot-information","title":"Bot Information","text":"<p>Creator: @hyperbolic</p> <p>Description: Hermes 3 is the latest version of our flagship Hermes series of LLMs by Nous Research. Hermes 3 is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board. The ethos of the Hermes series of models is focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.</p> <p>Extra: Powered by a server managed by @hyperbolic. Learn more</p>"},{"location":"models/Hermes-3-70B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Hermes-3-70B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 200 points/message |</p> <p>| Initial Points Cost | 200 points |</p> <p>Last Checked: 2025-08-05 23:26:31.785836</p>"},{"location":"models/Hermes-3-70B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Hermes-3-70B</code></p> <p>Object Type: model</p> <p>Created: 1724032528549</p> <p>Owned By: poe</p> <p>Root: Hermes-3-70B</p>"},{"location":"models/Hidream-I1-full.html","title":"Hidream-I1-full","text":""},{"location":"models/Hidream-I1-full.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Hidream-I1 is a state-of-the-art text to image model by Hidream. Use <code>--aspect</code> to set the aspect ratio. Valid aspect ratios are 16:9, 4:3, 1:1, 3:4, 9:16. Use <code>--negative_prompt</code> to set the negative prompt. Hosted by fal.ai.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Hidream-I1-full.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Hidream-I1-full.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 1417 points / message |</p> <p>| Initial Points Cost | 1417 points |</p> <p>Last Checked: 2025-08-05 23:26:38.962827</p>"},{"location":"models/Hidream-I1-full.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Hidream-I1-full</code></p> <p>Object Type: model</p> <p>Created: 1747144375790</p> <p>Owned By: poe</p> <p>Root: Hidream-I1-full</p>"},{"location":"models/Ideogram-v2.html","title":"Ideogram-v2","text":""},{"location":"models/Ideogram-v2.html#bot-information","title":"Bot Information","text":"<p>Creator: @ideogramai</p> <p>Description: Latest image model from Ideogram, with industry leading capabilities in generating realistic images, graphic design, typography, and more. Allows users to specify the aspect ratio of the image using the \"--aspect\" parameter at the end of the prompt (e.g. \"Tall trees, daylight --aspect 9:16\"). Valid aspect ratios are 10:16, 16:10, 9:16, 16:9, 3:2, 2:3, 4:3, 3:4, 1:1. \"--style\" parameter can be defined to specify the style of image generated(GENERAL, REALISTIC, DESIGN, RENDER_3D, ANIME). Powered by Ideogram.</p> <p>Extra: Powered by a server managed by @ideogramai. Learn more</p>"},{"location":"models/Ideogram-v2.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Ideogram-v2.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1900 points/message |</p> <p>| Initial Points Cost | 1900 points |</p> <p>Last Checked: 2025-08-05 23:26:52.339205</p>"},{"location":"models/Ideogram-v2.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Ideogram-v2</code></p> <p>Object Type: model</p> <p>Created: 1724273571743</p> <p>Owned By: poe</p> <p>Root: Ideogram-v2</p>"},{"location":"models/Ideogram-v2a-Turbo.html","title":"Ideogram-v2a-Turbo","text":""},{"location":"models/Ideogram-v2a-Turbo.html#bot-information","title":"Bot Information","text":"<p>Creator: @ideogramai</p> <p>Description: Fast, affordable text-to-image model, optimized for graphic design and photography. For higher quality, use https://poe.com/Ideogram-v2A Use <code>--aspect</code> to set the aspect ratio, and use <code>--style</code> to specify a style (one of <code>GENERAL</code>, <code>REALISTIC</code>, <code>DESIGN</code>, <code>3D RENDER</code> and <code>ANIME</code> default: <code>GENERAL</code>.)</p> <p>Extra: Powered by a server managed by @ideogramai. Learn more</p>"},{"location":"models/Ideogram-v2a-Turbo.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Ideogram-v2a-Turbo.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 800 points/message |</p> <p>| Initial Points Cost | 800 points |</p> <p>Last Checked: 2025-08-05 23:27:06.161208</p>"},{"location":"models/Ideogram-v2a-Turbo.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Ideogram-v2a-Turbo</code></p> <p>Object Type: model</p> <p>Created: 1740678577836</p> <p>Owned By: poe</p> <p>Root: Ideogram-v2a-Turbo</p>"},{"location":"models/Ideogram-v2a.html","title":"Ideogram-v2a","text":""},{"location":"models/Ideogram-v2a.html#bot-information","title":"Bot Information","text":"<p>Creator: @ideogramai</p> <p>Description: Fast, affordable text-to-image model, optimized for graphic design and photography. For faster and more cost-effective generations, use https://poe.com/Ideogram-v2A-Turbo Use <code>--aspect</code> to set the aspect ratio, and use <code>--style</code> to specify a style (one of <code>GENERAL</code>, <code>REALISTIC</code>, <code>DESIGN</code>, <code>3D RENDER</code> and <code>ANIME</code> default: <code>GENERAL</code>.)</p> <p>Extra: Powered by a server managed by @ideogramai. Learn more</p>"},{"location":"models/Ideogram-v2a.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Ideogram-v2a.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1300 points/message |</p> <p>| Initial Points Cost | 1300 points |</p> <p>Last Checked: 2025-08-05 23:26:59.261416</p>"},{"location":"models/Ideogram-v2a.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Ideogram-v2a</code></p> <p>Object Type: model</p> <p>Created: 1740678539688</p> <p>Owned By: poe</p> <p>Root: Ideogram-v2a</p>"},{"location":"models/Ideogram-v3.html","title":"Ideogram-v3","text":""},{"location":"models/Ideogram-v3.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Generate high-quality images, posters, and logos with Ideogram V3. Features exceptional typography handling and realistic outputs optimized for commercial and creative use. Use <code>--aspect</code> to set the aspect ratio (Valid aspect ratios are 16:9, 4:3, 1:1, 3:4, 9:16), and use <code>--style</code>  to specify a style (one of <code>AUTO</code>, <code>GENERAL</code>, <code>REALISTIC</code>, and <code>DESIGN</code>, default: <code>AUTO</code>.). Send one image with a prompt for image remixing/restyling. Send two images (one an image and the other a black-and-white mask image denoting an area) for image editing.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Ideogram-v3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Ideogram-v3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 2000 points / message |</p> <p>| Initial Points Cost | 2000 points |</p> <p>Last Checked: 2025-08-05 23:27:13.027905</p>"},{"location":"models/Ideogram-v3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Ideogram-v3</code></p> <p>Object Type: model</p> <p>Created: 1746189583927</p> <p>Owned By: poe</p> <p>Root: Ideogram-v3</p>"},{"location":"models/Ideogram.html","title":"Ideogram","text":""},{"location":"models/Ideogram.html#bot-information","title":"Bot Information","text":"<p>Creator: @ideogramai</p> <p>Description: Excels at creating high-quality images from text prompts. For most prompts, https://poe.com/Ideogram-v2 will produce better results. Allows users to specify the aspect ratio of the image using the \"--aspect\" parameter at the end of the prompt (e.g. \"Tall trees, daylight --aspect 9:16\"). Valid aspect ratios are 10:16, 16:10, 9:16, 16:9, 3:2, 2:3, 4:3, 3:4, &amp; 1:1.</p> <p>Extra: Powered by a server managed by @ideogramai. Learn more</p>"},{"location":"models/Ideogram.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Ideogram.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1500 points/message |</p> <p>| Initial Points Cost | 1500 points |</p> <p>Last Checked: 2025-08-05 23:26:45.751930</p>"},{"location":"models/Ideogram.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Ideogram</code></p> <p>Object Type: model</p> <p>Created: 1712178346331</p> <p>Owned By: poe</p> <p>Root: Ideogram</p>"},{"location":"models/Imagen-3-Fast.html","title":"Imagen-3-Fast","text":""},{"location":"models/Imagen-3-Fast.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Google DeepMind's highest quality text-to-image model, capable of generating images with great detail, rich lighting, and few distracting artifacts \u2014 optimized for short, simple prompts. To adjust the aspect ratio of your image add --aspect_ratio (1:1, 16:9, 9:16, 4:3, 3:4). For more complex prompts, use @Imagen3. Non english input will be translated first.</p> <p>Extra: Powered by a server managed by @google. Learn more</p>"},{"location":"models/Imagen-3-Fast.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Imagen-3-Fast.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 200 points/message |</p> <p>| Initial Points Cost | 200 points |</p> <p>Last Checked: 2025-08-05 23:27:27.058791</p>"},{"location":"models/Imagen-3-Fast.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Imagen-3-Fast</code></p> <p>Object Type: model</p> <p>Created: 1729127959259</p> <p>Owned By: poe</p> <p>Root: Imagen-3-Fast</p>"},{"location":"models/Imagen-3.html","title":"Imagen-3","text":""},{"location":"models/Imagen-3.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Google DeepMind's highest quality text-to-image model, capable of generating images with great detail, rich lighting, and few distracting artifacts. To adjust the aspect ratio of your image add --aspect_ratio (1:1, 16:9, 9:16, 4:3, 3:4). For simpler prompts, faster results, &amp; lower cost, use @Imagen3-Fast. Non english input will be translated first.</p> <p>Extra: Powered by a server managed by @google. Learn more</p>"},{"location":"models/Imagen-3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Imagen-3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 400 points/message |</p> <p>| Initial Points Cost | 400 points |</p> <p>Last Checked: 2025-08-05 23:27:20.123244</p>"},{"location":"models/Imagen-3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Imagen-3</code></p> <p>Object Type: model</p> <p>Created: 1729023417016</p> <p>Owned By: poe</p> <p>Root: Imagen-3</p>"},{"location":"models/Imagen-4-Fast.html","title":"Imagen-4-Fast","text":""},{"location":"models/Imagen-4-Fast.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: DeepMind's June 2025 text-to-image model with exceptional prompt adherence, capable of generating images with great detail, rich lighting, and few distracting artifacts. To adjust the aspect ratio of your image add --aspect_ratio (1:1, 16:9, 9:16, 4:3, 3:4). Non-English input will be translated first. Serves the <code>imagen-4.0-fast-generate-preview-06-06</code> model from Google Vertex, and has a maximum input of 480 tokens.</p> <p>Extra: Powered by a server managed by @google. Learn more</p>"},{"location":"models/Imagen-4-Fast.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Imagen-4-Fast.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 200 points/message |</p> <p>| Initial Points Cost | 200 points |</p> <p>Last Checked: 2025-08-05 23:27:41.002410</p>"},{"location":"models/Imagen-4-Fast.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Imagen-4-Fast</code></p> <p>Object Type: model</p> <p>Created: 1750875079224</p> <p>Owned By: poe</p> <p>Root: Imagen-4-Fast</p>"},{"location":"models/Imagen-4-Ultra-Exp.html","title":"Imagen-4-Ultra-Exp","text":""},{"location":"models/Imagen-4-Ultra-Exp.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: DeepMind's May 2025 text-to-image model with exceptional prompt adherence, capable of generating images with great detail, rich lighting, and few distracting artifacts. To adjust the aspect ratio of your image add --aspect_ratio (1:1, 16:9, 9:16, 4:3, 3:4). Non-English input will be translated first. Serves the <code>imagen-4.0-ultra-generate-exp-05-20</code> model from Google Vertex, and has a maximum input of 480 tokens.</p> <p>Extra: Powered by a server managed by @google. Learn more</p>"},{"location":"models/Imagen-4-Ultra-Exp.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Imagen-4-Ultra-Exp.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 400 points/message |</p> <p>| Initial Points Cost | 400 points |</p> <p>Last Checked: 2025-08-05 23:27:47.764398</p>"},{"location":"models/Imagen-4-Ultra-Exp.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Imagen-4-Ultra-Exp</code></p> <p>Object Type: model</p> <p>Created: 1748061401435</p> <p>Owned By: poe</p> <p>Root: Imagen-4-Ultra-Exp</p>"},{"location":"models/Imagen-4.html","title":"Imagen-4","text":""},{"location":"models/Imagen-4.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: DeepMind's May 2025 text-to-image model with exceptional prompt adherence, capable of generating images with great detail, rich lighting, and few distracting artifacts. To adjust the aspect ratio of your image add --aspect_ratio (1:1, 16:9, 9:16, 4:3, 3:4). Non-English input will be translated first. Serves the <code>imagen-4.0-ultra-generate-05-20</code> model from Google Vertex, and has a maximum input of 480 tokens.</p> <p>Extra: Powered by a server managed by @google. Learn more</p>"},{"location":"models/Imagen-4.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Imagen-4.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 400 points/message |</p> <p>| Initial Points Cost | 400 points |</p> <p>Last Checked: 2025-08-05 23:27:33.935208</p>"},{"location":"models/Imagen-4.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Imagen-4</code></p> <p>Object Type: model</p> <p>Created: 1747888192720</p> <p>Owned By: poe</p> <p>Root: Imagen-4</p>"},{"location":"models/Inception-Mercury-Coder.html","title":"Inception-Mercury-Coder","text":""},{"location":"models/Inception-Mercury-Coder.html#bot-information","title":"Bot Information","text":"<p>Creator: @inceptionlabsai</p> <p>Description: Mercury Coder is the first diffusion large language model (dLLM). Applying a breakthrough discrete diffusion approach, the model runs 5-10x faster than even speed optimized models like Claude 3.5 Haiku and GPT-4o Mini while matching their performance. Mercury Coder Small's speed means that developers can stay in the flow while coding, enjoying rapid chat-based iteration and responsive code completion suggestions. On Copilot Arena, Mercury Coder ranks 1st in speed and ties for 2nd in quality. Read more in the blog post here: https://www.inceptionlabs.ai/introducing-mercury.</p> <p>Extra: Powered by a server managed by @inceptionlabsai. Learn more</p>"},{"location":"models/Inception-Mercury-Coder.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Inception-Mercury-Coder.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 9 points / 1k tokens |</p> <p>| Initial Points Cost | 14+ points |</p> <p>| Bot Message (Text) | 34 points / 1k tokens |</p> <p>Last Checked: 2025-08-05 23:28:01.303010</p>"},{"location":"models/Inception-Mercury-Coder.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Inception-Mercury-Coder</code></p> <p>Object Type: model</p> <p>Created: 1747072614396</p> <p>Owned By: poe</p> <p>Root: Inception-Mercury-Coder</p>"},{"location":"models/Inception-Mercury.html","title":"Inception-Mercury","text":""},{"location":"models/Inception-Mercury.html#bot-information","title":"Bot Information","text":"<p>Creator: @inceptionlabsai</p> <p>Description: Mercury is the first diffusion large language model (dLLM). On Copilot Arena, Mercury Coder ranks 1st in speed and ties for 2nd in quality. A new generation of LLMs that push the frontier of fast, high-quality text generation.</p> <p>Extra: Powered by a server managed by @inceptionlabsai. Learn more</p>"},{"location":"models/Inception-Mercury.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Inception-Mercury.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 13 points / 1k tokens |</p> <p>| Initial Points Cost | 20+ points |</p> <p>| Bot Message (Text) | 50 points / 1k tokens |</p> <p>Last Checked: 2025-08-05 23:27:54.533447</p>"},{"location":"models/Inception-Mercury.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Inception-Mercury</code></p> <p>Object Type: model</p> <p>Created: 1750952818304</p> <p>Owned By: poe</p> <p>Root: Inception-Mercury</p>"},{"location":"models/Kimi-K2-T.html","title":"Kimi-K2-T","text":""},{"location":"models/Kimi-K2-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Kimi K2 is a state-of-the-art mixture-of-experts (MoE) language model with 32 billion activated parameters and 1 trillion total parameters. Trained with the Muon optimizer, Kimi K2 achieves exceptional performance across frontier knowledge, reasoning, and coding tasks while being meticulously optimized for agentic capabilities.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Kimi-K2-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Kimi-K2-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 360 points/message |</p> <p>| Initial Points Cost | 360 points |</p> <p>Last Checked: 2025-08-05 23:28:14.881761</p>"},{"location":"models/Kimi-K2-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Kimi-K2-T</code></p> <p>Object Type: model</p> <p>Created: 1752510412371</p> <p>Owned By: poe</p> <p>Root: Kimi-K2-T</p>"},{"location":"models/Kimi-K2.html","title":"Kimi-K2","text":""},{"location":"models/Kimi-K2.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: Kimi K2 is a state-of-the-art mixture-of-experts (MoE) language model with 32 billion activated parameters and 1 trillion total parameters. Trained with the Muon optimizer, Kimi K2 achieves exceptional performance across frontier knowledge, reasoning, and coding tasks while being meticulously optimized for agentic capabilities.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Kimi-K2.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Kimi-K2.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 200 points/message |</p> <p>| Initial Points Cost | 200 points |</p> <p>Last Checked: 2025-08-05 23:28:08.163105</p>"},{"location":"models/Kimi-K2.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Kimi-K2</code></p> <p>Object Type: model</p> <p>Created: 1752519798608</p> <p>Owned By: poe</p> <p>Root: Kimi-K2</p>"},{"location":"models/Kling-1.5-Pro.html","title":"Kling-1.5-Pro","text":""},{"location":"models/Kling-1.5-Pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Kling v1.5 video generation bot, hosted by fal.ai. For best results, upload an image attachment. Use <code>--aspect</code> to set the aspect ratio. Allowed values are <code>16:9</code>, <code>9:16</code> and <code>1:1</code>. Use <code>--duration</code> to set the duration of the generated video.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Kling-1.5-Pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Kling-1.5-Pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 2834 points / second |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:28:21.928770</p>"},{"location":"models/Kling-1.5-Pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Kling-1.5-Pro</code></p> <p>Object Type: model</p> <p>Created: 1733347438699</p> <p>Owned By: poe</p> <p>Root: Kling-1.5-Pro</p>"},{"location":"models/Kling-1.6-Pro.html","title":"Kling-1.6-Pro","text":""},{"location":"models/Kling-1.6-Pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Kling v1.6 video generation bot, hosted by fal.ai. For best results, upload an image attachment. Use <code>--aspect</code> to set the aspect ratio. Allowed values are <code>16:9</code>, <code>9:16</code> and <code>1:1</code>. Use <code>--duration</code> to set the duration of the generated video (5 or 10 seconds).</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Kling-1.6-Pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Kling-1.6-Pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 2834 points / second |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:28:29.183654</p>"},{"location":"models/Kling-1.6-Pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Kling-1.6-Pro</code></p> <p>Object Type: model</p> <p>Created: 1737537681579</p> <p>Owned By: poe</p> <p>Root: Kling-1.6-Pro</p>"},{"location":"models/Kling-2.0-Master.html","title":"Kling-2.0-Master","text":""},{"location":"models/Kling-2.0-Master.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Generate high-quality videos from text or images using Kling 2.0 Master. Use <code>--negative_prompt</code> to send a negative prompt, and <code>--cfg_scale</code> to send a classifier-free guidance scale between 0.0 and 1.0 (inclusive). Use <code>--aspect</code> to set the aspect ratio (One of <code>16:9</code>, <code>9:16</code> and <code>1:1</code>).</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Kling-2.0-Master.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image, video</p> <p>Modality: text-&gt;image,video</p>"},{"location":"models/Kling-2.0-Master.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 6000 points / second |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:28:35.934341</p>"},{"location":"models/Kling-2.0-Master.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Kling-2.0-Master</code></p> <p>Object Type: model</p> <p>Created: 1744698597290</p> <p>Owned By: poe</p> <p>Root: Kling-2.0-Master</p>"},{"location":"models/Kling-2.1-Master.html","title":"Kling-2.1-Master","text":""},{"location":"models/Kling-2.1-Master.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Kling 2.1 Master: The premium endpoint for Kling 2.1, designed for top-tier image-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision. Use <code>--negative_prompt</code> to send a negative prompt, and <code>--cfg_scale</code> to send a classifier-free guidance scale between 0.0 and 1.0 (inclusive). Use <code>--aspect</code> to set the aspect ratio (One of <code>16:9</code>, <code>9:16</code> and <code>1:1</code>). Use --duration to set either 5 second or 10 second video.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Kling-2.1-Master.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Kling-2.1-Master.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 6000 points / second |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:28:42.750959</p>"},{"location":"models/Kling-2.1-Master.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Kling-2.1-Master</code></p> <p>Object Type: model</p> <p>Created: 1748544153317</p> <p>Owned By: poe</p> <p>Root: Kling-2.1-Master</p>"},{"location":"models/Kling-2.1-Pro.html","title":"Kling-2.1-Pro","text":""},{"location":"models/Kling-2.1-Pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Kling 2.1 Pro is an advanced endpoint for the Kling 2.1 model, offering professional-grade videos with enhanced visual fidelity, precise camera movements, and dynamic motion control, perfect for cinematic storytelling. Use <code>--negative_prompt</code> to send a negative prompt, and <code>--cfg_scale</code> to send a classifier-free guidance scale between 0.0 and 1.0 (inclusive). Use <code>--aspect</code> to set the aspect ratio (One of <code>16:9</code>, <code>9:16</code> and <code>1:1</code>). Set video duration to one of <code>5</code> or <code>10</code> seconds with <code>--duration</code>.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Kling-2.1-Pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Kling-2.1-Pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 2834 points / second |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:28:49.713253</p>"},{"location":"models/Kling-2.1-Pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Kling-2.1-Pro</code></p> <p>Object Type: model</p> <p>Created: 1748544740987</p> <p>Owned By: poe</p> <p>Root: Kling-2.1-Pro</p>"},{"location":"models/Kling-2.1-Std.html","title":"Kling-2.1-Std","text":""},{"location":"models/Kling-2.1-Std.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Kling 2.1 Standard is a cost-efficient endpoint for the Kling 2.1 model, delivering high-quality image-to-video generation. Use <code>--negative_prompt</code> to send a negative prompt, and <code>--cfg_scale</code> to send a classifier-free guidance scale between 0.0 and 1.0 (inclusive). Use <code>--aspect</code> to set the aspect ratio (One of <code>16:9</code>, <code>9:16</code> and <code>1:1</code>). Set video duration to one of <code>5</code> or <code>10</code> seconds with <code>--duration</code>.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Kling-2.1-Std.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Kling-2.1-Std.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 1667 points / second |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:28:56.529083</p>"},{"location":"models/Kling-2.1-Std.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Kling-2.1-Std</code></p> <p>Object Type: model</p> <p>Created: 1748545509401</p> <p>Owned By: poe</p> <p>Root: Kling-2.1-Std</p>"},{"location":"models/Kling-Pro-Effects.html","title":"Kling-Pro-Effects","text":""},{"location":"models/Kling-Pro-Effects.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Generate videos with effects like squishing an object, two people hugging, making heart gestures, etc. using Kling-Pro-Effects. Requires an image input. Send a single image for <code>squish</code> and <code>expansion</code> effects and two images (of people) for <code>hug</code>, <code>kiss</code>, and <code>heart_gesture</code> effects. Set effect with --effect. Default effect: <code>squish</code>.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Kling-Pro-Effects.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Kling-Pro-Effects.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 3334 points / second |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:29:03.322016</p>"},{"location":"models/Kling-Pro-Effects.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Kling-Pro-Effects</code></p> <p>Object Type: model</p> <p>Created: 1743698583798</p> <p>Owned By: poe</p> <p>Root: Kling-Pro-Effects</p>"},{"location":"models/LivePortrait.html","title":"LivePortrait","text":""},{"location":"models/LivePortrait.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Animates given portraits with the motion's in the video. Powered by fal.ai</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/LivePortrait.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/LivePortrait.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 85 points / message |</p> <p>| Initial Points Cost | 85 points |</p> <p>Last Checked: 2025-08-05 23:29:10.359275</p>"},{"location":"models/LivePortrait.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>LivePortrait</code></p> <p>Object Type: model</p> <p>Created: 1720556185003</p> <p>Owned By: poe</p> <p>Root: LivePortrait</p>"},{"location":"models/Llama-3-70B-FP16.html","title":"Llama-3-70B-FP16","text":""},{"location":"models/Llama-3-70B-FP16.html#bot-information","title":"Bot Information","text":"<p>Creator: @hyperbolic</p> <p>Description: A highly efficient and powerful model designed for a veriety of tasks with 128K context length.</p> <p>Extra: Powered by a server managed by @hyperbolic. Learn more</p>"},{"location":"models/Llama-3-70B-FP16.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3-70B-FP16.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 200 points/message |</p> <p>| Initial Points Cost | 200 points |</p> <p>Last Checked: 2025-08-05 23:29:17.314299</p>"},{"location":"models/Llama-3-70B-FP16.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3-70B-FP16</code></p> <p>Object Type: model</p> <p>Created: 1724034563488</p> <p>Owned By: poe</p> <p>Root: Llama-3-70B-FP16</p>"},{"location":"models/Llama-3-70B-T.html","title":"Llama-3-70B-T","text":""},{"location":"models/Llama-3-70B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Llama 3 70B Instruct from Meta. For most use cases, https://poe.com/Llama-3.3-70B will perform better.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Llama-3-70B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3-70B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 75 points/message |</p> <p>| Initial Points Cost | 75 points |</p> <p>Last Checked: 2025-08-05 23:29:24.189769</p>"},{"location":"models/Llama-3-70B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3-70B-T</code></p> <p>Object Type: model</p> <p>Created: 1713463834064</p> <p>Owned By: poe</p> <p>Root: Llama-3-70B-T</p>"},{"location":"models/Llama-3-70b-Groq.html","title":"Llama-3-70b-Groq","text":""},{"location":"models/Llama-3-70b-Groq.html#bot-information","title":"Bot Information","text":"<p>Creator: @groq</p> <p>Description: Llama 3 70b powered by the Groq LPU\u2122 Inference Engine</p> <p>Extra: Powered by Groq. Learn more</p>"},{"location":"models/Llama-3-70b-Groq.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3-70b-Groq.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 75 points/message |</p> <p>| Initial Points Cost | 75 points |</p> <p>Last Checked: 2025-08-05 23:29:31.071131</p>"},{"location":"models/Llama-3-70b-Groq.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3-70b-Groq</code></p> <p>Object Type: model</p> <p>Created: 1713833546209</p> <p>Owned By: poe</p> <p>Root: Llama-3-70b-Groq</p>"},{"location":"models/Llama-3-70b-Inst-FW.html","title":"Llama-3-70b-Inst-FW","text":""},{"location":"models/Llama-3-70b-Inst-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: Meta's Llama-3-70B-Instruct hosted by Fireworks AI. For use cases, https://poe.com/Llama-3.3-70B-FW will be better.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Llama-3-70b-Inst-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3-70b-Inst-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 75 points/message |</p> <p>| Initial Points Cost | 75 points |</p> <p>Last Checked: 2025-08-05 23:29:37.905640</p>"},{"location":"models/Llama-3-70b-Inst-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3-70b-Inst-FW</code></p> <p>Object Type: model</p> <p>Created: 1713475738051</p> <p>Owned By: poe</p> <p>Root: Llama-3-70b-Inst-FW</p>"},{"location":"models/Llama-3-8B-T.html","title":"Llama-3-8B-T","text":""},{"location":"models/Llama-3-8B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Llama 3 8B Instruct from Meta.</p> <p>The points price is subject to change.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Llama-3-8B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3-8B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 15 points/message |</p> <p>| Initial Points Cost | 15 points |</p> <p>Last Checked: 2025-08-05 23:29:44.652580</p>"},{"location":"models/Llama-3-8B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3-8B-T</code></p> <p>Object Type: model</p> <p>Created: 1713463356287</p> <p>Owned By: poe</p> <p>Root: Llama-3-8B-T</p>"},{"location":"models/Llama-3-8b-Groq.html","title":"Llama-3-8b-Groq","text":""},{"location":"models/Llama-3-8b-Groq.html#bot-information","title":"Bot Information","text":"<p>Creator: @groq</p> <p>Description: Llama 3 8b powered by the Groq LPU\u2122 Inference Engine</p> <p>Extra: Powered by Groq. Learn more</p>"},{"location":"models/Llama-3-8b-Groq.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3-8b-Groq.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 10 points/message |</p> <p>| Initial Points Cost | 10 points |</p> <p>Last Checked: 2025-08-05 23:29:51.416038</p>"},{"location":"models/Llama-3-8b-Groq.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3-8b-Groq</code></p> <p>Object Type: model</p> <p>Created: 1704930986258</p> <p>Owned By: poe</p> <p>Root: Llama-3-8b-Groq</p>"},{"location":"models/Llama-3.1-405B-FP16.html","title":"Llama-3.1-405B-FP16","text":""},{"location":"models/Llama-3.1-405B-FP16.html#bot-information","title":"Bot Information","text":"<p>Creator: @hyperbolic</p> <p>Description: The Biggest and Best open-source AI model trained by Meta, beating GPT-4o across most benchmarks. This bot is in BF16 and with 128K context length.</p> <p>Extra: Powered by a server managed by @hyperbolic. Learn more</p>"},{"location":"models/Llama-3.1-405B-FP16.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-405B-FP16.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 2070 points/message |</p> <p>| Initial Points Cost | 2070 points |</p> <p>Last Checked: 2025-08-05 23:30:05.326261</p>"},{"location":"models/Llama-3.1-405B-FP16.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-405B-FP16</code></p> <p>Object Type: model</p> <p>Created: 1724034411290</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-405B-FP16</p>"},{"location":"models/Llama-3.1-405B-FW.html","title":"Llama-3.1-405B-FW","text":""},{"location":"models/Llama-3.1-405B-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models in 8B, 70B and 405B sizes. The Llama 3.1 instruction tuned text only models (8B, 70B, 405B) are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks. Supports 128k tokens.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Llama-3.1-405B-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-405B-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1500 points/message |</p> <p>| Initial Points Cost | 1500 points |</p> <p>Last Checked: 2025-08-05 23:30:12.076239</p>"},{"location":"models/Llama-3.1-405B-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-405B-FW</code></p> <p>Object Type: model</p> <p>Created: 1721749475784</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-405B-FW</p>"},{"location":"models/Llama-3.1-405B-T.html","title":"Llama-3.1-405B-T","text":""},{"location":"models/Llama-3.1-405B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Llama 3.1 405B Instruct from Meta. Supports 128k tokens of context.</p> <p>The points price is subject to change.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Llama-3.1-405B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-405B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 335 points/message |</p> <p>| Initial Points Cost | 335 points |</p> <p>Last Checked: 2025-08-05 23:30:19.351098</p>"},{"location":"models/Llama-3.1-405B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-405B-T</code></p> <p>Object Type: model</p> <p>Created: 1721748214074</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-405B-T</p>"},{"location":"models/Llama-3.1-405B.html","title":"Llama-3.1-405B","text":""},{"location":"models/Llama-3.1-405B.html#bot-information","title":"Bot Information","text":"<p>Creator: @meta</p> <p>Description: The pinnacle of Meta's Llama 3.1 family, this open-source language model excels in multilingual dialogue, outperforming numerous industry benchmarks for both closed and open-source conversational AI systems. For most tasks, https://poe.com/Llama-3.3-70B will perform similarly and may be more cost-effective. Serves the instruct-tuned version of Llama 3.1 405B, so is optimized for chat use cases.</p> <p>Extra: Powered by a server managed by @meta. Learn more</p>"},{"location":"models/Llama-3.1-405B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-405B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 100 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 39 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 62+ points |</p> <p>Last Checked: 2025-08-05 23:29:58.315106</p>"},{"location":"models/Llama-3.1-405B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-405B</code></p> <p>Object Type: model</p> <p>Created: 1723099000397</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-405B</p>"},{"location":"models/Llama-3.1-70B-FP16.html","title":"Llama-3.1-70B-FP16","text":""},{"location":"models/Llama-3.1-70B-FP16.html#bot-information","title":"Bot Information","text":"<p>Creator: @hyperbolic</p> <p>Description: The best LLM at its size with faster response times compared to the 405B model with 128K context length.</p> <p>Extra: Powered by a server managed by @hyperbolic. Learn more</p>"},{"location":"models/Llama-3.1-70B-FP16.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-70B-FP16.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 200 points/message |</p> <p>| Initial Points Cost | 200 points |</p> <p>Last Checked: 2025-08-05 23:30:34.324244</p>"},{"location":"models/Llama-3.1-70B-FP16.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-70B-FP16</code></p> <p>Object Type: model</p> <p>Created: 1724034470327</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-70B-FP16</p>"},{"location":"models/Llama-3.1-70B-FW.html","title":"Llama-3.1-70B-FW","text":""},{"location":"models/Llama-3.1-70B-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models in 8B, 70B and 405B sizes. The Llama 3.1 instruction tuned text only models (8B, 70B, 405B) are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks. Supports 128k tokens.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Llama-3.1-70B-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-70B-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 400 points/message |</p> <p>| Initial Points Cost | 400 points |</p> <p>Last Checked: 2025-08-05 23:30:41.237507</p>"},{"location":"models/Llama-3.1-70B-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-70B-FW</code></p> <p>Object Type: model</p> <p>Created: 1721749532051</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-70B-FW</p>"},{"location":"models/Llama-3.1-70B-T.html","title":"Llama-3.1-70B-T","text":""},{"location":"models/Llama-3.1-70B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Llama 3.1 70B Instruct from Meta. Supports 128k tokens of context.</p> <p>The points price is subject to change.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Llama-3.1-70B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-70B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 460 points/message |</p> <p>| Initial Points Cost | 460 points |</p> <p>Last Checked: 2025-08-05 23:30:47.975700</p>"},{"location":"models/Llama-3.1-70B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-70B-T</code></p> <p>Object Type: model</p> <p>Created: 1721748215163</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-70B-T</p>"},{"location":"models/Llama-3.1-70B.html","title":"Llama-3.1-70B","text":""},{"location":"models/Llama-3.1-70B.html#bot-information","title":"Bot Information","text":"<p>Creator: @meta</p> <p>Description: A medium-sized model from Meta's Llama 3.1 family which balances intelligence and speed. This open-source language model excels in multilingual dialogue, outperforming numerous industry benchmarks for both closed and open-source conversational AI systems. For most use cases, https://poe.com/Llama-3.3-70B will be better. Context window has been shortened to optimize for speed and cost.</p> <p>Extra: Powered by a server managed by @meta. Learn more</p>"},{"location":"models/Llama-3.1-70B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-70B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 30 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 8 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 15+ points |</p> <p>Last Checked: 2025-08-05 23:30:27.371374</p>"},{"location":"models/Llama-3.1-70B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-70B</code></p> <p>Object Type: model</p> <p>Created: 1723143011206</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-70B</p>"},{"location":"models/Llama-3.1-8B-DI.html","title":"Llama-3.1-8B-DI","text":""},{"location":"models/Llama-3.1-8B-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: The smallest and fastest model from Meta's Llama 3.1 family. This open-source language model excels in multilingual dialogue, outperforming numerous industry benchmarks for both closed and open-source conversational AI systems.  All data you submit to this bot is governed by the Poe privacy policy and is only sent to DeepInfra, a US-based company.</p> <p>Input token limit 128k, output token limit 8k. Quantization: FP16 (official).</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/Llama-3.1-8B-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-8B-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 0 points/message |</p> <p>| Initial Points Cost | 0 points |</p> <p>Last Checked: 2025-08-05 23:31:01.566403</p>"},{"location":"models/Llama-3.1-8B-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-8B-DI</code></p> <p>Object Type: model</p> <p>Created: 1740488781419</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-8B-DI</p>"},{"location":"models/Llama-3.1-8B-FP16.html","title":"Llama-3.1-8B-FP16","text":""},{"location":"models/Llama-3.1-8B-FP16.html#bot-information","title":"Bot Information","text":"<p>Creator: @hyperbolic</p> <p>Description: The smallest and fastest member of the Llama 3.1 family, offering exceptional efficiency and rapid response times with 128K context length.</p> <p>Extra: Powered by a server managed by @hyperbolic. Learn more</p>"},{"location":"models/Llama-3.1-8B-FP16.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-8B-FP16.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 50 points/message |</p> <p>| Initial Points Cost | 50 points |</p> <p>Last Checked: 2025-08-05 23:31:08.466479</p>"},{"location":"models/Llama-3.1-8B-FP16.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-8B-FP16</code></p> <p>Object Type: model</p> <p>Created: 1724034517400</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-8B-FP16</p>"},{"location":"models/Llama-3.1-8B-FW.html","title":"Llama-3.1-8B-FW","text":""},{"location":"models/Llama-3.1-8B-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models in 8B, 70B and 405B sizes. The Llama 3.1 instruction tuned text only models (8B, 70B, 405B) are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks. Supports up to 128k tokens.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Llama-3.1-8B-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-8B-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 50 points/message |</p> <p>| Initial Points Cost | 50 points |</p> <p>Last Checked: 2025-08-05 23:31:15.490392</p>"},{"location":"models/Llama-3.1-8B-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-8B-FW</code></p> <p>Object Type: model</p> <p>Created: 1721749569258</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-8B-FW</p>"},{"location":"models/Llama-3.1-8B-T-128k.html","title":"Llama-3.1-8B-T-128k","text":""},{"location":"models/Llama-3.1-8B-T-128k.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Llama 3.1 8B Instruct from Meta. Supports 128k tokens of context.</p> <p>The points price is subject to change.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Llama-3.1-8B-T-128k.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-8B-T-128k.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 100 points/message |</p> <p>| Initial Points Cost | 100 points |</p> <p>Last Checked: 2025-08-05 23:31:22.343319</p>"},{"location":"models/Llama-3.1-8B-T-128k.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-8B-T-128k</code></p> <p>Object Type: model</p> <p>Created: 1721748216574</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-8B-T-128k</p>"},{"location":"models/Llama-3.1-8B.html","title":"Llama-3.1-8B","text":""},{"location":"models/Llama-3.1-8B.html#bot-information","title":"Bot Information","text":"<p>Creator: @meta</p> <p>Description: The smallest and fastest model from Meta's Llama 3.1 family. This open-source language model excels in multilingual dialogue, outperforming numerous industry benchmarks for both closed and open-source conversational AI systems. Context window has been shortened to optimize for speed and cost. For longer context messages, please try Llama-3.1-70B-FW-128k or Llama-3.1-70B-T-128k. The compute points value is subject to change.</p> <p>Extra: Powered by a server managed by @meta. Learn more</p>"},{"location":"models/Llama-3.1-8B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-8B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 7 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 2 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 4+ points |</p> <p>Last Checked: 2025-08-05 23:30:54.570651</p>"},{"location":"models/Llama-3.1-8B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-8B</code></p> <p>Object Type: model</p> <p>Created: 1723143047872</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-8B</p>"},{"location":"models/Llama-3.1-Nemotron.html","title":"Llama-3.1-Nemotron","text":""},{"location":"models/Llama-3.1-Nemotron.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Llama 3.1 Nemotron 70B from Nvidia. Excels in understanding, following instructions, writing and performing coding tasks. Strong reasoning abilities.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Llama-3.1-Nemotron.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.1-Nemotron.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 200 points/message |</p> <p>| Initial Points Cost | 200 points |</p> <p>Last Checked: 2025-08-05 23:31:29.204173</p>"},{"location":"models/Llama-3.1-Nemotron.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.1-Nemotron</code></p> <p>Object Type: model</p> <p>Created: 1731442142151</p> <p>Owned By: poe</p> <p>Root: Llama-3.1-Nemotron</p>"},{"location":"models/Llama-3.3-70B-DI.html","title":"Llama-3.3-70B-DI","text":""},{"location":"models/Llama-3.3-70B-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: Llama 3.3 70B \u2013 with similar performance as Llama 3.1 405B while being faster and much smaller! Llama 3.3 70B is a new open source model that delivers leading performance and quality across text-based use cases such as synthetic data generation at a fraction of the inference cost, improving over Llama 3.1 70B. All data you provide this bot will not be used in training, and is sent only to DeepInfra, a US-based company.</p> <p>Supports 128k tokens of input context and 8k tokens of output context. Quantization: FP8 (for speed)</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/Llama-3.3-70B-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.3-70B-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 50 points/message |</p> <p>| Initial Points Cost | 50 points |</p> <p>Last Checked: 2025-08-05 23:31:43.098006</p>"},{"location":"models/Llama-3.3-70B-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.3-70B-DI</code></p> <p>Object Type: model</p> <p>Created: 1740489360582</p> <p>Owned By: poe</p> <p>Root: Llama-3.3-70B-DI</p>"},{"location":"models/Llama-3.3-70B-FW.html","title":"Llama-3.3-70B-FW","text":""},{"location":"models/Llama-3.3-70B-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: Meta's Llama 3.3 70B Instruct, hosted by Fireworks AI. Llama 3.3 70B is a new open source model that delivers leading performance and quality across text-based use cases such as synthetic data generation at a fraction of the inference cost, improving over Llama 3.1 70B.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Llama-3.3-70B-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.3-70B-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 140 points/message |</p> <p>| Initial Points Cost | 140 points |</p> <p>Last Checked: 2025-08-05 23:31:49.968636</p>"},{"location":"models/Llama-3.3-70B-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.3-70B-FW</code></p> <p>Object Type: model</p> <p>Created: 1733508651951</p> <p>Owned By: poe</p> <p>Root: Llama-3.3-70B-FW</p>"},{"location":"models/Llama-3.3-70B-Vers.html","title":"Llama-3.3-70B-Vers","text":""},{"location":"models/Llama-3.3-70B-Vers.html#bot-information","title":"Bot Information","text":"<p>Creator: @OpenSourceLab</p> <p>Description: Open-source model suitable for a wide range of tasks like coding, essay writing, grammar correction and world knowledge answers. It supports analysing images, PDFs, SVGs, XLSX, WEBP, HTML and many other file types.</p> <p>Extra: Powered by a server managed by @OpenSourceLab. Learn more</p>"},{"location":"models/Llama-3.3-70B-Vers.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.3-70B-Vers.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 7 points / 1k tokens |</p> <p>| Input Image | 10 points / image |</p> <p>| Initial Points Cost | 15+ points |</p> <p>| Output (Text) | 7 points / 1k tokens |</p> <p>| File Processing | 3 points / file |</p> <p>| Document Processing | 15 points / document |</p> <p>Last Checked: 2025-08-05 23:31:56.693649</p>"},{"location":"models/Llama-3.3-70B-Vers.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.3-70B-Vers</code></p> <p>Object Type: model</p> <p>Created: 1753869935065</p> <p>Owned By: poe</p> <p>Root: Llama-3.3-70B-Vers</p>"},{"location":"models/Llama-3.3-70B.html","title":"Llama-3.3-70B","text":""},{"location":"models/Llama-3.3-70B.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Llama 3.3 70B \u2013 with similar performance as Llama 3.1 405B while being faster and much smaller! Llama 3.3 70B is a new open source model that delivers leading performance and quality across text-based use cases such as synthetic data generation at a fraction of the inference cost, improving over Llama 3.1 70B.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Llama-3.3-70B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-3.3-70B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 130 points/message |</p> <p>| Initial Points Cost | 130 points |</p> <p>Last Checked: 2025-08-05 23:31:36.120662</p>"},{"location":"models/Llama-3.3-70B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-3.3-70B</code></p> <p>Object Type: model</p> <p>Created: 1733509126023</p> <p>Owned By: poe</p> <p>Root: Llama-3.3-70B</p>"},{"location":"models/Llama-4-Maverick-B10.html","title":"Llama-4-Maverick-B10","text":""},{"location":"models/Llama-4-Maverick-B10.html#bot-information","title":"Bot Information","text":"<p>Creator: @baseten</p> <p>Description: Llama 4 Maverick is a state-of-the-art multimodal model with support for 12 languages. This ultra-fast implementation by Baseten supports a 1M token context window, the largest on Poe.</p> <p>This model supports images and PDFs. For PDFs, please add --page_range x,y to restrict the model to that page range.</p> <p>Maverick is a versatile model, great for tasks from creative content generation to customer support and coding assistance. It has higher performance and cost-efficency than the Llama 3 series of models, GPT-4o, and Gemini 2.0 Flash across a broad range of benchmarks, achieving comparable results to DeepSeek V3 on reasoning and coding while being a fraction of its size.</p> <p>Extra: Powered by a server managed by @baseten. Learn more</p>"},{"location":"models/Llama-4-Maverick-B10.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-4-Maverick-B10.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 145 points/message |</p> <p>| Initial Points Cost | 145 points |</p> <p>Last Checked: 2025-08-05 23:32:10.172263</p>"},{"location":"models/Llama-4-Maverick-B10.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-4-Maverick-B10</code></p> <p>Object Type: model</p> <p>Created: 1743915107713</p> <p>Owned By: poe</p> <p>Root: Llama-4-Maverick-B10</p>"},{"location":"models/Llama-4-Maverick-T.html","title":"Llama-4-Maverick-T","text":""},{"location":"models/Llama-4-Maverick-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Llama 4 Maverick, state of the art long-context multimodal model from Meta. A 128-expert MoE powerhouse for multilingual image/text understanding (12 languages), creative writing, and enterprise-scale applications\u2014outperforming Llama 3.3 70B. Supports 500k tokens context.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Llama-4-Maverick-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-4-Maverick-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 55 points/message |</p> <p>| Initial Points Cost | 55 points |</p> <p>Last Checked: 2025-08-05 23:32:17.076272</p>"},{"location":"models/Llama-4-Maverick-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-4-Maverick-T</code></p> <p>Object Type: model</p> <p>Created: 1743883014548</p> <p>Owned By: poe</p> <p>Root: Llama-4-Maverick-T</p>"},{"location":"models/Llama-4-Maverick.html","title":"Llama-4-Maverick","text":""},{"location":"models/Llama-4-Maverick.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: Llama 4 Maverick delivers SOTA intelligence and blazing-fast performance across languages, optimized for speed and quality in real-world applications. Supports 1.05M tokens of input context.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Llama-4-Maverick.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-4-Maverick.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 50 points/message |</p> <p>| Initial Points Cost | 50 points |</p> <p>Last Checked: 2025-08-05 23:32:03.409144</p>"},{"location":"models/Llama-4-Maverick.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-4-Maverick</code></p> <p>Object Type: model</p> <p>Created: 1743882925518</p> <p>Owned By: poe</p> <p>Root: Llama-4-Maverick</p>"},{"location":"models/Llama-4-Scout-B10.html","title":"Llama-4-Scout-B10","text":""},{"location":"models/Llama-4-Scout-B10.html#bot-information","title":"Bot Information","text":"<p>Creator: @baseten</p> <p>Description: Llama 4 Scout is the leading multimodal model in the world. This ultra-fast implementation by Baseten also supports an 8M token context window, the largest on Poe.</p> <p>This model supports images and PDFs. For PDFs, please add --page_range x,y to restrict the model to that page range.</p> <p>Scout is perfect for tasks requiring a lot of context, from summarizing large documents to reasoning over massive code bases. It outperforms Gemma 3, Gemini 2.0 Flash-Lite, and Mistral 3.1 across a broad range of benchmarks while fitting in a single NVIDIA H100 GPU.</p> <p>Extra: Powered by a server managed by @baseten. Learn more</p>"},{"location":"models/Llama-4-Scout-B10.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-4-Scout-B10.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 100 points/message |</p> <p>| Initial Points Cost | 100 points |</p> <p>Last Checked: 2025-08-05 23:32:30.529482</p>"},{"location":"models/Llama-4-Scout-B10.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-4-Scout-B10</code></p> <p>Object Type: model</p> <p>Created: 1743896554195</p> <p>Owned By: poe</p> <p>Root: Llama-4-Scout-B10</p>"},{"location":"models/Llama-4-Scout-T.html","title":"Llama-4-Scout-T","text":""},{"location":"models/Llama-4-Scout-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Llama 4 Scout, fast long-context multimodal model from Meta. A 16-expert MoE model that excels at multi-document analysis, codebase reasoning, and personalized tasks. A smaller model than Maverick but state of the art in its size &amp; with text + image input support. Supports 300k context.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Llama-4-Scout-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-4-Scout-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 35 points/message |</p> <p>| Initial Points Cost | 35 points |</p> <p>Last Checked: 2025-08-05 23:32:37.263865</p>"},{"location":"models/Llama-4-Scout-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-4-Scout-T</code></p> <p>Object Type: model</p> <p>Created: 1743891662563</p> <p>Owned By: poe</p> <p>Root: Llama-4-Scout-T</p>"},{"location":"models/Llama-4-Scout-nitro.html","title":"Llama-4-Scout-nitro","text":""},{"location":"models/Llama-4-Scout-nitro.html#bot-information","title":"Bot Information","text":"<p>Creator: @cerebrasai</p> <p>Description: World\u2019s fastest inference for Llama 4 Scout with Cerebras.</p> <p>Extra: Powered by a server managed by @cerebrasai. Learn more</p>"},{"location":"models/Llama-4-Scout-nitro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-4-Scout-nitro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 350 points/message |</p> <p>| Initial Points Cost | 350 points |</p> <p>Last Checked: 2025-08-05 23:32:44.113342</p>"},{"location":"models/Llama-4-Scout-nitro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-4-Scout-nitro</code></p> <p>Object Type: model</p> <p>Created: 1747179494349</p> <p>Owned By: poe</p> <p>Root: Llama-4-Scout-nitro</p>"},{"location":"models/Llama-4-Scout.html","title":"Llama-4-Scout","text":""},{"location":"models/Llama-4-Scout.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: Llama 4 Scout is a versatile, general-purpose LLM with multi-modal capabilities\u2014ideal for tasks like multi-document summarization. Supports 131k tokens of input context.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Llama-4-Scout.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Llama-4-Scout.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 30 points/message |</p> <p>| Initial Points Cost | 30 points |</p> <p>Last Checked: 2025-08-05 23:32:23.732519</p>"},{"location":"models/Llama-4-Scout.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Llama-4-Scout</code></p> <p>Object Type: model</p> <p>Created: 1743882853643</p> <p>Owned By: poe</p> <p>Root: Llama-4-Scout</p>"},{"location":"models/Luma-Photon-Flash.html","title":"Luma-Photon-Flash","text":""},{"location":"models/Luma-Photon-Flash.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Luma Photon delivers industry-specific visual excellence, crafting images that align perfectly with professional standards - not just generic AI art. From marketing to creative design, each generation is purposefully tailored to your industry's unique requirements. Add --aspect to the end of your prompts to change the aspect ratio of your generations (1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21 are supported).</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Luma-Photon-Flash.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Luma-Photon-Flash.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 167 points / message |</p> <p>| Initial Points Cost | 167 points |</p> <p>Last Checked: 2025-08-05 23:32:57.794151</p>"},{"location":"models/Luma-Photon-Flash.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Luma-Photon-Flash</code></p> <p>Object Type: model</p> <p>Created: 1733181412355</p> <p>Owned By: poe</p> <p>Root: Luma-Photon-Flash</p>"},{"location":"models/Luma-Photon.html","title":"Luma-Photon","text":""},{"location":"models/Luma-Photon.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Luma Photon delivers industry-specific visual excellence, crafting images that align perfectly with professional standards - not just generic AI art. From marketing to creative design, each generation is purposefully tailored to your industry's unique requirements. Add --aspect to the end of your prompts to change the aspect ratio of your generations (1:1, 16:9, 9:16, 4:3, 3:4, 21:9, 9:21 are supported).</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Luma-Photon.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Luma-Photon.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 634 points / message |</p> <p>| Initial Points Cost | 634 points |</p> <p>Last Checked: 2025-08-05 23:32:50.996305</p>"},{"location":"models/Luma-Photon.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Luma-Photon</code></p> <p>Object Type: model</p> <p>Created: 1733181326256</p> <p>Owned By: poe</p> <p>Root: Luma-Photon</p>"},{"location":"models/Lyria.html","title":"Lyria","text":""},{"location":"models/Lyria.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Google DeepMind's Lyria 2 delivers high-quality audio generation, capable of creating diverse soundscapes and musical pieces from text prompts.</p> <p>Allows users to specify elements to exclude in the audio using the \"--no\" parameter at the end of the prompt. Also supports \"--seed\" for deterministic generation. e.g. \"An energetic electronic dance track --no vocals, slow tempo --seed 123\". Lyria blocks prompts that name specific artists or songs (artist-intent and recitation checks). This bot does not support attachments.</p> <p>Extra: Powered by a server managed by @google. Learn more</p>"},{"location":"models/Lyria.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Lyria.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 2000 points per generated song |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:33:04.616564</p>"},{"location":"models/Lyria.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Lyria</code></p> <p>Object Type: model</p> <p>Created: 1749063911995</p> <p>Owned By: poe</p> <p>Root: Lyria</p>"},{"location":"models/MarkItDown.html","title":"MarkItDown","text":""},{"location":"models/MarkItDown.html#bot-information","title":"Bot Information","text":"<p>Creator: @opentools</p> <p>Description: Convert anything to Markdown: URLs, PDFs, Word, Excel, PowerPoint, images (EXIF metadata), audio (EXIF metadata and transcription), and more. This bot wraps Microsoft\u2019s MarkItDown MCP server (https://github.com/microsoft/markitdown).</p> <p>Extra: Powered by a server managed by @opentools. Learn more</p>"},{"location":"models/MarkItDown.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/MarkItDown.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Markdown Conversion | 100 per Markdown conversion |</p> <p>Last Checked: 2025-08-05 23:33:11.349106</p>"},{"location":"models/MarkItDown.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>MarkItDown</code></p> <p>Object Type: model</p> <p>Created: 1746488364378</p> <p>Owned By: poe</p> <p>Root: MarkItDown</p>"},{"location":"models/MiniMax-M1.html","title":"MiniMax-M1","text":""},{"location":"models/MiniMax-M1.html#bot-information","title":"Bot Information","text":"<p>Creator: @MiniMax</p> <p>Description: MiniMax's open-weight M1 reasoning model supports 1M context window, making it ideal for long-context retrieval, summarization or problem-solving tasks. Maintains strong memory in extended, multi-turn conversations. This is a pure text reasoning model and currently does not process any file types</p> <p>Extra: Powered by a server managed by @MiniMax. Learn more</p>"},{"location":"models/MiniMax-M1.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/MiniMax-M1.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | 100+ |</p> <p>| Input (\u2264200K Tokens) | 20 credits / 1000 tokens |</p> <p>| Input (&gt;200K Tokens) | 65 credits / 1000 tokens |</p> <p>| Output | 110 credits / 1000 tokens |</p> <p>Last Checked: 2025-08-05 23:33:18.629743</p>"},{"location":"models/MiniMax-M1.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>MiniMax-M1</code></p> <p>Object Type: model</p> <p>Created: 1749637524703</p> <p>Owned By: poe</p> <p>Root: MiniMax-M1</p>"},{"location":"models/Mistral-7B-v0.3-DI.html","title":"Mistral-7B-v0.3-DI","text":""},{"location":"models/Mistral-7B-v0.3-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: Mistral Instruct 7B v0.3 from Mistral AI.</p> <p>All data you provide this bot will not be used in training, and is sent only to DeepInfra, a US-based company.</p> <p>Supports 32k tokens of input context and 8k tokens of output context. Quantization: FP16 (official).</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/Mistral-7B-v0.3-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Mistral-7B-v0.3-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 5 points/message |</p> <p>| Initial Points Cost | 5 points |</p> <p>Last Checked: 2025-08-05 23:33:25.938299</p>"},{"location":"models/Mistral-7B-v0.3-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Mistral-7B-v0.3-DI</code></p> <p>Object Type: model</p> <p>Created: 1740490886743</p> <p>Owned By: poe</p> <p>Root: Mistral-7B-v0.3-DI</p>"},{"location":"models/Mistral-7B-v0.3-T.html","title":"Mistral-7B-v0.3-T","text":""},{"location":"models/Mistral-7B-v0.3-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Mistral Instruct 7B v0.3 from Mistral AI.</p> <p>The points price is subject to change.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Mistral-7B-v0.3-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Mistral-7B-v0.3-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 45 points/message |</p> <p>| Initial Points Cost | 45 points |</p> <p>Last Checked: 2025-08-05 23:33:33.000566</p>"},{"location":"models/Mistral-7B-v0.3-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Mistral-7B-v0.3-T</code></p> <p>Object Type: model</p> <p>Created: 1716798156279</p> <p>Owned By: poe</p> <p>Root: Mistral-7B-v0.3-T</p>"},{"location":"models/Mistral-Large-2.html","title":"Mistral-Large-2","text":""},{"location":"models/Mistral-Large-2.html#bot-information","title":"Bot Information","text":"<p>Creator: @mistral</p> <p>Description: Mistral's latest text generation model (Mistral-Large-2407) with top-tier reasoning capabilities. It can be used for complex multilingual reasoning tasks, including text understanding, transformation, and code generation. This bot has the full 128k context window supported by the model.</p> <p>Extra: Powered by Mistral. Learn more</p>"},{"location":"models/Mistral-Large-2.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Mistral-Large-2.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 100 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 241 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 264+ points |</p> <p>Last Checked: 2025-08-05 23:33:39.901647</p>"},{"location":"models/Mistral-Large-2.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Mistral-Large-2</code></p> <p>Object Type: model</p> <p>Created: 1708971504266</p> <p>Owned By: poe</p> <p>Root: Mistral-Large-2</p>"},{"location":"models/Mistral-Medium.html","title":"Mistral-Medium","text":""},{"location":"models/Mistral-Medium.html#bot-information","title":"Bot Information","text":"<p>Creator: @mistral</p> <p>Description: Mistral AI's medium-sized model. Supports a context window of 32k tokens (around 24,000 words) and is stronger than Mixtral-8x7b and Mistral-7b on benchmarks across the board.</p> <p>Extra: Powered by Mistral. Learn more</p>"},{"location":"models/Mistral-Medium.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Mistral-Medium.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 90 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 227 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 248+ points |</p> <p>Last Checked: 2025-08-05 23:33:46.719356</p>"},{"location":"models/Mistral-Medium.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Mistral-Medium</code></p> <p>Object Type: model</p> <p>Created: 1703096777397</p> <p>Owned By: poe</p> <p>Root: Mistral-Medium</p>"},{"location":"models/Mistral-NeMo.html","title":"Mistral-NeMo","text":""},{"location":"models/Mistral-NeMo.html#bot-information","title":"Bot Information","text":"<p>Creator: @OpenSourceLab</p> <p>Description: Mistral and NVIDIA collaborated to create a multimodal, open source model. It can translate, analyse text files (.pdf, .md, .csv, .xlsx), images (.jpg, .png, .gif) and code (.json, .css, .js, .py, .xml, .html). The 12B parameter language model is also designed for extensive multilingual support. The server bot facilitates communication across diverse linguistic landscapes.</p> <p>The supported languages include, but are not limited to, widely spoken languages such as English, French, German, Spanish, Italian and Portuguese. The model also supports Chinese, Japanese, Korean, Arabic, and Hindi. This broad language coverage makes the model a versatile tool for international applications.</p> <p>Extra: Powered by a server managed by @OpenSourceLab. Learn more</p>"},{"location":"models/Mistral-NeMo.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Mistral-NeMo.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | 25+ |</p> <p>| Base Request Fee | 50 |</p> <p>| Input Processing | 2 per token |</p> <p>| Output Generation | 4 per token |</p> <p>Last Checked: 2025-08-05 23:33:53.622131</p>"},{"location":"models/Mistral-NeMo.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Mistral-NeMo</code></p> <p>Object Type: model</p> <p>Created: 1747480582228</p> <p>Owned By: poe</p> <p>Root: Mistral-NeMo</p>"},{"location":"models/Mistral-Small-3.1.html","title":"Mistral-Small-3.1","text":""},{"location":"models/Mistral-Small-3.1.html#bot-information","title":"Bot Information","text":"<p>Creator: @empiriolabsai</p> <p>Description: Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small 3 (2501), featuring 24 billion parameters with advanced multimodal capabilities. It provides state-of-the-art performance in text-based reasoning and vision tasks, including image analysis, programming, mathematical reasoning, and multilingual support across dozens of languages. Equipped with an extensive 128k token context window and optimized for efficient local inference, it supports use cases such as conversational agents, function calling, long-document comprehension, and privacy-sensitive deployments.</p> <p>Extra: Powered by a server managed by @empiriolabsai. Learn more</p>"},{"location":"models/Mistral-Small-3.1.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Mistral-Small-3.1.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Per Message | 64 points |</p> <p>| Initial Points Cost | 64 points |</p> <p>Last Checked: 2025-08-05 23:34:07.637659</p>"},{"location":"models/Mistral-Small-3.1.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Mistral-Small-3.1</code></p> <p>Object Type: model</p> <p>Created: 1742338142315</p> <p>Owned By: poe</p> <p>Root: Mistral-Small-3.1</p>"},{"location":"models/Mistral-Small-3.2.html","title":"Mistral-Small-3.2","text":""},{"location":"models/Mistral-Small-3.2.html#bot-information","title":"Bot Information","text":"<p>Creator: @OpenSourceLab</p> <p>Description: Mistral-Small-3.2 is a lightweight open-source language model designed for natural language tasks while being efficient enough to run on modest hardware. Mistral's mission is to democratize artificial intelligence through open source and open science.</p> <p>Despite its small size, it offers reliable performance across multilingual tasks, programming help, file understanding, and general-purpose reasoning. Perfect for developers, students, analysts, and tech enthusiasts looking for an open, responsive, low-cost AI.</p> <p>Supported File Types - Text &amp; Data: .txt, .md, .csv, .json, .html - Code: .js, .css, .py, .java, .sh, .ts, .c, .cpp, .go, .rb - Images (via plugins or extensions): .jpg, .png, .svg - File size: up to 10MB per file depending on platform setup</p> <p>Extra: Powered by a server managed by @OpenSourceLab. Learn more</p>"},{"location":"models/Mistral-Small-3.2.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Mistral-Small-3.2.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | 50+ points |</p> <p>| Base Request Fee | 50 |</p> <p>| Input Processing | 2 per token |</p> <p>| Output Generation | 4 per token |</p> <p>Last Checked: 2025-08-05 23:34:14.300020</p>"},{"location":"models/Mistral-Small-3.2.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Mistral-Small-3.2</code></p> <p>Object Type: model</p> <p>Created: 1753262625533</p> <p>Owned By: poe</p> <p>Root: Mistral-Small-3.2</p>"},{"location":"models/Mistral-Small-3.html","title":"Mistral-Small-3","text":""},{"location":"models/Mistral-Small-3.html#bot-information","title":"Bot Information","text":"<p>Creator: @mistral</p> <p>Description: Mistral Small 3 is a pre-trained and instructed model catered to the \u201880%\u2019 of generative AI tasks--those that require robust language and instruction following performance, with very low latency. Released under an Apache 2.0 license and comparable to Llama-3.3-70B and Qwen2.5-32B-Instruct.</p> <p>Extra: Powered by Mistral. Learn more</p>"},{"location":"models/Mistral-Small-3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Mistral-Small-3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 4 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 6 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 7+ points |</p> <p>Last Checked: 2025-08-05 23:34:00.718416</p>"},{"location":"models/Mistral-Small-3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Mistral-Small-3</code></p> <p>Object Type: model</p> <p>Created: 1738360161146</p> <p>Owned By: poe</p> <p>Root: Mistral-Small-3</p>"},{"location":"models/Mixtral8x22b-Inst-FW.html","title":"Mixtral8x22b-Inst-FW","text":""},{"location":"models/Mixtral8x22b-Inst-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: Mixtral 8x22B Mixture-of-Experts instruct model from Mistral hosted by Fireworks.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Mixtral8x22b-Inst-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Mixtral8x22b-Inst-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 120 points/message |</p> <p>| Initial Points Cost | 120 points |</p> <p>Last Checked: 2025-08-05 23:34:21.000610</p>"},{"location":"models/Mixtral8x22b-Inst-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Mixtral8x22b-Inst-FW</code></p> <p>Object Type: model</p> <p>Created: 1712949013942</p> <p>Owned By: poe</p> <p>Root: Mixtral8x22b-Inst-FW</p>"},{"location":"models/Mochi-preview.html","title":"Mochi-preview","text":""},{"location":"models/Mochi-preview.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Open state-of-the-art video generation model with high-fidelity motion and strong prompt adherence. Supports both text-to-video and image-to-video.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Mochi-preview.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Mochi-preview.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 11334 points / message |</p> <p>| Initial Points Cost | 11334 points |</p> <p>Last Checked: 2025-08-05 23:34:27.761025</p>"},{"location":"models/Mochi-preview.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Mochi-preview</code></p> <p>Object Type: model</p> <p>Created: 1729817676311</p> <p>Owned By: poe</p> <p>Root: Mochi-preview</p>"},{"location":"models/OpenAI-GPT-OSS-120B.html","title":"OpenAI-GPT-OSS-120B","text":""},{"location":"models/OpenAI-GPT-OSS-120B.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: GPT-OSS-120b is a high-performance, open-weight language model designed for production-grade, general-purpose use cases. It fits on a single H100 GPU, making it accessible without requiring multi-GPU infrastructure. Trained on the Harmony response format, it excels at complex reasoning and supports configurable reasoning effort, full chain-of-thought transparency for easier debugging and trust, and native agentic capabilities for function calling, tool use, and structured outputs.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/OpenAI-GPT-OSS-120B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/OpenAI-GPT-OSS-120B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 50 points/message |</p> <p>| Initial Points Cost | 50 points |</p> <p>Last Checked: 2025-08-05 23:34:34.624297</p>"},{"location":"models/OpenAI-GPT-OSS-120B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>OpenAI-GPT-OSS-120B</code></p> <p>Object Type: model</p> <p>Created: 1754416223840</p> <p>Owned By: poe</p> <p>Root: OpenAI-GPT-OSS-120B</p>"},{"location":"models/OpenAI-GPT-OSS-20B.html","title":"OpenAI-GPT-OSS-20B","text":""},{"location":"models/OpenAI-GPT-OSS-20B.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: GPT-OSS-20b is a compact, open-weight language model optimized for low-latency and resource-constrained environments, including local and edge deployments. It shares the same Harmony training foundation and capabilities as 120B, with faster inference and easier deployment that is ideal for specialized or offline use cases, fast responsive performance, chain-of-thought output and adjustable reasoning levels, and agentic workflows.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/OpenAI-GPT-OSS-20B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/OpenAI-GPT-OSS-20B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 25 points/message |</p> <p>| Initial Points Cost | 25 points |</p> <p>Last Checked: 2025-08-05 23:34:41.269870</p>"},{"location":"models/OpenAI-GPT-OSS-20B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>OpenAI-GPT-OSS-20B</code></p> <p>Object Type: model</p> <p>Created: 1754418551040</p> <p>Owned By: poe</p> <p>Root: OpenAI-GPT-OSS-20B</p>"},{"location":"models/Orpheus-TTS.html","title":"Orpheus-TTS","text":""},{"location":"models/Orpheus-TTS.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Orpheus TTS is a state-of-the-art, Llama-based Speech-LLM designed for high-quality, empathetic text-to-speech generation. Send a text prompt to voice it. Use --voice to choose from one of the available voices (<code>tara</code>, <code>leah</code>, <code>jess</code>, <code>leo</code>, <code>dan</code>,<code>mia</code>, <code>zac</code>, <code>zoe</code>). Officially supported sound effects are: , , , , , , , , and . <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Orpheus-TTS.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: audio</p> <p>Modality: text-&gt;audio</p>"},{"location":"models/Orpheus-TTS.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| Audio Output | 1667 points / 1000 character |</p> <p>Last Checked: 2025-08-05 23:34:47.967523</p>"},{"location":"models/Orpheus-TTS.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Orpheus-TTS</code></p> <p>Object Type: model</p> <p>Created: 1743698312235</p> <p>Owned By: poe</p> <p>Root: Orpheus-TTS</p>"},{"location":"models/Perplexity-Deep-Research.html","title":"Perplexity-Deep-Research","text":""},{"location":"models/Perplexity-Deep-Research.html#bot-information","title":"Bot Information","text":"<p>Creator: @empiriolabsai</p> <p>Description: Sonar Deep Research is a research-focused model designed for multi-step retrieval, synthesis, and reasoning across complex topics. It autonomously searches, reads, and evaluates sources, refining its approach as it gathers information. This enables comprehensive report generation across domains like finance, technology, health, and current events. Context Length: 128k</p> <p>Extra: Powered by a server managed by @empiriolabsai. Learn more</p>"},{"location":"models/Perplexity-Deep-Research.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Perplexity-Deep-Research.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Per Message | 15167 points |</p> <p>| Initial Points Cost | 15167 points |</p> <p>Last Checked: 2025-08-05 23:34:54.669430</p>"},{"location":"models/Perplexity-Deep-Research.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Perplexity-Deep-Research</code></p> <p>Object Type: model</p> <p>Created: 1740542141787</p> <p>Owned By: poe</p> <p>Root: Perplexity-Deep-Research</p>"},{"location":"models/Perplexity-R1-1776.html","title":"Perplexity-R1-1776","text":""},{"location":"models/Perplexity-R1-1776.html#bot-information","title":"Bot Information","text":"<p>Creator: @empiriolabsai</p> <p>Description: This model does not search the web. R1 1776 is a DeepSeek-R1 reasoning model that has been post-trained by Perplexity AI to remove Chinese Communist Party censorship. The model provides unbiased, accurate, and factual information while maintaining high reasoning capabilities. Context Length: 128k</p> <p>Extra: Powered by a server managed by @empiriolabsai. Learn more</p>"},{"location":"models/Perplexity-R1-1776.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Perplexity-R1-1776.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Per Message | 580 points |</p> <p>| Initial Points Cost | 580 points |</p> <p>Last Checked: 2025-08-05 23:35:01.771024</p>"},{"location":"models/Perplexity-R1-1776.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Perplexity-R1-1776</code></p> <p>Object Type: model</p> <p>Created: 1742157434003</p> <p>Owned By: poe</p> <p>Root: Perplexity-R1-1776</p>"},{"location":"models/Perplexity-Sonar-Pro.html","title":"Perplexity-Sonar-Pro","text":""},{"location":"models/Perplexity-Sonar-Pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @empiriolabsai</p> <p>Description: Sonar Pro by Perplexity is an advanced AI model that enhances real-time, web-connected search capabilities with double the citations and a larger context window. It's designed for complex queries, providing in-depth, nuanced answers and extended extensibility, making it ideal for enterprises and developers needing robust search solutions. Context Length: 200k (max output token limit of 8k)</p> <p>Extra: Powered by a server managed by @empiriolabsai. Learn more</p>"},{"location":"models/Perplexity-Sonar-Pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Perplexity-Sonar-Pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Per Message | 1667 points |</p> <p>| Initial Points Cost | 1667 points |</p> <p>Last Checked: 2025-08-05 23:35:15.241202</p>"},{"location":"models/Perplexity-Sonar-Pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Perplexity-Sonar-Pro</code></p> <p>Object Type: model</p> <p>Created: 1737790959209</p> <p>Owned By: poe</p> <p>Root: Perplexity-Sonar-Pro</p>"},{"location":"models/Perplexity-Sonar-Rsn-Pro.html","title":"Perplexity-Sonar-Rsn-Pro","text":""},{"location":"models/Perplexity-Sonar-Rsn-Pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @empiriolabsai</p> <p>Description: This model operates on the open-sourced uncensored R1-1776 model from Perplexity with web search capabilities. The Sonar Pro Reasoning Model takes AI-powered answers to the next level, offering unmatched quality and precision. Outperforming leading search engines and LLMs, Sonar Pro has demonstrated superior performance in the SimpleQA benchmark, making it the gold standard for high-quality answer generation. Context Length: 128k (max output token limit of 8k)</p> <p>Extra: Powered by a server managed by @empiriolabsai. Learn more</p>"},{"location":"models/Perplexity-Sonar-Rsn-Pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Perplexity-Sonar-Rsn-Pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Per Message | 2967 points |</p> <p>| Initial Points Cost | 2967 points |</p> <p>Last Checked: 2025-08-05 23:35:29.954636</p>"},{"location":"models/Perplexity-Sonar-Rsn-Pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Perplexity-Sonar-Rsn-Pro</code></p> <p>Object Type: model</p> <p>Created: 1739997380566</p> <p>Owned By: poe</p> <p>Root: Perplexity-Sonar-Rsn-Pro</p>"},{"location":"models/Perplexity-Sonar-Rsn.html","title":"Perplexity-Sonar-Rsn","text":""},{"location":"models/Perplexity-Sonar-Rsn.html#bot-information","title":"Bot Information","text":"<p>Creator: @empiriolabsai</p> <p>Description: This model operates on the open-sourced uncensored R1-1776 model from Perplexity with web search capabilities. The Sonar Reasoning Model is a cutting-edge AI answer engine designed to deliver fast, accurate, and reliable responses. Context Length: 128k</p> <p>Extra: Powered by a server managed by @empiriolabsai. Learn more</p>"},{"location":"models/Perplexity-Sonar-Rsn.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Perplexity-Sonar-Rsn.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Per Message | 1234 points |</p> <p>| Initial Points Cost | 1234 points |</p> <p>Last Checked: 2025-08-05 23:35:21.931176</p>"},{"location":"models/Perplexity-Sonar-Rsn.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Perplexity-Sonar-Rsn</code></p> <p>Object Type: model</p> <p>Created: 1739996703995</p> <p>Owned By: poe</p> <p>Root: Perplexity-Sonar-Rsn</p>"},{"location":"models/Perplexity-Sonar.html","title":"Perplexity-Sonar","text":""},{"location":"models/Perplexity-Sonar.html#bot-information","title":"Bot Information","text":"<p>Creator: @empiriolabsai</p> <p>Description: Sonar by Perplexity is a cutting-edge AI model that delivers real-time, web-connected search results with accurate citations. It's designed to provide up-to-date information and customizable search sources, making it a powerful tool for integrating AI search into various applications. Context Length: 127k</p> <p>Extra: Powered by a server managed by @empiriolabsai. Learn more</p>"},{"location":"models/Perplexity-Sonar.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Perplexity-Sonar.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Per Message | 434 points |</p> <p>| Initial Points Cost | 434 points |</p> <p>Last Checked: 2025-08-05 23:35:08.632041</p>"},{"location":"models/Perplexity-Sonar.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Perplexity-Sonar</code></p> <p>Object Type: model</p> <p>Created: 1737790362317</p> <p>Owned By: poe</p> <p>Root: Perplexity-Sonar</p>"},{"location":"models/Phi-4-DI.html","title":"Phi-4-DI","text":""},{"location":"models/Phi-4-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: Microsoft Research Phi-4 is designed to perform well in complex reasoning tasks and can operate efficiently in situations with limited memory or where quick responses are needed.</p> <p>At 14 billion parameters, it was trained on a mix of high-quality synthetic datasets, data from curated websites, and academic materials. It has undergone careful improvement to follow instructions accurately and maintain strong safety standards. It works best with English language inputs.</p> <p>All data you provide this bot will not be used in training, and is sent only to DeepInfra, a US-based company.</p> <p>Supports 16k tokens of input context and 8k tokens of output context. Quantization: FP16 (official).</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/Phi-4-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Phi-4-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 10 points/message |</p> <p>| Initial Points Cost | 10 points |</p> <p>Last Checked: 2025-08-05 23:35:36.883529</p>"},{"location":"models/Phi-4-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Phi-4-DI</code></p> <p>Object Type: model</p> <p>Created: 1740490334949</p> <p>Owned By: poe</p> <p>Root: Phi-4-DI</p>"},{"location":"models/Phoenix-1.0.html","title":"Phoenix-1.0","text":""},{"location":"models/Phoenix-1.0.html#bot-information","title":"Bot Information","text":"<p>Creator: @leonardoai</p> <p>Description: High-fidelity image generation with strong prompt adherence, especially for long and detailed instructions. Phoenix is capable of rendering coherent text in a wide variety of contexts. Prompt enhance is on to see the full power of a long, detailed prompt, but it can be turned off for full control. Uses the Phoenix 1.0 Fast model for performant, high-quality generations.</p> <p>Parameters: - Aspect Ratio (1:1, 3:2, 2:3, 9:16, 16:9) - Prompt Enhance (Enable the prompt for better image generation) - Style (Please see parameter control to identify available styles)</p> <p>Image generation prompts can be a maximum of 1500 characters.</p> <p>Extra: Powered by a server managed by @leonardoai. Learn more</p>"},{"location":"models/Phoenix-1.0.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Phoenix-1.0.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 560 points/message |</p> <p>| Initial Points Cost | 560 points |</p> <p>Last Checked: 2025-08-05 23:35:43.785165</p>"},{"location":"models/Phoenix-1.0.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Phoenix-1.0</code></p> <p>Object Type: model</p> <p>Created: 1748565176146</p> <p>Owned By: poe</p> <p>Root: Phoenix-1.0</p>"},{"location":"models/Pika.html","title":"Pika","text":""},{"location":"models/Pika.html#bot-information","title":"Bot Information","text":"<p>Creator: @pikalabs</p> <p>Description: Pika's video generation models. Select between Turbo, 2.1, 2.2, or Pikaffect. To adjust the aspect ratio of your image add --aspect (1:1, 5:2, 16:9, 4:3, 4:5, 9:16). Image to video is supported on all models, and multiple images are supported for 2.2 with an IngredientMode selected.</p> <p>Extra: Powered by a server managed by @pikalabs. Learn more</p>"},{"location":"models/Pika.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Pika.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| Turbo (Default) | ['720p', '5s', '5,000'] |</p> <p>| 2.1 | ['1080p', '5s', '19,167'] |</p> <p>| 2.2 | ['1080p', '10s', '40,000'] |</p> <p>| 2.2 + Ingredients | ['1080p', '10s', '60,000'] |</p> <p>| Pikaffects | ['720p', '5s', '23,334'] |</p> <p>Last Checked: 2025-08-05 23:35:50.521416</p>"},{"location":"models/Pika.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Pika</code></p> <p>Object Type: model</p> <p>Created: 1742425653535</p> <p>Owned By: poe</p> <p>Root: Pika</p>"},{"location":"models/Pixverse-v4.5.html","title":"Pixverse-v4.5","text":""},{"location":"models/Pixverse-v4.5.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Pixverse v4.5 is a video generation model capable of generating high quality videos in under a minute.  Use <code>--negative_prompt</code> to set the negative prompt.  Use <code>--duration</code> to set the video duration (5 or 8 seconds).  Set the resolution (360p,540p,720p or 1080p) using <code>--resolution</code>.  Send 1 image to perform an image-to-video task or a video effect generation task, and 2 images to perform a video transition task, using the first image as the first frame and the second image as the last frame.  Use <code>--effect</code> to set the video generation effect, provided 1 image is given (Options: <code>Kiss_Me_AI</code>, <code>Kiss</code>, <code>Muscle_Surge</code>, <code>Warmth_of_Jesus</code>, <code>Anything,_Robot</code>, <code>The_Tiger_Touch</code>, <code>Hug</code>, <code>Holy_Wings</code>, <code>Hulk</code>, <code>Venom</code>, <code>Microwave</code>). Use <code>--style</code> to set the video generation style (for text-to-video,image-to-video, and transition only, options: <code>anime</code>, <code>3d_animation</code>, <code>clay</code>, <code>comic</code>, <code>cyberpunk</code>). Use <code>--seed</code> to set the seed and <code>--aspect</code> to set the aspect ratio.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Pixverse-v4.5.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Pixverse-v4.5.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| Video Output (360P) | 2000 points / second |</p> <p>| Video Output (540P) | 2000 points / second |</p> <p>| Video Output (720P) | 2667 points / second |</p> <p>| Video Output (1080P) | 5334 points / second |</p> <p>| Video Effects/Video Transition Output (360P) | 4000 points / second |</p> <p>| Video Effects/Video Transition Output (540P) | 4000 points / second |</p> <p>| Video Effects/Video Transition Output (720P) | 5334 points / second |</p> <p>| Video Effects/Video Transition Output (1080P) | 10667 points / second |</p> <p>Last Checked: 2025-08-05 23:35:57.229243</p>"},{"location":"models/Pixverse-v4.5.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Pixverse-v4.5</code></p> <p>Object Type: model</p> <p>Created: 1747737997951</p> <p>Owned By: poe</p> <p>Root: Pixverse-v4.5</p>"},{"location":"models/PlayAI-Dialog.html","title":"PlayAI-Dialog","text":""},{"location":"models/PlayAI-Dialog.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Generates dialogues based on your script using PlayHT's text-to-speech model, in the voices of your choice. Use --speaker_1 [voice_name]  and --speaker_2 [voice_name] to pass in the voices of your choice, choosing from below. Voice defaults to <code>Jennifer_(English_(US)/American)</code>.  Follow the below format while prompting (case sensitive): FORMAT: <pre><code>Speaker 1: ......\nSpeaker 2: ......\nSpeaker 1: ......\nSpeaker 2: ......\n--speaker_1 [voice_1] --speaker_2 [voice_2]\n</code></pre> VOICES AVAILABLE: Jennifer_(English_(US)/American) Dexter_(English_(US)/American) Ava_(English_(AU)/Australian) Tilly_(English_(AU)/Australian) Charlotte_(Advertising)(English(CA)/Canadian) Charlotte_(Meditation)(English(CA)/Canadian) Cecil_(English_(GB)/British) Sterling_(English_(GB)/British) Cillian_(English_(IE)/Irish) Madison_(English_(IE)/Irish) Ada_(English_(ZA)/South_African) Furio_(English_(IT)/Italian) Alessandro_(English_(IT)/Italian) Carmen_(English_(MX)/Mexican) Sumita_(English_(IN)/Indian) Navya_(English_(IN)/Indian) Baptiste_(English_(FR)/French) Lumi_(English_(FI)/Finnish) Ronel_Conversational_(Afrikaans/South_African) Ronel_Narrative_(Afrikaans/South_African) Abdo_Conversational_(Arabic/Arabic) Abdo_Narrative_(Arabic/Arabic) Mousmi_Conversational_(Bengali/Bengali) Mousmi_Narrative_(Bengali/Bengali) Caroline_Conversational_(Portuguese_(BR)/Brazilian) Caroline_Narrative_(Portuguese_(BR)/Brazilian) Ange_Conversational_(French/French) Ange_Narrative_(French/French) Anke_Conversational_(German/German) Anke_Narrative_(German/German) Bora_Conversational_(Greek/Greek) Bora_Narrative_(Greek/Greek) Anuj_Conversational_(Hindi/Indian) Anuj_Narrative_(Hindi/Indian) Alessandro_Conversational_(Italian/Italian) Alessandro_Narrative_(Italian/Italian) Kiriko_Conversational_(Japanese/Japanese) Kiriko_Narrative_(Japanese/Japanese) Dohee_Conversational_(Korean/Korean) Dohee_Narrative_(Korean/Korean) Ignatius_Conversational_(Malay/Malay) Ignatius_Narrative_(Malay/Malay) Adam_Conversational_(Polish/Polish) Adam_Narrative_(Polish/Polish) Andrei_Conversational_(Russian/Russian) Andrei_Narrative_(Russian/Russian) Aleksa_Conversational_(Serbian/Serbian) Aleksa_Narrative_(Serbian/Serbian) Carmen_Conversational_(Spanish/Spanish) Patricia_Conversational_(Spanish/Spanish) Aiken_Conversational_(Tagalog/Filipino) Aiken_Narrative_(Tagalog/Filipino) Katbundit_Conversational_(Thai/Thai) Katbundit_Narrative_(Thai/Thai) Ali_Conversational_(Turkish/Turkish) Ali_Narrative_(Turkish/Turkish) Sahil_Conversational_(Urdu/Pakistani) Sahil_Narrative_(Urdu/Pakistani) Mary_Conversational_(Hebrew/Israeli) Mary_Narrative_(Hebrew/Israeli)</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/PlayAI-Dialog.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: audio</p> <p>Modality: text-&gt;audio</p>"},{"location":"models/PlayAI-Dialog.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| Audio Output | 29 points / second |</p> <p>Last Checked: 2025-08-05 23:36:04.017253</p>"},{"location":"models/PlayAI-Dialog.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>PlayAI-Dialog</code></p> <p>Object Type: model</p> <p>Created: 1737460623400</p> <p>Owned By: poe</p> <p>Root: PlayAI-Dialog</p>"},{"location":"models/PlayAI-TTS.html","title":"PlayAI-TTS","text":""},{"location":"models/PlayAI-TTS.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Generates audio based on your prompt using PlayHT's text-to-speech model, in the voice of your choice. Use --voice [voice_name] to pass in the voice of your choice, choosing one from below. Voice defaults to <code>Jennifer_(English_(US)/American)</code>. </p> <p>Jennifer_(English_(US)/American) Dexter_(English_(US)/American) Ava_(English_(AU)/Australian) Tilly_(English_(AU)/Australian) Charlotte_(Advertising)(English(CA)/Canadian) Charlotte_(Meditation)(English(CA)/Canadian) Cecil_(English_(GB)/British) Sterling_(English_(GB)/British) Cillian_(English_(IE)/Irish) Madison_(English_(IE)/Irish) Ada_(English_(ZA)/South_African) Furio_(English_(IT)/Italian) Alessandro_(English_(IT)/Italian) Carmen_(English_(MX)/Mexican) Sumita_(English_(IN)/Indian) Navya_(English_(IN)/Indian) Baptiste_(English_(FR)/French) Lumi_(English_(FI)/Finnish) Ronel_Conversational_(Afrikaans/South_African) Ronel_Narrative_(Afrikaans/South_African) Abdo_Conversational_(Arabic/Arabic) Abdo_Narrative_(Arabic/Arabic) Mousmi_Conversational_(Bengali/Bengali) Mousmi_Narrative_(Bengali/Bengali) Caroline_Conversational_(Portuguese_(BR)/Brazilian) Caroline_Narrative_(Portuguese_(BR)/Brazilian) Ange_Conversational_(French/French) Ange_Narrative_(French/French) Anke_Conversational_(German/German) Anke_Narrative_(German/German) Bora_Conversational_(Greek/Greek) Bora_Narrative_(Greek/Greek) Anuj_Conversational_(Hindi/Indian) Anuj_Narrative_(Hindi/Indian) Alessandro_Conversational_(Italian/Italian) Alessandro_Narrative_(Italian/Italian) Kiriko_Conversational_(Japanese/Japanese) Kiriko_Narrative_(Japanese/Japanese) Dohee_Conversational_(Korean/Korean) Dohee_Narrative_(Korean/Korean) Ignatius_Conversational_(Malay/Malay) Ignatius_Narrative_(Malay/Malay) Adam_Conversational_(Polish/Polish) Adam_Narrative_(Polish/Polish) Andrei_Conversational_(Russian/Russian) Andrei_Narrative_(Russian/Russian) Aleksa_Conversational_(Serbian/Serbian) Aleksa_Narrative_(Serbian/Serbian) Carmen_Conversational_(Spanish/Spanish) Patricia_Conversational_(Spanish/Spanish) Aiken_Conversational_(Tagalog/Filipino) Aiken_Narrative_(Tagalog/Filipino) Katbundit_Conversational_(Thai/Thai) Katbundit_Narrative_(Thai/Thai) Ali_Conversational_(Turkish/Turkish) Ali_Narrative_(Turkish/Turkish) Sahil_Conversational_(Urdu/Pakistani) Sahil_Narrative_(Urdu/Pakistani) Mary_Conversational_(Hebrew/Israeli) Mary_Narrative_(Hebrew/Israeli)</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/PlayAI-TTS.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: audio</p> <p>Modality: text-&gt;audio</p>"},{"location":"models/PlayAI-TTS.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| Audio Output | 17 points / second |</p> <p>Last Checked: 2025-08-05 23:36:11.067852</p>"},{"location":"models/PlayAI-TTS.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>PlayAI-TTS</code></p> <p>Object Type: model</p> <p>Created: 1737458808496</p> <p>Owned By: poe</p> <p>Root: PlayAI-TTS</p>"},{"location":"models/Poe-System-Bot.html","title":"Poe-System-Bot","text":""},{"location":"models/Poe-System-Bot.html#bot-information","title":"Bot Information","text":"<p>Creator: @poe</p> <p>Description: A system bot that helps manage the chat.</p> <p>Extra: Powered by Anthropic: claude-3-haiku-20240307. Learn more</p>"},{"location":"models/Poe-System-Bot.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Poe-System-Bot.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 30 points/message |</p> <p>| Initial Points Cost | 30 points |</p> <p>Last Checked: 2025-08-05 23:36:17.731036</p>"},{"location":"models/Poe-System-Bot.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Poe-System-Bot</code></p> <p>Object Type: model</p> <p>Created: 1725041210466</p> <p>Owned By: poe</p> <p>Root: Poe-System-Bot</p>"},{"location":"models/Python.html","title":"Python","text":""},{"location":"models/Python.html#bot-information","title":"Bot Information","text":"<p>Creator: @poe</p> <p>Description: Executes Python code (version 3.11) from the user message and outputs the results. If there are code blocks in the user message (surrounded by triple backticks), then only the code blocks will be executed. These libraries are imported into this bot's run-time automatically -- numpy, pandas, requests, matplotlib, scikit-learn, torch, PyYAML, tensorflow, scipy, pytest -- along with ~150 of the most widely used Python libraries.</p> <p>Extra: Powered by Poe and third party model providers. Learn more</p>"},{"location":"models/Python.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Python.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1 point/message |</p> <p>| Initial Points Cost | 1 point |</p> <p>Last Checked: 2025-08-05 23:36:24.428504</p>"},{"location":"models/Python.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Python</code></p> <p>Object Type: model</p> <p>Created: 1724756919380</p> <p>Owned By: poe</p> <p>Root: Python</p>"},{"location":"models/QwQ-32B-B10.html","title":"QwQ-32B-B10","text":""},{"location":"models/QwQ-32B-B10.html#bot-information","title":"Bot Information","text":"<p>Creator: @baseten</p> <p>Description: QwQ-32B is a medium-sized reasoning model from the Qwen series. It delivers human-like responses to diverse prompts, including math and code generation, while supporting dozens of different languages. With quality on par with reasoning models multiple times bigger in size, QwQ also features an extensive context window of up to 131,072 tokens. </p> <p>Try it out with blazing-fast speed optimized by Baseten's model performance engineers.</p> <p>Extra: Powered by a server managed by @baseten. Learn more</p>"},{"location":"models/QwQ-32B-B10.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/QwQ-32B-B10.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 200 points/message |</p> <p>| Initial Points Cost | 200 points |</p> <p>Last Checked: 2025-08-05 23:36:31.598040</p>"},{"location":"models/QwQ-32B-B10.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>QwQ-32B-B10</code></p> <p>Object Type: model</p> <p>Created: 1742954432562</p> <p>Owned By: poe</p> <p>Root: QwQ-32B-B10</p>"},{"location":"models/QwQ-32B-Preview-T.html","title":"QwQ-32B-Preview-T","text":""},{"location":"models/QwQ-32B-Preview-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: An experimental research model focused on advancing AI reasoning capabilities. On par with O-1 mini and preview.</p> <p>It demonstrates exceptional performance in complex problem-solving, achieving impressive scores on mathematical and scientific reasoning benchmarks (65.2% on GPQA, 50.0% on AIME, 90.6% on MATH-500)</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/QwQ-32B-Preview-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/QwQ-32B-Preview-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 320 points/message |</p> <p>| Initial Points Cost | 320 points |</p> <p>Last Checked: 2025-08-05 23:36:38.369043</p>"},{"location":"models/QwQ-32B-Preview-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>QwQ-32B-Preview-T</code></p> <p>Object Type: model</p> <p>Created: 1733158246974</p> <p>Owned By: poe</p> <p>Root: QwQ-32B-Preview-T</p>"},{"location":"models/QwQ-32B-T.html","title":"QwQ-32B-T","text":""},{"location":"models/QwQ-32B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: QwQ\u201132B \u2013 a compact, open\u2011source reasoning model with 32B parameters. It leverages multi\u2011stage reinforcement learning and agentic capabilities to deliver strong performance on math, coding, and general problem\u2011solving tasks \u2013 rivaling giants like DeepSeek\u2011R1 despite being much smaller. It also supports an impressive context window of up to 131k tokens.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/QwQ-32B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/QwQ-32B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 250 points/message |</p> <p>| Initial Points Cost | 250 points |</p> <p>Last Checked: 2025-08-05 23:36:45.070268</p>"},{"location":"models/QwQ-32B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>QwQ-32B-T</code></p> <p>Object Type: model</p> <p>Created: 1742492449252</p> <p>Owned By: poe</p> <p>Root: QwQ-32B-T</p>"},{"location":"models/Qwen-2.5-72B-T.html","title":"Qwen-2.5-72B-T","text":""},{"location":"models/Qwen-2.5-72B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Qwen 2.5 72B from Alibaba. Excels in coding, math, instruction following, natural language understanding, and has great multilangual support with more than 29 languages. </p> <p>Delivering results on par with Llama-3-405B despite using only one-fifth of the parameters.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Qwen-2.5-72B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen-2.5-72B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 300 points/message |</p> <p>| Initial Points Cost | 300 points |</p> <p>Last Checked: 2025-08-05 23:36:52.211945</p>"},{"location":"models/Qwen-2.5-72B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen-2.5-72B-T</code></p> <p>Object Type: model</p> <p>Created: 1730863910082</p> <p>Owned By: poe</p> <p>Root: Qwen-2.5-72B-T</p>"},{"location":"models/Qwen-2.5-7B-T.html","title":"Qwen-2.5-7B-T","text":""},{"location":"models/Qwen-2.5-7B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Qwen 2.5 7B from Alibaba. Excels in coding, math, instruction following, natural language understanding, and has great multilangual support with more than 29 languages.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Qwen-2.5-7B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen-2.5-7B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 75 points/message |</p> <p>| Initial Points Cost | 75 points |</p> <p>Last Checked: 2025-08-05 23:36:59.016836</p>"},{"location":"models/Qwen-2.5-7B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen-2.5-7B-T</code></p> <p>Object Type: model</p> <p>Created: 1730863674687</p> <p>Owned By: poe</p> <p>Root: Qwen-2.5-7B-T</p>"},{"location":"models/Qwen-2.5-Coder-32B-T.html","title":"Qwen-2.5-Coder-32B-T","text":""},{"location":"models/Qwen-2.5-Coder-32B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: A powerful model from Alibaba with 32.5B parameters, excelling in coding, math, and multilingual tasks. It offers strong performance across various domains while being more compact than larger models.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Qwen-2.5-Coder-32B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen-2.5-Coder-32B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 210 points/message |</p> <p>| Initial Points Cost | 210 points |</p> <p>Last Checked: 2025-08-05 23:37:05.768897</p>"},{"location":"models/Qwen-2.5-Coder-32B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen-2.5-Coder-32B-T</code></p> <p>Object Type: model</p> <p>Created: 1733158197633</p> <p>Owned By: poe</p> <p>Root: Qwen-2.5-Coder-32B-T</p>"},{"location":"models/Qwen-2.5-VL-32b.html","title":"Qwen-2.5-VL-32b","text":""},{"location":"models/Qwen-2.5-VL-32b.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: Qwen2.5-VL-32B's mathematical and problem-solving capabilities have been strengthened through reinforcement learning, leading to a significantly improved user experience. The model's response styles have been refined to better align with human preferences, particularly for objective queries involving mathematics, logical reasoning, and knowledge-based Q&amp;A. As a result, responses now feature greater detail, improved clarity, and enhanced formatting.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Qwen-2.5-VL-32b.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen-2.5-VL-32b.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 220 points/message |</p> <p>| Initial Points Cost | 220 points |</p> <p>Last Checked: 2025-08-05 23:37:12.751511</p>"},{"location":"models/Qwen-2.5-VL-32b.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen-2.5-VL-32b</code></p> <p>Object Type: model</p> <p>Created: 1743550499150</p> <p>Owned By: poe</p> <p>Root: Qwen-2.5-VL-32b</p>"},{"location":"models/Qwen-3-235B-0527-T.html","title":"Qwen-3-235B-0527-T","text":""},{"location":"models/Qwen-3-235B-0527-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Qwen3 235B A22B 2507, currently the best instruct model (non-reasoning) among both closed and open source models. It excels in instruction following, logical reasoning, text comprehension, mathematics, science, coding and tool usage. It is also great at multilingual tasks and supports a long context window (262k).</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Qwen-3-235B-0527-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen-3-235B-0527-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 63 points/message |</p> <p>| Initial Points Cost | 63 points |</p> <p>Last Checked: 2025-08-05 23:37:19.705652</p>"},{"location":"models/Qwen-3-235B-0527-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen-3-235B-0527-T</code></p> <p>Object Type: model</p> <p>Created: 1745978851479</p> <p>Owned By: poe</p> <p>Root: Qwen-3-235B-0527-T</p>"},{"location":"models/Qwen-72B-T.html","title":"Qwen-72B-T","text":""},{"location":"models/Qwen-72B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Qwen1.5 (\u901a\u4e49\u5343\u95ee1.5) 72B\uff0c\u57fa\u4e8e\u963f\u91cc\u5df4\u5df4\u81ea\u7814\u5927\u6a21\u578b\u7684AI\u52a9\u624b\uff0c\u5c24\u5176\u64c5\u957f\u4e2d\u6587\u5bf9\u8bdd\u3002</p> <p>Alibaba's general-purpose model which excels particularly in Chinese-language queries.</p> <p>The points price is subject to change.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Qwen-72B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen-72B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 125 points/message |</p> <p>| Initial Points Cost | 125 points |</p> <p>Last Checked: 2025-08-05 23:37:26.704047</p>"},{"location":"models/Qwen-72B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen-72B-T</code></p> <p>Object Type: model</p> <p>Created: 1709166989166</p> <p>Owned By: poe</p> <p>Root: Qwen-72B-T</p>"},{"location":"models/Qwen-QwQ-32b-preview.html","title":"Qwen-QwQ-32b-preview","text":""},{"location":"models/Qwen-QwQ-32b-preview.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: Qwen QwQ model focuses on advancing AI reasoning, and showcases the power of open models to match closed frontier model performance. QwQ-32B-Preview is an experimental release, comparable to o1 and surpassing GPT-4o and Claude 3.5 Sonnet on analytical and reasoning abilities across GPQA, AIME, MATH-500 and LiveCodeBench benchmarks. Note: This model is served experimentally by Fireworks.AI</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Qwen-QwQ-32b-preview.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen-QwQ-32b-preview.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 240 points/message |</p> <p>| Initial Points Cost | 240 points |</p> <p>Last Checked: 2025-08-05 23:37:33.522406</p>"},{"location":"models/Qwen-QwQ-32b-preview.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen-QwQ-32b-preview</code></p> <p>Object Type: model</p> <p>Created: 1733275325628</p> <p>Owned By: poe</p> <p>Root: Qwen-QwQ-32b-preview</p>"},{"location":"models/Qwen2-72B-Instruct-T.html","title":"Qwen2-72B-Instruct-T","text":""},{"location":"models/Qwen2-72B-Instruct-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Qwen2 (\u901a\u4e49\u5343\u95ee2) 72B\uff0c\u57fa\u4e8e\u963f\u91cc\u5df4\u5df4\u81ea\u7814\u5927\u6a21\u578b\u7684AI\u52a9\u624b\uff0c\u5c24\u5176\u64c5\u957f\u4e2d\u6587\u5bf9\u8bdd\u3002</p> <p>Alibaba's general-purpose model which excels particularly in Chinese-language queries.</p> <p>The points price is subject to change.</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Qwen2-72B-Instruct-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen2-72B-Instruct-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 190 points/message |</p> <p>| Initial Points Cost | 190 points |</p> <p>Last Checked: 2025-08-05 23:37:40.299065</p>"},{"location":"models/Qwen2-72B-Instruct-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen2-72B-Instruct-T</code></p> <p>Object Type: model</p> <p>Created: 1718313334490</p> <p>Owned By: poe</p> <p>Root: Qwen2-72B-Instruct-T</p>"},{"location":"models/Qwen2.5-Coder-32B.html","title":"Qwen2.5-Coder-32B","text":""},{"location":"models/Qwen2.5-Coder-32B.html#bot-information","title":"Bot Information","text":"<p>Creator: @hyperbolic</p> <p>Description: Qwen2.5-Coder is the latest series of code-specific Qwen large language models (formerly known as CodeQwen), developed by Alibaba.</p> <p>Extra: Powered by a server managed by @hyperbolic. Learn more</p>"},{"location":"models/Qwen2.5-Coder-32B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen2.5-Coder-32B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 50 points/message |</p> <p>| Initial Points Cost | 50 points |</p> <p>Last Checked: 2025-08-05 23:37:47.009580</p>"},{"location":"models/Qwen2.5-Coder-32B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen2.5-Coder-32B</code></p> <p>Object Type: model</p> <p>Created: 1731698228854</p> <p>Owned By: poe</p> <p>Root: Qwen2.5-Coder-32B</p>"},{"location":"models/Qwen2.5-VL-72B-T.html","title":"Qwen2.5-VL-72B-T","text":""},{"location":"models/Qwen2.5-VL-72B-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @togetherai</p> <p>Description: Qwen 2.5 VL 72B, a cutting-edge multimodal model from the Qwen Team, excels in visual and video understanding, multilingual text/image processing (including Japanese, Arabic, and Korean), and dynamic agentic reasoning for automation. It supports long-context comprehension (32K tokens)</p> <p>Extra: Powered by a server managed by @togetherai. Learn more</p>"},{"location":"models/Qwen2.5-VL-72B-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen2.5-VL-72B-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 290 points/message |</p> <p>| Initial Points Cost | 290 points |</p> <p>Last Checked: 2025-08-05 23:37:53.708533</p>"},{"location":"models/Qwen2.5-VL-72B-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen2.5-VL-72B-T</code></p> <p>Object Type: model</p> <p>Created: 1743431047831</p> <p>Owned By: poe</p> <p>Root: Qwen2.5-VL-72B-T</p>"},{"location":"models/Qwen3-235B-2507-FW.html","title":"Qwen3-235B-2507-FW","text":""},{"location":"models/Qwen3-235B-2507-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: State-of-the-art language model with exceptional math, coding, and problem-solving performance. Operates in non-thinking mode, and does not generate  blocks in its output. Supports 256k tokens of native context length. All data provided will not be used in training, and is sent only to Fireworks AI, a US-based company. Uses the latest July 21st, 2025 snapshot (Qwen3-235B-A22B-Instruct-2507).</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Qwen3-235B-2507-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen3-235B-2507-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 90 points/message |</p> <p>| Initial Points Cost | 90 points |</p> <p>Last Checked: 2025-08-05 23:38:00.571537</p>"},{"location":"models/Qwen3-235B-2507-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen3-235B-2507-FW</code></p> <p>Object Type: model</p> <p>Created: 1745952547301</p> <p>Owned By: poe</p> <p>Root: Qwen3-235B-2507-FW</p>"},{"location":"models/Qwen3-235B-A22B-DI.html","title":"Qwen3-235B-A22B-DI","text":""},{"location":"models/Qwen3-235B-A22B-DI.html#bot-information","title":"Bot Information","text":"<p>Creator: @deepinfra</p> <p>Description: Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support.</p> <p>Supports 32k tokens of input context and 8k tokens of output context. Quantization: FP8.</p> <p>Extra: Powered by a server managed by @deepinfra. Learn more</p>"},{"location":"models/Qwen3-235B-A22B-DI.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen3-235B-A22B-DI.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 63 points/message |</p> <p>| Initial Points Cost | 63 points |</p> <p>Last Checked: 2025-08-05 23:38:14.117934</p>"},{"location":"models/Qwen3-235B-A22B-DI.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen3-235B-A22B-DI</code></p> <p>Object Type: model</p> <p>Created: 1746004656402</p> <p>Owned By: poe</p> <p>Root: Qwen3-235B-A22B-DI</p>"},{"location":"models/Qwen3-235B-A22B.html","title":"Qwen3-235B-A22B","text":""},{"location":"models/Qwen3-235B-A22B.html#bot-information","title":"Bot Information","text":"<p>Creator: @baseten</p> <p>Description: The fastest implementation of the new Qwen3 235B flagship model. With support for 119 languages and dialects, you can use it for code generation, content understanding and summarization, conversational AI, math, or any task requiring complex reasoning.</p> <p>Extra: Powered by a server managed by @baseten. Learn more</p>"},{"location":"models/Qwen3-235B-A22B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen3-235B-A22B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1 point/message |</p> <p>| Initial Points Cost | 1 point |</p> <p>Last Checked: 2025-08-05 23:38:07.438613</p>"},{"location":"models/Qwen3-235B-A22B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen3-235B-A22B</code></p> <p>Object Type: model</p> <p>Created: 1745872547811</p> <p>Owned By: poe</p> <p>Root: Qwen3-235B-A22B</p>"},{"location":"models/Qwen3-32B-nitro.html","title":"Qwen3-32B-nitro","text":""},{"location":"models/Qwen3-32B-nitro.html#bot-information","title":"Bot Information","text":"<p>Creator: @cerebrasai</p> <p>Description: World\u2019s fastest inference for Qwen 3 32B with Cerebras.</p> <p>Extra: Powered by a server managed by @cerebrasai. Learn more</p>"},{"location":"models/Qwen3-32B-nitro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen3-32B-nitro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1 point/message |</p> <p>| Initial Points Cost | 1 point |</p> <p>Last Checked: 2025-08-05 23:38:20.884039</p>"},{"location":"models/Qwen3-32B-nitro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen3-32B-nitro</code></p> <p>Object Type: model</p> <p>Created: 1747326165823</p> <p>Owned By: poe</p> <p>Root: Qwen3-32B-nitro</p>"},{"location":"models/Qwen3-Coder-480B-FW.html","title":"Qwen3-Coder-480B-FW","text":""},{"location":"models/Qwen3-Coder-480B-FW.html#bot-information","title":"Bot Information","text":"<p>Creator: @fireworksai</p> <p>Description: This state-of-the-art 480B-parameter Mixture-of-Experts model (35B active) achieves top-tier performance across multiple agentic coding benchmarks. Supports 256K native context length and scales to 1M tokens with extrapolation. All data provided will not be used in training, and is sent only to Fireworks AI, a US-based company.</p> <p>Extra: Powered by a server managed by @fireworksai. Learn more</p>"},{"location":"models/Qwen3-Coder-480B-FW.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Qwen3-Coder-480B-FW.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 300 points/message |</p> <p>| Initial Points Cost | 300 points |</p> <p>Last Checked: 2025-08-05 23:38:27.785906</p>"},{"location":"models/Qwen3-Coder-480B-FW.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Qwen3-Coder-480B-FW</code></p> <p>Object Type: model</p> <p>Created: 1753296529249</p> <p>Owned By: poe</p> <p>Root: Qwen3-Coder-480B-FW</p>"},{"location":"models/Ray2.html","title":"Ray2","text":""},{"location":"models/Ray2.html#bot-information","title":"Bot Information","text":"<p>Creator: @lumalabs</p> <p>Description: Ray2 is a large\u2013scale video generative model capable of creating realistic visuals with natural, coherent motion. It has strong understanding of text instructions and can also take image input. Can produce videos from 540p to 4k resolution and with either 5/9s durations.</p> <p>Extra: Powered by a server managed by @lumalabs. Learn more</p>"},{"location":"models/Ray2.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Ray2.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| 5S | ['6,000 points', '11,750 points', '26,250 points', '106,250 points'] |</p> <p>| 9S | ['10,800 points', '21,150 points', '47,250 points', '191,250 points'] |</p> <p>Last Checked: 2025-08-05 23:38:34.650389</p>"},{"location":"models/Ray2.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Ray2</code></p> <p>Object Type: model</p> <p>Created: 1740094898040</p> <p>Owned By: poe</p> <p>Root: Ray2</p>"},{"location":"models/Recraft-V3.html","title":"Recraft-V3","text":""},{"location":"models/Recraft-V3.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Recraft V3, state of the art image generation. Use --style for styles, and --aspect for aspect ratio configuration. Available styles: realistic_image, digital_illustration, vector_illustration, realistic_image/b_and_w, realistic_image/hard_flash, realistic_image/hdr, realistic_image/natural_light, realistic_image/studio_portrait, realistic_image/enterprise, realistic_image/motion_blur, digital_illustration/pixel_art, digital_illustration/hand_drawn, digital_illustration/grain, digital_illustration/infantile_sketch, digital_illustration/2d_art_poster, digital_illustration/handmade_3d, digital_illustration/hand_drawn_outline, digital_illustration/engraving_color, digital_illustration/2d_art_poster_2, vector_illustration/engraving, vector_illustration/line_art, vector_illustration/line_circuit, vector_illustration/linocut</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Recraft-V3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Recraft-V3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 2267 points / message |</p> <p>| Initial Points Cost | 2267 points |</p> <p>Last Checked: 2025-08-05 23:38:41.717608</p>"},{"location":"models/Recraft-V3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Recraft-V3</code></p> <p>Object Type: model</p> <p>Created: 1730322043217</p> <p>Owned By: poe</p> <p>Root: Recraft-V3</p>"},{"location":"models/Reka-Core.html","title":"Reka-Core","text":""},{"location":"models/Reka-Core.html#bot-information","title":"Bot Information","text":"<p>Creator: @reka</p> <p>Description: Reka's largest and most capable multimodal language model. Works with text, images, and video inputs. 8k context length.</p> <p>Extra: Powered by a server managed by @reka. Learn more</p>"},{"location":"models/Reka-Core.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Reka-Core.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | 834 points |</p> <p>| Total Cost | 834 points / message |</p> <p>Last Checked: 2025-08-05 23:38:48.669710</p>"},{"location":"models/Reka-Core.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Reka-Core</code></p> <p>Object Type: model</p> <p>Created: 1713038207102</p> <p>Owned By: poe</p> <p>Root: Reka-Core</p>"},{"location":"models/Reka-Flash.html","title":"Reka-Flash","text":""},{"location":"models/Reka-Flash.html#bot-information","title":"Bot Information","text":"<p>Creator: @reka</p> <p>Description: Reka's efficient and capable 21B multimodal model optimized for fast workloads and amazing quality. Works with text, images and video inputs.</p> <p>Extra: Powered by a server managed by @reka. Learn more</p>"},{"location":"models/Reka-Flash.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Reka-Flash.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | 27 points |</p> <p>| Total Cost | 27 points / message |</p> <p>Last Checked: 2025-08-05 23:38:55.471406</p>"},{"location":"models/Reka-Flash.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Reka-Flash</code></p> <p>Object Type: model</p> <p>Created: 1707892216404</p> <p>Owned By: poe</p> <p>Root: Reka-Flash</p>"},{"location":"models/Reka-Research.html","title":"Reka-Research","text":""},{"location":"models/Reka-Research.html#bot-information","title":"Bot Information","text":"<p>Creator: @reka</p> <p>Description: Reka Research is a state-of-the-art agentic AI that answers complex questions by browsing the web. It excels at synthesizing information from multiple sources, performing work that usually takes hours in minutes</p> <p>Extra: Powered by a server managed by @reka. Learn more</p>"},{"location":"models/Reka-Research.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Reka-Research.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | 334 points |</p> <p>| Total Cost | 334 points / message |</p> <p>Last Checked: 2025-08-05 23:39:02.721156</p>"},{"location":"models/Reka-Research.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Reka-Research</code></p> <p>Object Type: model</p> <p>Created: 1750919363394</p> <p>Owned By: poe</p> <p>Root: Reka-Research</p>"},{"location":"models/Restyler.html","title":"Restyler","text":""},{"location":"models/Restyler.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: This bot enables rapid transformation of existing images, delivering high-quality style transfers and image modifications. Takes in a text input and an image attachment. Use --strength to control the guidance given by the initial image, with higher values adhering to the image more strongly.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Restyler.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Restyler.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 2000 points / message |</p> <p>| Initial Points Cost | 2000 points |</p> <p>Last Checked: 2025-08-05 23:39:09.601288</p>"},{"location":"models/Restyler.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Restyler</code></p> <p>Object Type: model</p> <p>Created: 1739302186273</p> <p>Owned By: poe</p> <p>Root: Restyler</p>"},{"location":"models/Retro-Diffusion-Core.html","title":"Retro-Diffusion-Core","text":""},{"location":"models/Retro-Diffusion-Core.html#bot-information","title":"Bot Information","text":"<p>Creator: @retrodiffusion</p> <p>Description: Generate true game ready pixel art in seconds at any resolution between 16x16 and 512x512 across the various styles. Create 48x48 walking animations of sprites using the \"animation_four_angle_walking\" style! First 50 basic image requests worth of points free! Check out more settings below \ud83d\udc47</p> <p>Example message: \"A cute corgi wearing sunglasses and a party hat --ar 128:128 --style rd_fast__portrait\"</p> <p>Settings: --ar : (Image size in pixels, larger images cost more. Or aspect ratio like 16:9) --style  (The name of the style you want to use. Available styles: rd_fast__anime, rd_fast__retro, rd_fast__simple, rd_fast__detailed, rd_fast__game_asset, rd_fast__portrait, rd_fast__texture, rd_fast__ui, rd_fast__item_sheet, rd_fast__mc_texture, rd_fast__mc_item, rd_fast__character_turnaround, rd_fast__1_bit, animation__four_angle_walking, rd_plus__default, rd_plus__retro, rd_plus__watercolor, rd_plus__textured, rd_plus__cartoon, rd_plus__ui_element, rd_plus__item_sheet, rd_plus__character_turnaround, rd_plus__isometric, rd_plus__isometric_asset, rd_plus__topdown_map, rd_plus__top_down_asset) --seed (Random number, keep the same for consistent generations) --tile (Creates seamless edges on applicable images) --tilex (Seamless horizontally only) --tiley (Seamless vertically only) --native (Returns pixel art at native resolution, without upscaling) --removebg (Automatically remove the background) --iw  (Controls how strong the image generation is. 0.0 for small changes, 1.0 for big changes) <p>Additional notes: All styles have a size range of 48x48 -&gt; 512x512, except for the \"mc\" styles, which have a size range of 16x16 -&gt; 128x128, and the \"animation_four_angle_walking\" style, which will only create 48x48 animations.</p> <p>Extra: Powered by a server managed by @retrodiffusion. Learn more</p>"},{"location":"models/Retro-Diffusion-Core.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Retro-Diffusion-Core.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Retro-Diffusion-Core</code></p> <p>Object Type: model</p> <p>Created: 1742484693553</p> <p>Owned By: poe</p> <p>Root: Retro-Diffusion-Core</p>"},{"location":"models/Runway-Gen-4-Turbo.html","title":"Runway-Gen-4-Turbo","text":""},{"location":"models/Runway-Gen-4-Turbo.html#bot-information","title":"Bot Information","text":"<p>Creator: @runwayml</p> <p>Description: Runway's Gen-4 Turbo model creates best-in-class, controllable, and high-fidelity video generations based on your prompts. Both text inputs (max 1000 characters) and image inputs are supported, but we recommend using image inputs for best results. Use --aspect_ratio (16:9, 9:16, landscape, portrait) for landscape/portrait videos. Use --duration (5, 10) to specify video length in seconds. Full prompting guide here: https://help.runwayml.com/hc/en-us/articles/39789879462419-Gen-4-Video-Prompting-Guide</p> <p>Extra: Powered by a server managed by @runwayml. Learn more</p>"},{"location":"models/Runway-Gen-4-Turbo.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Runway-Gen-4-Turbo.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| 5 Seconds | 11334 points |</p> <p>| 10 Seconds | 21334 points |</p> <p>Last Checked: 2025-08-05 23:39:29.900681</p>"},{"location":"models/Runway-Gen-4-Turbo.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Runway-Gen-4-Turbo</code></p> <p>Object Type: model</p> <p>Created: 1746825004531</p> <p>Owned By: poe</p> <p>Root: Runway-Gen-4-Turbo</p>"},{"location":"models/Runway.html","title":"Runway","text":""},{"location":"models/Runway.html#bot-information","title":"Bot Information","text":"<p>Creator: @runwayml</p> <p>Description: Runway's Gen-3 Alpha Turbo model creates best-in-class, controllable, and high-fidelity video generations based on your prompts. Both text inputs (max 1000 characters) and image inputs are supported, but we recommend using image inputs for best results. Use --aspect_ratio (16:9, 9:16, landscape, portrait) for landscape/portrait videos. Use --duration (5, 10) to specify video length in seconds.</p> <p>Extra: Powered by a server managed by @runwayml. Learn more</p>"},{"location":"models/Runway.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Runway.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| 5 Seconds | 11334 points |</p> <p>| 10 Seconds | 21334 points |</p> <p>Last Checked: 2025-08-05 23:39:23.053451</p>"},{"location":"models/Runway.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Runway</code></p> <p>Object Type: model</p> <p>Created: 1728610474100</p> <p>Owned By: poe</p> <p>Root: Runway</p>"},{"location":"models/Sana-T2I.html","title":"Sana-T2I","text":""},{"location":"models/Sana-T2I.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: SANA can synthesize high-resolution, high-quality images at a remarkably fast rate, with the ability to generate 4K images in less than a second.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Sana-T2I.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/Sana-T2I.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 29 points / message |</p> <p>| Initial Points Cost | 29 points |</p> <p>Last Checked: 2025-08-05 23:39:36.762692</p>"},{"location":"models/Sana-T2I.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Sana-T2I</code></p> <p>Object Type: model</p> <p>Created: 1736139178094</p> <p>Owned By: poe</p> <p>Root: Sana-T2I</p>"},{"location":"models/Seedance-1.0-Lite.html","title":"Seedance-1.0-Lite","text":""},{"location":"models/Seedance-1.0-Lite.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Seedance is a video generation model with text-to-video and image-to-video capabilities. It achieves breakthroughs in semantic understanding and prompt following. Use <code>--aspect</code> to set the aspect ratio (available values: <code>16:9</code>, <code>4:3</code>, <code>1:1</code> and <code>9:21</code>). Use <code>--resolution</code> (one of <code>480p</code> and <code>720p</code> to set the video resolution. <code>--duration</code> (5 or 10) sets the video duration. Number of video tokens calculated for pricing is approximately: `height * width * fps * duration / 1024).</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Seedance-1.0-Lite.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Seedance-1.0-Lite.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 60000 points / million video tokens |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:39:43.587532</p>"},{"location":"models/Seedance-1.0-Lite.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Seedance-1.0-Lite</code></p> <p>Object Type: model</p> <p>Created: 1750007728801</p> <p>Owned By: poe</p> <p>Root: Seedance-1.0-Lite</p>"},{"location":"models/Seedance-1.0-Pro.html","title":"Seedance-1.0-Pro","text":""},{"location":"models/Seedance-1.0-Pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Seedance is a video generation model with text-to-video and image-to-video capabilities. It achieves breakthroughs in semantic understanding and prompt following. Use <code>--aspect</code> to set the aspect ratio (available values: <code>21:9</code>, <code>16:9</code>, <code>4:3</code>, <code>1:1</code>, <code>3:4</code>, <code>9:16</code>). Use <code>--resolution</code> (one of <code>480p</code> and <code>1080p</code> to set the video resolution. <code>--duration</code> (5 or 10) sets the video duration. Number of video tokens calculated for pricing is approximately: `height * width * fps * duration / 1024).</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Seedance-1.0-Pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Seedance-1.0-Pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 83334 points / million video tokens |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:39:50.550570</p>"},{"location":"models/Seedance-1.0-Pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Seedance-1.0-Pro</code></p> <p>Object Type: model</p> <p>Created: 1750447821693</p> <p>Owned By: poe</p> <p>Root: Seedance-1.0-Pro</p>"},{"location":"models/Seedream-3.0.html","title":"Seedream-3.0","text":""},{"location":"models/Seedream-3.0.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Seedream 3.0 by ByteDance is a bilingual (Chinese and English) text-to-image model that excels at text-to-image generation.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Seedream-3.0.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Seedream-3.0.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 1334 points / message |</p> <p>| Initial Points Cost | 1334 points |</p> <p>Last Checked: 2025-08-05 23:39:57.500106</p>"},{"location":"models/Seedream-3.0.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Seedream-3.0</code></p> <p>Object Type: model</p> <p>Created: 1750007407012</p> <p>Owned By: poe</p> <p>Root: Seedream-3.0</p>"},{"location":"models/Sketch-to-Image.html","title":"Sketch-to-Image","text":""},{"location":"models/Sketch-to-Image.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Takes in sketches and converts them to colored images.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Sketch-to-Image.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Sketch-to-Image.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 992 points / message |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:40:04.326621</p>"},{"location":"models/Sketch-to-Image.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Sketch-to-Image</code></p> <p>Object Type: model</p> <p>Created: 1736176125104</p> <p>Owned By: poe</p> <p>Root: Sketch-to-Image</p>"},{"location":"models/Solar-Pro-2.html","title":"Solar-Pro-2","text":""},{"location":"models/Solar-Pro-2.html#bot-information","title":"Bot Information","text":"<p>Creator: @upstage</p> <p>Description: Solar Pro 2 is Upstage's latest frontier-scale LLM. With just 31B parameters, it delivers top-tier performance through world-class multilingual support, advanced reasoning, and real-world tool use. Especially in Korean, it outperforms much larger models across critical benchmarks. Built for the next generation of practical LLMs, Solar Pro 2 proves that smaller models can still lead. Supports a context length of 64k tokens.</p> <p>Extra: Powered by an open source model hosted by Poe. Learn more</p>"},{"location":"models/Solar-Pro-2.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Solar-Pro-2.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 70 points/message |</p> <p>| Initial Points Cost | 70 points |</p> <p>Last Checked: 2025-08-05 23:40:11.150652</p>"},{"location":"models/Solar-Pro-2.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Solar-Pro-2</code></p> <p>Object Type: model</p> <p>Created: 1694610718864</p> <p>Owned By: poe</p> <p>Root: Solar-Pro-2</p>"},{"location":"models/Sora.html","title":"Sora","text":""},{"location":"models/Sora.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Sora is OpenAI's video generation model. Use <code>--duration</code> to set the duration of the generated video, and <code>--resolution</code> to set the video's resolution (480p, 720p, or 1080p). Set the aspect ratio of the generated video with <code>--aspect</code> (Valid aspect ratios are 16:9, 1:1, 9:16). This is a text-to-video model only.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Sora.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Sora.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 1667 points / second |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:40:18.005847</p>"},{"location":"models/Sora.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Sora</code></p> <p>Object Type: model</p> <p>Created: 1749552672238</p> <p>Owned By: poe</p> <p>Root: Sora</p>"},{"location":"models/StableDiffusion3-2B.html","title":"StableDiffusion3-2B","text":""},{"location":"models/StableDiffusion3-2B.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Stable Diffusion v3 Medium - by fal.ai</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/StableDiffusion3-2B.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/StableDiffusion3-2B.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 334 points / message |</p> <p>| Initial Points Cost | 334 points |</p> <p>Last Checked: 2025-08-05 23:40:24.751517</p>"},{"location":"models/StableDiffusion3-2B.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>StableDiffusion3-2B</code></p> <p>Object Type: model</p> <p>Created: 1718216691252</p> <p>Owned By: poe</p> <p>Root: StableDiffusion3-2B</p>"},{"location":"models/StableDiffusion3.5-L.html","title":"StableDiffusion3.5-L","text":""},{"location":"models/StableDiffusion3.5-L.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Stability.ai's StableDiffusion3.5 Large, hosted by @fal, is the Stable Diffusion family's most powerful image generation model both in terms of image quality and prompt adherence. Use \"--aspect\" to select an aspect ratio (e.g --aspect 1:1). Valid aspect ratios are 16:9, 4:3, 1:1, 3:4, 9:16.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/StableDiffusion3.5-L.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/StableDiffusion3.5-L.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 1842 points / message |</p> <p>| Initial Points Cost | 1842 points |</p> <p>Last Checked: 2025-08-05 23:40:32.725927</p>"},{"location":"models/StableDiffusion3.5-L.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>StableDiffusion3.5-L</code></p> <p>Object Type: model</p> <p>Created: 1729613306476</p> <p>Owned By: poe</p> <p>Root: StableDiffusion3.5-L</p>"},{"location":"models/StableDiffusion3.5-T.html","title":"StableDiffusion3.5-T","text":""},{"location":"models/StableDiffusion3.5-T.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Faster version of Stable Diffusion 3 Large, hosted by @fal. Excels for fast image generation. Use \"--aspect\" to select an aspect ratio (e.g --aspect 1:1).</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/StableDiffusion3.5-T.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/StableDiffusion3.5-T.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 284 points / message |</p> <p>| Initial Points Cost | 284 points |</p> <p>Last Checked: 2025-08-05 23:40:39.632388</p>"},{"location":"models/StableDiffusion3.5-T.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>StableDiffusion3.5-T</code></p> <p>Object Type: model</p> <p>Created: 1729817429663</p> <p>Owned By: poe</p> <p>Root: StableDiffusion3.5-T</p>"},{"location":"models/StableDiffusionXL.html","title":"StableDiffusionXL","text":""},{"location":"models/StableDiffusionXL.html#bot-information","title":"Bot Information","text":"<p>Creator: @stabilityai</p> <p>Description: Generates high quality images based on the user's most recent prompt. </p> <p>Allows users to specify elements to avoid in the image using the \"--no\" parameter at the end of the prompt. Select an aspect ratio with \"--aspect\". (e.g. \"Tall trees, daylight --no rain --aspect 7:4\"). Valid aspect ratios are 1:1, 7:4, 4:7, 9:7, 7:9, 19:13, 13:19, 12:5, &amp; 5:12. </p> <p>Powered by Stable Diffusion XL.</p> <p>Extra: Powered by a server managed by @stabilityai. Learn more</p>"},{"location":"models/StableDiffusionXL.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/StableDiffusionXL.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 120 points/message |</p> <p>| Initial Points Cost | 120 points |</p> <p>Last Checked: 2025-08-05 23:40:46.372779</p>"},{"location":"models/StableDiffusionXL.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>StableDiffusionXL</code></p> <p>Object Type: model</p> <p>Created: 1688868065472</p> <p>Owned By: poe</p> <p>Root: StableDiffusionXL</p>"},{"location":"models/Tako.html","title":"Tako","text":""},{"location":"models/Tako.html#bot-information","title":"Bot Information","text":"<p>Creator: @trytako</p> <p>Description: Tako is a bot that transforms your questions about stocks, sports, economics or politics into interactive, shareable knowledge cards from trusted sources. Tako's knowledge graph is built exclusively from authoritative, real-time data providers, and is embeddable in your apps, research and storytelling. You can adjust the specificity threshold by typing <code>--specificity 30</code> (or a value between 0 - 100) at the end of your query/question; the default is 60.</p> <p>Extra: Powered by a server managed by @trytako. Learn more</p>"},{"location":"models/Tako.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Tako.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 1000 points/message |</p> <p>| Initial Points Cost | 1000 points |</p> <p>Last Checked: 2025-08-05 23:40:53.136305</p>"},{"location":"models/Tako.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Tako</code></p> <p>Object Type: model</p> <p>Created: 1723756137465</p> <p>Owned By: poe</p> <p>Root: Tako</p>"},{"location":"models/TopazLabs.html","title":"TopazLabs","text":""},{"location":"models/TopazLabs.html#bot-information","title":"Bot Information","text":"<p>Creator: @topazlabsco</p> <p>Description: Topaz Labs\u2019 image upscaler is a best-in-class generative AI model to increase overall clarity and the pixel amount of inputted photos \u2014 whether they be ones generated by AI image models and from the real world \u2014 while preserving the original photo\u2019s contents. It can produce images of as small as ~10MB and as large as 512MB, depending on the size of the input photo. Specify --upscale and a number up to 16 to control the upscaling factor, output_height and/or output_width to specify the number of pixels for each dimension, and add --generated if the input photo is AI-generated. With no parameters specified, it will increase both input photo\u2019s height and width by 2; especially effective on images of human faces.</p> <p>Extra: Powered by a server managed by @topazlabsco. Learn more</p>"},{"location":"models/TopazLabs.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/TopazLabs.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| Up To 24 | 1167 points |</p> <p>| 24 - 32 | 2334 points |</p> <p>| 32 - 48 | 3501 points |</p> <p>| 48 - 64 | 4668 points |</p> <p>| 64 - 128 | 7002 points |</p> <p>| 128 - 256 | 11670 points |</p> <p>| &gt; 256(Up To 512) | 18672 points |</p> <p>Last Checked: 2025-08-05 23:40:59.940563</p>"},{"location":"models/TopazLabs.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>TopazLabs</code></p> <p>Object Type: model</p> <p>Created: 1733266151324</p> <p>Owned By: poe</p> <p>Root: TopazLabs</p>"},{"location":"models/Trellis-3D.html","title":"Trellis-3D","text":""},{"location":"models/Trellis-3D.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Generate 3D models from your images using Trellis, a native 3D generative model enabling versatile and high-quality 3D asset creation. Send an image to convert it into a 3D model.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Trellis-3D.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Trellis-3D.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | 567 points |</p> <p>| 3D Output | 567 points / message |</p> <p>Last Checked: 2025-08-05 23:41:06.753634</p>"},{"location":"models/Trellis-3D.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Trellis-3D</code></p> <p>Object Type: model</p> <p>Created: 1743054517902</p> <p>Owned By: poe</p> <p>Root: Trellis-3D</p>"},{"location":"models/TwelveLabs.html","title":"TwelveLabs","text":""},{"location":"models/TwelveLabs.html#bot-information","title":"Bot Information","text":"<p>Creator: @twelvelabsai</p> <p>Description: Hi, I'm Pegasus! \ud83d\udc4b</p> <p>I'm an AI assistant powered by Twelve Labs' Pegasus Engine that helps me understand videos just like you do! Think of me as your helpful companion who can:</p> <ul> <li>Search through videos to find exactly what you need</li> <li>Understand and explain what's happening in any video scene</li> <li>Create quick, helpful summaries of any video content</li> </ul> <p>Whether you're looking for a specific moment or want to understand what's in your videos, I'm here to help make it simple and fun!</p> <p>Let's explore your videos together!</p> <p>Extra: Powered by a server managed by @twelvelabsai. Learn more</p>"},{"location":"models/TwelveLabs.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/TwelveLabs.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Initial Points Cost | Variable points |</p> <p>| Visual Analysis | 1100 points |</p> <p>| Audio Analysis | 277 points |</p> <p>| Storage | 50 points |</p> <p>Last Checked: 2025-08-05 23:41:13.804179</p>"},{"location":"models/TwelveLabs.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>TwelveLabs</code></p> <p>Object Type: model</p> <p>Created: 1736295272277</p> <p>Owned By: poe</p> <p>Root: TwelveLabs</p>"},{"location":"models/Unreal-Speech-TTS.html","title":"Unreal-Speech-TTS","text":""},{"location":"models/Unreal-Speech-TTS.html#bot-information","title":"Bot Information","text":"<p>Creator: @UnrealSpeech</p> <p>Description: Convert chats, URLs, and documents into natural speech. 8 Languages: English, Japanese, Chinese, Spanish, French, Hindi, Italian, Portuguese. Use <code>--voice &lt;VOICE_NAME&gt;</code>. Defaults to <code>--voice Sierra</code>. Full list below:</p> <p>American English - Male: Noah, Jasper, Caleb, Ronan, Ethan, Daniel, Zane, Rowan - Female: Autumn, Melody, Hannah, Emily, Ivy, Kaitlyn, Luna, Willow, Lauren, Sierra</p> <p>British English - Male: Benjamin, Arthur, Edward, Oliver - Female: Eleanor, Chloe, Amelia, Charlotte</p> <p>Japanese - Male: Haruto - Female: Sakura, Hana, Yuki, Rina</p> <p>Chinese - Male: Wei, Jian, Hao, Sheng - Female: Mei, Lian, Ting, Jing</p> <p>Spanish - Male: Mateo, Javier - Female: Luc\u00eda</p> <p>French - Female: \u00c9lodie</p> <p>Hindi - Male: Arjun, Rohan - Female: Ananya, Priya</p> <p>Italian - Male: Luca - Female: Giulia</p> <p>Portuguese - Male: Thiago, Rafael - Female: Camila</p> <p>Extra: Powered by a server managed by @UnrealSpeech. Learn more</p>"},{"location":"models/Unreal-Speech-TTS.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: audio</p> <p>Modality: text-&gt;audio</p>"},{"location":"models/Unreal-Speech-TTS.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Text Input | 1 point per 5 characters |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:41:20.548138</p>"},{"location":"models/Unreal-Speech-TTS.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Unreal-Speech-TTS</code></p> <p>Object Type: model</p> <p>Created: 1741061137514</p> <p>Owned By: poe</p> <p>Root: Unreal-Speech-TTS</p>"},{"location":"models/Veo-2-Video.html","title":"Veo-2-Video","text":""},{"location":"models/Veo-2-Video.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Veo2 is Google's cutting-edge video generation model. Veo creates videos with realistic motion and high quality output.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Veo-2-Video.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Veo-2-Video.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 70834 points / message |</p> <p>| Initial Points Cost | 70834 points |</p> <p>Last Checked: 2025-08-05 23:41:34.388204</p>"},{"location":"models/Veo-2-Video.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Veo-2-Video</code></p> <p>Object Type: model</p> <p>Created: 1740172728462</p> <p>Owned By: poe</p> <p>Root: Veo-2-Video</p>"},{"location":"models/Veo-2.html","title":"Veo-2","text":""},{"location":"models/Veo-2.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Veo 2 creates incredibly high-quality videos in a wide range of subjects and styles. It brings an improved understanding of real-world physics and the nuances of human movement and expression, which helps improve its detail and realism overall. Veo 2 understands the unique language of cinematography: ask it for a genre, specify a lens, suggest cinematic effects and Veo 2 will deliver in 8-second clips. Use --aspect-ratio (16:9 or 9:16) to customize video aspect ratio. Supports text-to-video as well as image-to-video. Non english input will be translated first. Note: currently has low rate limit so you may need to retry your request at times of peak usage.</p> <p>Extra: Powered by a server managed by @google. Learn more</p>"},{"location":"models/Veo-2.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Veo-2.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 37000 points/message |</p> <p>| Initial Points Cost | 37000 points |</p> <p>Last Checked: 2025-08-05 23:41:27.384550</p>"},{"location":"models/Veo-2.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Veo-2</code></p> <p>Object Type: model</p> <p>Created: 1733117805122</p> <p>Owned By: poe</p> <p>Root: Veo-2</p>"},{"location":"models/Veo-3-Fast.html","title":"Veo-3-Fast","text":""},{"location":"models/Veo-3-Fast.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Veo-3 Fast is a faster and more cost effective version of Google's Veo 3. Use <code>--aspect</code> to set the aspect ratio of the generated image (one of <code>16:9</code>, <code>1:1</code>, <code>9:16</code>. Use <code>--generate_audio</code> to generate audio with your video at a higher cost. Use --negative_prompt to set negative prompt option <code>blur</code>, <code>low resolution</code>, <code>poor resolution</code>. This is a text to video generation model only.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Veo-3-Fast.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Veo-3-Fast.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 8334 points / s |</p> <p>| Initial Points Cost | Variable points |</p> <p>| Audio + Video Output | 13334 points / s |</p> <p>Last Checked: 2025-08-05 23:41:48.319898</p>"},{"location":"models/Veo-3-Fast.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Veo-3-Fast</code></p> <p>Object Type: model</p> <p>Created: 1752140109634</p> <p>Owned By: poe</p> <p>Root: Veo-3-Fast</p>"},{"location":"models/Veo-3.html","title":"Veo-3","text":""},{"location":"models/Veo-3.html#bot-information","title":"Bot Information","text":"<p>Creator: @google</p> <p>Description: Veo 3 creates incredibly high-quality videos in a wide range of subjects and styles. It brings an improved understanding of real-world physics and the nuances of human movement and expression, which helps improve its detail and realism overall. Veo 3 understands the unique language of cinematography: ask it for a genre, specify a lens, suggest cinematic effects and Veo 3 will deliver in 8-second clips. Supports text-to-video as well as image-to-video. Note: currently has low rate limit so you may need to retry your request at times of peak usage.</p> <p>Extra: Powered by a server managed by @google. Learn more</p>"},{"location":"models/Veo-3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Veo-3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Total Cost | 55500 points/message |</p> <p>| Initial Points Cost | 55500 points |</p> <p>Last Checked: 2025-08-05 23:41:41.451474</p>"},{"location":"models/Veo-3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Veo-3</code></p> <p>Object Type: model</p> <p>Created: 1747796700448</p> <p>Owned By: poe</p> <p>Root: Veo-3</p>"},{"location":"models/Wan-2.1.html","title":"Wan-2.1","text":""},{"location":"models/Wan-2.1.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Wan-2.1 is a text-to-video model that generates high-quality videos with high visual quality and motion diversity from text prompts.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Wan-2.1.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: video</p> <p>Modality: text-&gt;video</p>"},{"location":"models/Wan-2.1.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 11334 points / message |</p> <p>| Initial Points Cost | 11334 points |</p> <p>Last Checked: 2025-08-05 23:41:55.253613</p>"},{"location":"models/Wan-2.1.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Wan-2.1</code></p> <p>Object Type: model</p> <p>Created: 1741001573656</p> <p>Owned By: poe</p> <p>Root: Wan-2.1</p>"},{"location":"models/Wan-2.2.html","title":"Wan-2.2","text":""},{"location":"models/Wan-2.2.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Wan-2.2 is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. Use <code>--aspect</code> to set the aspect ratio (One of <code>16:9</code>, <code>1:1</code>, <code>9:16</code>) for text-to-video requests. Duration is limited to 5 seconds only with up to 720p resolution.</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/Wan-2.2.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Wan-2.2.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Video Output | 2667 points / second |</p> <p>| Initial Points Cost | Variable points |</p> <p>Last Checked: 2025-08-05 23:42:02.026350</p>"},{"location":"models/Wan-2.2.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Wan-2.2</code></p> <p>Object Type: model</p> <p>Created: 1753731782474</p> <p>Owned By: poe</p> <p>Root: Wan-2.2</p>"},{"location":"models/Web-Search.html","title":"Web-Search","text":""},{"location":"models/Web-Search.html#bot-information","title":"Bot Information","text":"<p>Creator: @poe</p> <p>Description: Web-enabled assistant bot that searches the internet to inform its responses. Particularly good for queries regarding up-to-date information or specific facts. Powered by Gemini 2.0 Flash.</p> <p>Extra: Powered by Poe and third party model providers. Learn more</p>"},{"location":"models/Web-Search.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/Web-Search.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>Web-Search</code></p> <p>Object Type: model</p> <p>Created: 1694131444821</p> <p>Owned By: poe</p> <p>Root: Web-Search</p>"},{"location":"models/o1-mini.html","title":"o1-mini","text":""},{"location":"models/o1-mini.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: Small version of OpenAI's o1 model, which is designed to spend more time thinking before it responds but at a better performance profile. Can reason through complex tasks in science, coding, and math. For most tasks, https://poe.com/o3-mini will be better. Supports 128k tokens of context.</p> <p>Extra: Powered by OpenAI: o1-mini-2024-09-12. Learn more</p>"},{"location":"models/o1-mini.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/o1-mini.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 33 points/1k tokens |</p> <p>| Bot Message | 352 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 360+ points |</p> <p>Last Checked: 2025-08-05 23:42:21.888136</p>"},{"location":"models/o1-mini.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>o1-mini</code></p> <p>Object Type: model</p> <p>Created: 1726176659168</p> <p>Owned By: poe</p> <p>Root: o1-mini</p>"},{"location":"models/o1-pro.html","title":"o1-pro","text":""},{"location":"models/o1-pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI\u2019s o1-pro highly capable reasoning model, tailored for complex, compute- or context-heavy tasks, dedicating additional thinking time to deliver more accurate, reliable answers. For less costly, complex tasks, https://poe.com/o3-mini is recommended. To instruct the bot to use more reasoning effort, add --reasoning_effort to the end of your message with one of \"low\", \"medium\", or \"high\".</p> <p>Extra: Powered by OpenAI: o1-pro-2025-03-19. Learn more</p>"},{"location":"models/o1-pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/o1-pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 4500 points/1k tokens |</p> <p>| Input Image | 4500 points/1k tokens |</p> <p>| Bot Message | 53457 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 54420+ points |</p> <p>Last Checked: 2025-08-05 23:42:28.739426</p>"},{"location":"models/o1-pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>o1-pro</code></p> <p>Object Type: model</p> <p>Created: 1742413231833</p> <p>Owned By: poe</p> <p>Root: o1-pro</p>"},{"location":"models/o1.html","title":"o1","text":""},{"location":"models/o1.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: OpenAI's o1 is designed to reason before it responds and provides world-class capabilities on complex tasks (e.g. science, coding, and math). Improving upon o1-preview and with higher reasoning effort, it is also capable of reasoning through images and supports 200k tokens of input context. By default, uses reasoning_effort of medium, but low, medium &amp; high are also selectable.</p> <p>Extra: Powered by OpenAI: o1-2024-12-17. Learn more</p>"},{"location":"models/o1.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/o1.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 450 points/1k tokens |</p> <p>| Input Image | 450 points/1k tokens |</p> <p>| Bot Message | 3853 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 3950+ points |</p> <p>Last Checked: 2025-08-05 23:42:15.056787</p>"},{"location":"models/o1.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>o1</code></p> <p>Object Type: model</p> <p>Created: 1734482114732</p> <p>Owned By: poe</p> <p>Root: o1</p>"},{"location":"models/o3-deep-research.html","title":"o3-deep-research","text":""},{"location":"models/o3-deep-research.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: Deep Research from OpenAI powered by the o3 model, can search through extensive web information to answer complex, nuanced research questions in various domains such as finance, consulting, and science. Research queries that take longer than 10 minutes (600 seconds) will error out and compute points will be refunded.</p> <p>Extra: Powered by OpenAI: o3-deep-research-2025-06-26. Learn more</p>"},{"location":"models/o3-deep-research.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/o3-deep-research.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 300 points/1k tokens |</p> <p>| Input Image | 300 points/1k tokens |</p> <p>| Bot Message | 95345 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 75% discount oncached chat history |</p> <p>| Initial Points Cost | 95410+ points |</p> <p>Last Checked: 2025-08-05 23:42:42.355031</p>"},{"location":"models/o3-deep-research.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>o3-deep-research</code></p> <p>Object Type: model</p> <p>Created: 1750982619753</p> <p>Owned By: poe</p> <p>Root: o3-deep-research</p>"},{"location":"models/o3-mini-high.html","title":"o3-mini-high","text":""},{"location":"models/o3-mini-high.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: o3-mini-high is OpenAI's most recent reasoning model with reasoning_effort set to high, providing frontier intelligence on most tasks. Like other models in the o-series, it is designed to excel at science, math, and coding tasks. Supports 200k tokens of input context and 100k tokens of output context.</p> <p>Extra: Powered by OpenAI: o3-mini-2025-01-31. Learn more</p>"},{"location":"models/o3-mini-high.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/o3-mini-high.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 33 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 447 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 455+ points |</p> <p>Last Checked: 2025-08-05 23:42:56.317548</p>"},{"location":"models/o3-mini-high.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>o3-mini-high</code></p> <p>Object Type: model</p> <p>Created: 1738356365479</p> <p>Owned By: poe</p> <p>Root: o3-mini-high</p>"},{"location":"models/o3-mini.html","title":"o3-mini","text":""},{"location":"models/o3-mini.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: o3-mini is OpenAI's reasoning model, providing high intelligence on a variety of tasks and domains, including science, math, and coding. This bot uses medium reasoning effort by default but low, medium &amp; high can be selected; supports 200k tokens of input context and 100k tokens of output context. To instruct the bot to use more reasoning effort, add --reasoning_effort to the end of your message with one of \"low\", \"medium\", or \"high\".</p> <p>Extra: Powered by OpenAI: o3-mini-2025-01-31. Learn more</p>"},{"location":"models/o3-mini.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/o3-mini.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 33 points/1k tokens |</p> <p>| Input Image | Variable |</p> <p>| Bot Message | 199 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 207+ points |</p> <p>Last Checked: 2025-08-05 23:42:49.316928</p>"},{"location":"models/o3-mini.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>o3-mini</code></p> <p>Object Type: model</p> <p>Created: 1738356284517</p> <p>Owned By: poe</p> <p>Root: o3-mini</p>"},{"location":"models/o3-pro.html","title":"o3-pro","text":""},{"location":"models/o3-pro.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: o3-pro is a well-rounded and powerful model across domains, with more capability than https://poe.com/o3 at the cost of higher price and lower speed. It is especially capable at math, science, coding, visual reasoning tasks, technical writing, and instruction-following. Use it to think through multi-step problems that involve analysis across text, code, and images. </p> <p>To instruct the bot to use more reasoning effort, add --reasoning_effort to the end of your message with one of \"low\", \"medium\", or \"high\".</p> <p>Extra: Powered by OpenAI: o3-pro-2025-06-10. Learn more</p>"},{"location":"models/o3-pro.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/o3-pro.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 600 points/1k tokens |</p> <p>| Input Image | 600 points/1k tokens |</p> <p>| Bot Message | 4669 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Initial Points Cost | 4798+ points |</p> <p>Last Checked: 2025-08-05 23:43:03.178226</p>"},{"location":"models/o3-pro.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>o3-pro</code></p> <p>Object Type: model</p> <p>Created: 1749588430571</p> <p>Owned By: poe</p> <p>Root: o3-pro</p>"},{"location":"models/o3.html","title":"o3","text":""},{"location":"models/o3.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: o3 provides state-of-the-art intelligence on a variety of tasks and domains, including science, math, and coding. This bot uses medium reasoning effort by default but low, medium &amp; high are also selectable; supports 200k tokens of input context and 100k tokens of output context.</p> <p>To instruct the bot to use more reasoning effort, add --reasoning_effort to the end of your message with one of \"low\", \"medium\", or \"high\".</p> <p>Extra: Powered by OpenAI: o3-2025-04-16. Learn more</p>"},{"location":"models/o3.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/o3.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 60 points/1k tokens |</p> <p>| Input Image | 60 points/1k tokens |</p> <p>| Bot Message | 388 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 75% discount oncached chat history |</p> <p>| Initial Points Cost | 401+ points |</p> <p>Last Checked: 2025-08-05 23:42:35.454194</p>"},{"location":"models/o3.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>o3</code></p> <p>Object Type: model</p> <p>Created: 1744826529075</p> <p>Owned By: poe</p> <p>Root: o3</p>"},{"location":"models/o4-mini-deep-research.html","title":"o4-mini-deep-research","text":""},{"location":"models/o4-mini-deep-research.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: Deep Research from OpenAI powered by the o4-mini model, can search through extensive web information to answer complex, nuanced research questions in various domains such as finance, consulting, and science. Research queries that take longer than 10 minutes (600 seconds) will error out and compute points will be refunded.</p> <p>Extra: Powered by OpenAI: o4-mini-deep-research-2025-06-26. Learn more</p>"},{"location":"models/o4-mini-deep-research.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/o4-mini-deep-research.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 60 points/1k tokens |</p> <p>| Input Image | 60 points/1k tokens |</p> <p>| Bot Message | 21977 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 75% discount oncached chat history |</p> <p>| Initial Points Cost | 21990+ points |</p> <p>Last Checked: 2025-08-05 23:43:16.644220</p>"},{"location":"models/o4-mini-deep-research.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>o4-mini-deep-research</code></p> <p>Object Type: model</p> <p>Created: 1750982713340</p> <p>Owned By: poe</p> <p>Root: o4-mini-deep-research</p>"},{"location":"models/o4-mini.html","title":"o4-mini","text":""},{"location":"models/o4-mini.html#bot-information","title":"Bot Information","text":"<p>Creator: @openai</p> <p>Description: o4-mini provides high intelligence on a variety of tasks and domains, including science, math, and coding at an affordable price point. This bot uses medium reasoning effort by low, medium &amp; high are also selectable; supports 200k tokens of input context and 100k tokens of output context.</p> <p>To instruct the bot to use more reasoning effort, add --reasoning_effort to the end of your message with one of \"low\", \"medium\", or \"high\".</p> <p>Extra: Powered by OpenAI: o4-mini-2025-04-16. Learn more</p>"},{"location":"models/o4-mini.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: text</p> <p>Modality: text-&gt;text</p>"},{"location":"models/o4-mini.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Input Text | 33 points/1k tokens |</p> <p>| Input Image | 33 points/1k tokens |</p> <p>| Bot Message | 235 points/message |</p> <p>| Chat History | Input rates are applied |</p> <p>| Chat History Cache Discount | 75% discount oncached chat history |</p> <p>| Initial Points Cost | 243+ points |</p> <p>Last Checked: 2025-08-05 23:43:09.818497</p>"},{"location":"models/o4-mini.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>o4-mini</code></p> <p>Object Type: model</p> <p>Created: 1744826580331</p> <p>Owned By: poe</p> <p>Root: o4-mini</p>"},{"location":"models/remove-background.html","title":"remove-background","text":""},{"location":"models/remove-background.html#bot-information","title":"Bot Information","text":"<p>Creator: @fal</p> <p>Description: Remove background from your images</p> <p>Extra: Powered by a server managed by @fal. Learn more</p>"},{"location":"models/remove-background.html#architecture","title":"Architecture","text":"<p>Input Modalities: text</p> <p>Output Modalities: image</p> <p>Modality: text-&gt;image</p>"},{"location":"models/remove-background.html#pricing","title":"Pricing","text":"<p>| Type | Cost |</p> <p>|------|------|</p> <p>| Image Output | 34 points / message |</p> <p>| Initial Points Cost | 34 points |</p> <p>Last Checked: 2025-08-05 23:43:23.507230</p>"},{"location":"models/remove-background.html#technical-details","title":"Technical Details","text":"<p>Model ID: <code>remove-background</code></p> <p>Object Type: model</p> <p>Created: 1714848450172</p> <p>Owned By: poe</p> <p>Root: remove-background</p>"}]}